{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c52f56",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a4b29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
    "    precision_recall_curve, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "\n",
    "import warnings\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RAND=10\n",
    "N_FOLDS=5\n",
    "percent_of_negative_class = 0.958"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd4096",
   "metadata": {},
   "source": [
    "# Метод для подсчёта метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04d8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name):\n",
    "    df_metrics = pd.DataFrame()\n",
    "    \n",
    "    df_metrics['model'] = [name]\n",
    "    \n",
    "    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n",
    "    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:,1])]\n",
    "    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n",
    "    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n",
    "    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n",
    "    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6656c",
   "metadata": {},
   "source": [
    "# Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f744fd7",
   "metadata": {},
   "source": [
    "Выгрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49e0902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEMESTER</th>\n",
       "      <th>DISC_ID</th>\n",
       "      <th>TYPE_NAME</th>\n",
       "      <th>DEBT</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>EXAM_TYPE</th>\n",
       "      <th>EXAM_SUBJECT_1</th>\n",
       "      <th>EXAM_SUBJECT_2</th>\n",
       "      <th>EXAM_SUBJECT_3</th>\n",
       "      <th>ADMITTED_EXAM_1</th>\n",
       "      <th>ADMITTED_EXAM_2</th>\n",
       "      <th>ADMITTED_EXAM_3</th>\n",
       "      <th>ADMITTED_SUBJECT_PRIZE_LEVEL</th>\n",
       "      <th>REGION_ID</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10502311854018326223</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1601392918367593206</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9559803959325174929</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8955667882044263414</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17741967398854095262</td>\n",
       "      <td>Экзамен</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEMESTER               DISC_ID TYPE_NAME  DEBT GENDER  \\\n",
       "0         1  10502311854018326223     Зачет     0      М   \n",
       "1         1   1601392918367593206     Зачет     0      М   \n",
       "2         1   9559803959325174929     Зачет     0      М   \n",
       "3         1   8955667882044263414     Зачет     0      М   \n",
       "4         1  17741967398854095262   Экзамен     0      М   \n",
       "\n",
       "            CITIZENSHIP EXAM_TYPE     EXAM_SUBJECT_1       EXAM_SUBJECT_2  \\\n",
       "0  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "1  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "2  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "3  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "4  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "\n",
       "        EXAM_SUBJECT_3  ADMITTED_EXAM_1  ADMITTED_EXAM_2  ADMITTED_EXAM_3  \\\n",
       "0  8388269026169219461             78.0             79.0             91.0   \n",
       "1  8388269026169219461             78.0             79.0             91.0   \n",
       "2  8388269026169219461             78.0             79.0             91.0   \n",
       "3  8388269026169219461             78.0             79.0             91.0   \n",
       "4  8388269026169219461             78.0             79.0             91.0   \n",
       "\n",
       "  ADMITTED_SUBJECT_PRIZE_LEVEL            REGION_ID  mean_score  \n",
       "0                          ЕГЭ  7805492244297918082   82.666667  \n",
       "1                          ЕГЭ  7805492244297918082   82.666667  \n",
       "2                          ЕГЭ  7805492244297918082   82.666667  \n",
       "3                          ЕГЭ  7805492244297918082   82.666667  \n",
       "4                          ЕГЭ  7805492244297918082   82.666667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb829e9",
   "metadata": {},
   "source": [
    "Проведём разбиение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88581c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.drop(columns = ['DEBT'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols,\n",
    "                                                    df['DEBT'],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4aa2e",
   "metadata": {},
   "source": [
    "Разобьём train на train_ и val для чтобы сформировать eval_set (для ранней остановки в бустингах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5bb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=0.16,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RAND)\n",
    "eval_set = [(X_val, y_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f75602",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbf928",
   "metadata": {},
   "source": [
    "Найдём параметры при помощи библиотеки optuna. Сначала подберём learning_rate и n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b56bca",
   "metadata": {},
   "source": [
    "## learning_rate и n_esimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35481418",
   "metadata": {},
   "source": [
    "- n_estimators - кол-во базовых алгоритмов\n",
    "- learning rate - скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "897808fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 14:43:12,550]\u001b[0m A new study created in memory with name: LightGBM\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1a8e33cfa1488cac48cf0b9188eef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 14:43:20,394]\u001b[0m Trial 0 finished with value: 0.8554715479113805 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17203026361943966, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:25,254]\u001b[0m Trial 1 finished with value: 0.848333986959973 and parameters: {'n_estimators': 11841, 'Learning_rate': 0.2557376697839917, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:31,153]\u001b[0m Trial 2 finished with value: 0.8450412192006047 and parameters: {'n_estimators': 14780, 'Learning_rate': 0.27917781444103074, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:37,292]\u001b[0m Trial 3 finished with value: 0.8519560531729595 and parameters: {'n_estimators': 1146, 'Learning_rate': 0.18765711830815424, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:49,334]\u001b[0m Trial 4 finished with value: 0.7575019350417485 and parameters: {'n_estimators': 464, 'Learning_rate': 0.0016559674300467963, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:49,454]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:49,599]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:49,767]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:49,907]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:50,037]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:50,169]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:50,320]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,035]\u001b[0m Trial 12 finished with value: 0.8501351395478289 and parameters: {'n_estimators': 3539, 'Learning_rate': 0.21144481564615097, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,162]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,300]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,465]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,612]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:43:56,830]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:44:03,514]\u001b[0m Trial 18 finished with value: 0.850770153229301 and parameters: {'n_estimators': 1824, 'Learning_rate': 0.2151325310783699, 'random_state:': 10, 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8554715479113805.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 14:44:03,659]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.72741\tvalid_0's binary_logloss: 0.186131\n",
      "[4]\tvalid_0's auc: 0.744927\tvalid_0's binary_logloss: 0.181537\n",
      "[6]\tvalid_0's auc: 0.754231\tvalid_0's binary_logloss: 0.178157\n",
      "[8]\tvalid_0's auc: 0.76305\tvalid_0's binary_logloss: 0.175084\n",
      "[10]\tvalid_0's auc: 0.76667\tvalid_0's binary_logloss: 0.173192\n",
      "[12]\tvalid_0's auc: 0.770264\tvalid_0's binary_logloss: 0.171532\n",
      "[14]\tvalid_0's auc: 0.771433\tvalid_0's binary_logloss: 0.170509\n",
      "[16]\tvalid_0's auc: 0.773818\tvalid_0's binary_logloss: 0.169514\n",
      "[18]\tvalid_0's auc: 0.774718\tvalid_0's binary_logloss: 0.168707\n",
      "[20]\tvalid_0's auc: 0.777526\tvalid_0's binary_logloss: 0.167915\n",
      "[22]\tvalid_0's auc: 0.779565\tvalid_0's binary_logloss: 0.167188\n",
      "[24]\tvalid_0's auc: 0.784421\tvalid_0's binary_logloss: 0.166051\n",
      "[26]\tvalid_0's auc: 0.786651\tvalid_0's binary_logloss: 0.165332\n",
      "[28]\tvalid_0's auc: 0.789557\tvalid_0's binary_logloss: 0.16456\n",
      "[30]\tvalid_0's auc: 0.792051\tvalid_0's binary_logloss: 0.16389\n",
      "[32]\tvalid_0's auc: 0.791833\tvalid_0's binary_logloss: 0.163694\n",
      "[34]\tvalid_0's auc: 0.795055\tvalid_0's binary_logloss: 0.162977\n",
      "[36]\tvalid_0's auc: 0.795183\tvalid_0's binary_logloss: 0.162806\n",
      "[38]\tvalid_0's auc: 0.796035\tvalid_0's binary_logloss: 0.162309\n",
      "[40]\tvalid_0's auc: 0.799371\tvalid_0's binary_logloss: 0.161649\n",
      "[42]\tvalid_0's auc: 0.802593\tvalid_0's binary_logloss: 0.160858\n",
      "[44]\tvalid_0's auc: 0.803232\tvalid_0's binary_logloss: 0.160619\n",
      "[46]\tvalid_0's auc: 0.803729\tvalid_0's binary_logloss: 0.160382\n",
      "[48]\tvalid_0's auc: 0.805589\tvalid_0's binary_logloss: 0.159755\n",
      "[50]\tvalid_0's auc: 0.807782\tvalid_0's binary_logloss: 0.159276\n",
      "[52]\tvalid_0's auc: 0.808573\tvalid_0's binary_logloss: 0.158932\n",
      "[54]\tvalid_0's auc: 0.80894\tvalid_0's binary_logloss: 0.158827\n",
      "[56]\tvalid_0's auc: 0.809682\tvalid_0's binary_logloss: 0.158675\n",
      "[58]\tvalid_0's auc: 0.810332\tvalid_0's binary_logloss: 0.158498\n",
      "[60]\tvalid_0's auc: 0.810903\tvalid_0's binary_logloss: 0.158351\n",
      "[62]\tvalid_0's auc: 0.811697\tvalid_0's binary_logloss: 0.158059\n",
      "[64]\tvalid_0's auc: 0.812176\tvalid_0's binary_logloss: 0.157968\n",
      "[66]\tvalid_0's auc: 0.812785\tvalid_0's binary_logloss: 0.157893\n",
      "[68]\tvalid_0's auc: 0.813204\tvalid_0's binary_logloss: 0.157802\n",
      "[70]\tvalid_0's auc: 0.813481\tvalid_0's binary_logloss: 0.157649\n",
      "[72]\tvalid_0's auc: 0.814399\tvalid_0's binary_logloss: 0.157403\n",
      "[74]\tvalid_0's auc: 0.814877\tvalid_0's binary_logloss: 0.157258\n",
      "[76]\tvalid_0's auc: 0.815631\tvalid_0's binary_logloss: 0.157117\n",
      "[78]\tvalid_0's auc: 0.817143\tvalid_0's binary_logloss: 0.15673\n",
      "[80]\tvalid_0's auc: 0.816691\tvalid_0's binary_logloss: 0.156782\n",
      "[82]\tvalid_0's auc: 0.817472\tvalid_0's binary_logloss: 0.156634\n",
      "[84]\tvalid_0's auc: 0.818924\tvalid_0's binary_logloss: 0.156285\n",
      "[86]\tvalid_0's auc: 0.818709\tvalid_0's binary_logloss: 0.156223\n",
      "[88]\tvalid_0's auc: 0.819522\tvalid_0's binary_logloss: 0.156007\n",
      "[90]\tvalid_0's auc: 0.820002\tvalid_0's binary_logloss: 0.155867\n",
      "[92]\tvalid_0's auc: 0.820639\tvalid_0's binary_logloss: 0.155631\n",
      "[94]\tvalid_0's auc: 0.821252\tvalid_0's binary_logloss: 0.155396\n",
      "[96]\tvalid_0's auc: 0.82271\tvalid_0's binary_logloss: 0.15498\n",
      "[98]\tvalid_0's auc: 0.823436\tvalid_0's binary_logloss: 0.154772\n",
      "[100]\tvalid_0's auc: 0.82417\tvalid_0's binary_logloss: 0.154539\n",
      "[102]\tvalid_0's auc: 0.825938\tvalid_0's binary_logloss: 0.154033\n",
      "[104]\tvalid_0's auc: 0.826781\tvalid_0's binary_logloss: 0.153837\n",
      "[106]\tvalid_0's auc: 0.828061\tvalid_0's binary_logloss: 0.153472\n",
      "[108]\tvalid_0's auc: 0.829989\tvalid_0's binary_logloss: 0.152948\n",
      "[110]\tvalid_0's auc: 0.830854\tvalid_0's binary_logloss: 0.152693\n",
      "[112]\tvalid_0's auc: 0.831066\tvalid_0's binary_logloss: 0.152538\n",
      "[114]\tvalid_0's auc: 0.831587\tvalid_0's binary_logloss: 0.152386\n",
      "[116]\tvalid_0's auc: 0.831623\tvalid_0's binary_logloss: 0.152342\n",
      "[118]\tvalid_0's auc: 0.832271\tvalid_0's binary_logloss: 0.15215\n",
      "[120]\tvalid_0's auc: 0.832205\tvalid_0's binary_logloss: 0.152159\n",
      "[122]\tvalid_0's auc: 0.832985\tvalid_0's binary_logloss: 0.151911\n",
      "[124]\tvalid_0's auc: 0.833571\tvalid_0's binary_logloss: 0.151764\n",
      "[126]\tvalid_0's auc: 0.834059\tvalid_0's binary_logloss: 0.151607\n",
      "[128]\tvalid_0's auc: 0.834577\tvalid_0's binary_logloss: 0.151488\n",
      "[130]\tvalid_0's auc: 0.835098\tvalid_0's binary_logloss: 0.151288\n",
      "[132]\tvalid_0's auc: 0.835323\tvalid_0's binary_logloss: 0.151214\n",
      "[134]\tvalid_0's auc: 0.836524\tvalid_0's binary_logloss: 0.150903\n",
      "[136]\tvalid_0's auc: 0.836534\tvalid_0's binary_logloss: 0.150893\n",
      "[138]\tvalid_0's auc: 0.837445\tvalid_0's binary_logloss: 0.150645\n",
      "[140]\tvalid_0's auc: 0.838045\tvalid_0's binary_logloss: 0.1505\n",
      "[142]\tvalid_0's auc: 0.839002\tvalid_0's binary_logloss: 0.150203\n",
      "[144]\tvalid_0's auc: 0.84015\tvalid_0's binary_logloss: 0.149903\n",
      "[146]\tvalid_0's auc: 0.840635\tvalid_0's binary_logloss: 0.149772\n",
      "[148]\tvalid_0's auc: 0.841413\tvalid_0's binary_logloss: 0.149589\n",
      "[150]\tvalid_0's auc: 0.841361\tvalid_0's binary_logloss: 0.14957\n",
      "[152]\tvalid_0's auc: 0.841995\tvalid_0's binary_logloss: 0.149429\n",
      "[154]\tvalid_0's auc: 0.842233\tvalid_0's binary_logloss: 0.149335\n",
      "[156]\tvalid_0's auc: 0.842321\tvalid_0's binary_logloss: 0.149309\n",
      "[158]\tvalid_0's auc: 0.842528\tvalid_0's binary_logloss: 0.14924\n",
      "[160]\tvalid_0's auc: 0.842319\tvalid_0's binary_logloss: 0.149254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162]\tvalid_0's auc: 0.842607\tvalid_0's binary_logloss: 0.149174\n",
      "[164]\tvalid_0's auc: 0.843428\tvalid_0's binary_logloss: 0.148922\n",
      "[166]\tvalid_0's auc: 0.843786\tvalid_0's binary_logloss: 0.148767\n",
      "[168]\tvalid_0's auc: 0.84446\tvalid_0's binary_logloss: 0.148575\n",
      "[170]\tvalid_0's auc: 0.844585\tvalid_0's binary_logloss: 0.148505\n",
      "[172]\tvalid_0's auc: 0.844768\tvalid_0's binary_logloss: 0.148419\n",
      "[174]\tvalid_0's auc: 0.845445\tvalid_0's binary_logloss: 0.148168\n",
      "[176]\tvalid_0's auc: 0.845811\tvalid_0's binary_logloss: 0.148028\n",
      "[178]\tvalid_0's auc: 0.846308\tvalid_0's binary_logloss: 0.147876\n",
      "[180]\tvalid_0's auc: 0.846634\tvalid_0's binary_logloss: 0.147762\n",
      "[182]\tvalid_0's auc: 0.846543\tvalid_0's binary_logloss: 0.147806\n",
      "[184]\tvalid_0's auc: 0.846527\tvalid_0's binary_logloss: 0.147777\n",
      "[186]\tvalid_0's auc: 0.846825\tvalid_0's binary_logloss: 0.147626\n",
      "[188]\tvalid_0's auc: 0.847285\tvalid_0's binary_logloss: 0.147395\n",
      "[190]\tvalid_0's auc: 0.847811\tvalid_0's binary_logloss: 0.147236\n",
      "[192]\tvalid_0's auc: 0.847797\tvalid_0's binary_logloss: 0.147193\n",
      "[194]\tvalid_0's auc: 0.847911\tvalid_0's binary_logloss: 0.147119\n",
      "[196]\tvalid_0's auc: 0.848296\tvalid_0's binary_logloss: 0.147018\n",
      "[198]\tvalid_0's auc: 0.848657\tvalid_0's binary_logloss: 0.1469\n",
      "[200]\tvalid_0's auc: 0.848648\tvalid_0's binary_logloss: 0.14681\n",
      "[202]\tvalid_0's auc: 0.849737\tvalid_0's binary_logloss: 0.146503\n",
      "[204]\tvalid_0's auc: 0.85027\tvalid_0's binary_logloss: 0.146302\n",
      "[206]\tvalid_0's auc: 0.850379\tvalid_0's binary_logloss: 0.146237\n",
      "[208]\tvalid_0's auc: 0.850335\tvalid_0's binary_logloss: 0.14621\n",
      "[210]\tvalid_0's auc: 0.850697\tvalid_0's binary_logloss: 0.146107\n",
      "[212]\tvalid_0's auc: 0.8508\tvalid_0's binary_logloss: 0.146116\n",
      "[214]\tvalid_0's auc: 0.850819\tvalid_0's binary_logloss: 0.146129\n",
      "[216]\tvalid_0's auc: 0.851329\tvalid_0's binary_logloss: 0.146001\n",
      "[218]\tvalid_0's auc: 0.851563\tvalid_0's binary_logloss: 0.145903\n",
      "[220]\tvalid_0's auc: 0.851587\tvalid_0's binary_logloss: 0.145873\n",
      "[222]\tvalid_0's auc: 0.851541\tvalid_0's binary_logloss: 0.145865\n",
      "[224]\tvalid_0's auc: 0.851722\tvalid_0's binary_logloss: 0.145838\n",
      "[226]\tvalid_0's auc: 0.852045\tvalid_0's binary_logloss: 0.145626\n",
      "[228]\tvalid_0's auc: 0.852298\tvalid_0's binary_logloss: 0.145572\n",
      "[230]\tvalid_0's auc: 0.852341\tvalid_0's binary_logloss: 0.145534\n",
      "[232]\tvalid_0's auc: 0.852803\tvalid_0's binary_logloss: 0.145353\n",
      "[234]\tvalid_0's auc: 0.853092\tvalid_0's binary_logloss: 0.145241\n",
      "[236]\tvalid_0's auc: 0.853503\tvalid_0's binary_logloss: 0.145097\n",
      "[238]\tvalid_0's auc: 0.853571\tvalid_0's binary_logloss: 0.145079\n",
      "[240]\tvalid_0's auc: 0.85383\tvalid_0's binary_logloss: 0.145019\n",
      "[242]\tvalid_0's auc: 0.854098\tvalid_0's binary_logloss: 0.144935\n",
      "[244]\tvalid_0's auc: 0.853786\tvalid_0's binary_logloss: 0.144986\n",
      "[246]\tvalid_0's auc: 0.854802\tvalid_0's binary_logloss: 0.144694\n",
      "[248]\tvalid_0's auc: 0.854647\tvalid_0's binary_logloss: 0.144733\n",
      "[250]\tvalid_0's auc: 0.854773\tvalid_0's binary_logloss: 0.144658\n",
      "[252]\tvalid_0's auc: 0.855258\tvalid_0's binary_logloss: 0.144467\n",
      "[254]\tvalid_0's auc: 0.855506\tvalid_0's binary_logloss: 0.144368\n",
      "[256]\tvalid_0's auc: 0.855856\tvalid_0's binary_logloss: 0.144288\n",
      "[258]\tvalid_0's auc: 0.856041\tvalid_0's binary_logloss: 0.144256\n",
      "[260]\tvalid_0's auc: 0.856038\tvalid_0's binary_logloss: 0.144272\n",
      "[262]\tvalid_0's auc: 0.856031\tvalid_0's binary_logloss: 0.144227\n",
      "[264]\tvalid_0's auc: 0.856271\tvalid_0's binary_logloss: 0.144225\n",
      "[266]\tvalid_0's auc: 0.856637\tvalid_0's binary_logloss: 0.144152\n",
      "[268]\tvalid_0's auc: 0.857239\tvalid_0's binary_logloss: 0.143946\n",
      "[270]\tvalid_0's auc: 0.857492\tvalid_0's binary_logloss: 0.143913\n",
      "[272]\tvalid_0's auc: 0.857578\tvalid_0's binary_logloss: 0.143909\n",
      "[274]\tvalid_0's auc: 0.857673\tvalid_0's binary_logloss: 0.143914\n",
      "[276]\tvalid_0's auc: 0.858029\tvalid_0's binary_logloss: 0.143801\n",
      "[278]\tvalid_0's auc: 0.857934\tvalid_0's binary_logloss: 0.143843\n",
      "[280]\tvalid_0's auc: 0.85785\tvalid_0's binary_logloss: 0.143833\n",
      "[282]\tvalid_0's auc: 0.85822\tvalid_0's binary_logloss: 0.14377\n",
      "[284]\tvalid_0's auc: 0.8582\tvalid_0's binary_logloss: 0.143767\n",
      "[286]\tvalid_0's auc: 0.858688\tvalid_0's binary_logloss: 0.143633\n",
      "[288]\tvalid_0's auc: 0.858665\tvalid_0's binary_logloss: 0.143661\n",
      "[290]\tvalid_0's auc: 0.858822\tvalid_0's binary_logloss: 0.143611\n",
      "[292]\tvalid_0's auc: 0.858853\tvalid_0's binary_logloss: 0.143612\n",
      "[294]\tvalid_0's auc: 0.858729\tvalid_0's binary_logloss: 0.143631\n",
      "[296]\tvalid_0's auc: 0.858983\tvalid_0's binary_logloss: 0.143566\n",
      "[298]\tvalid_0's auc: 0.85927\tvalid_0's binary_logloss: 0.143463\n",
      "[300]\tvalid_0's auc: 0.85973\tvalid_0's binary_logloss: 0.143319\n",
      "[302]\tvalid_0's auc: 0.860158\tvalid_0's binary_logloss: 0.143237\n",
      "[304]\tvalid_0's auc: 0.860225\tvalid_0's binary_logloss: 0.143242\n",
      "[306]\tvalid_0's auc: 0.860217\tvalid_0's binary_logloss: 0.143256\n",
      "[308]\tvalid_0's auc: 0.860289\tvalid_0's binary_logloss: 0.143286\n",
      "[310]\tvalid_0's auc: 0.860462\tvalid_0's binary_logloss: 0.14319\n",
      "[312]\tvalid_0's auc: 0.860983\tvalid_0's binary_logloss: 0.143063\n",
      "[314]\tvalid_0's auc: 0.861281\tvalid_0's binary_logloss: 0.142955\n",
      "[316]\tvalid_0's auc: 0.861332\tvalid_0's binary_logloss: 0.143002\n",
      "[318]\tvalid_0's auc: 0.861404\tvalid_0's binary_logloss: 0.142909\n",
      "[320]\tvalid_0's auc: 0.861358\tvalid_0's binary_logloss: 0.142921\n",
      "[322]\tvalid_0's auc: 0.861355\tvalid_0's binary_logloss: 0.142933\n",
      "[324]\tvalid_0's auc: 0.861298\tvalid_0's binary_logloss: 0.142993\n",
      "[326]\tvalid_0's auc: 0.861239\tvalid_0's binary_logloss: 0.14305\n",
      "[328]\tvalid_0's auc: 0.861186\tvalid_0's binary_logloss: 0.143076\n",
      "[330]\tvalid_0's auc: 0.861022\tvalid_0's binary_logloss: 0.143129\n",
      "[332]\tvalid_0's auc: 0.86119\tvalid_0's binary_logloss: 0.143102\n",
      "[334]\tvalid_0's auc: 0.86168\tvalid_0's binary_logloss: 0.142945\n",
      "[336]\tvalid_0's auc: 0.861915\tvalid_0's binary_logloss: 0.142821\n",
      "[338]\tvalid_0's auc: 0.861807\tvalid_0's binary_logloss: 0.142886\n",
      "[340]\tvalid_0's auc: 0.861553\tvalid_0's binary_logloss: 0.142922\n",
      "[342]\tvalid_0's auc: 0.86149\tvalid_0's binary_logloss: 0.142941\n",
      "[344]\tvalid_0's auc: 0.861989\tvalid_0's binary_logloss: 0.142817\n",
      "[346]\tvalid_0's auc: 0.862267\tvalid_0's binary_logloss: 0.142734\n",
      "[348]\tvalid_0's auc: 0.86231\tvalid_0's binary_logloss: 0.142762\n",
      "[350]\tvalid_0's auc: 0.862621\tvalid_0's binary_logloss: 0.142657\n",
      "[352]\tvalid_0's auc: 0.862674\tvalid_0's binary_logloss: 0.142667\n",
      "[354]\tvalid_0's auc: 0.863272\tvalid_0's binary_logloss: 0.142484\n",
      "[356]\tvalid_0's auc: 0.863335\tvalid_0's binary_logloss: 0.142448\n",
      "[358]\tvalid_0's auc: 0.863145\tvalid_0's binary_logloss: 0.142501\n",
      "[360]\tvalid_0's auc: 0.86333\tvalid_0's binary_logloss: 0.142391\n",
      "[362]\tvalid_0's auc: 0.863495\tvalid_0's binary_logloss: 0.142304\n",
      "[364]\tvalid_0's auc: 0.863573\tvalid_0's binary_logloss: 0.142276\n",
      "[366]\tvalid_0's auc: 0.863712\tvalid_0's binary_logloss: 0.14228\n",
      "[368]\tvalid_0's auc: 0.863826\tvalid_0's binary_logloss: 0.142263\n",
      "[370]\tvalid_0's auc: 0.863745\tvalid_0's binary_logloss: 0.142274\n",
      "[372]\tvalid_0's auc: 0.863895\tvalid_0's binary_logloss: 0.142206\n",
      "[374]\tvalid_0's auc: 0.864018\tvalid_0's binary_logloss: 0.142194\n",
      "[376]\tvalid_0's auc: 0.864101\tvalid_0's binary_logloss: 0.142175\n",
      "[378]\tvalid_0's auc: 0.864528\tvalid_0's binary_logloss: 0.142103\n",
      "[380]\tvalid_0's auc: 0.864573\tvalid_0's binary_logloss: 0.142086\n",
      "[382]\tvalid_0's auc: 0.864738\tvalid_0's binary_logloss: 0.142041\n",
      "[384]\tvalid_0's auc: 0.864796\tvalid_0's binary_logloss: 0.142032\n",
      "[386]\tvalid_0's auc: 0.864748\tvalid_0's binary_logloss: 0.142044\n",
      "[388]\tvalid_0's auc: 0.864496\tvalid_0's binary_logloss: 0.142149\n",
      "[390]\tvalid_0's auc: 0.864481\tvalid_0's binary_logloss: 0.142177\n",
      "[392]\tvalid_0's auc: 0.864467\tvalid_0's binary_logloss: 0.14219\n",
      "[394]\tvalid_0's auc: 0.864485\tvalid_0's binary_logloss: 0.142184\n",
      "[396]\tvalid_0's auc: 0.864594\tvalid_0's binary_logloss: 0.142148\n",
      "[398]\tvalid_0's auc: 0.864644\tvalid_0's binary_logloss: 0.142147\n",
      "[400]\tvalid_0's auc: 0.864611\tvalid_0's binary_logloss: 0.142181\n",
      "[402]\tvalid_0's auc: 0.864745\tvalid_0's binary_logloss: 0.142147\n",
      "[404]\tvalid_0's auc: 0.864716\tvalid_0's binary_logloss: 0.142179\n",
      "[406]\tvalid_0's auc: 0.864768\tvalid_0's binary_logloss: 0.142141\n",
      "[408]\tvalid_0's auc: 0.865023\tvalid_0's binary_logloss: 0.142074\n",
      "[410]\tvalid_0's auc: 0.865059\tvalid_0's binary_logloss: 0.142056\n",
      "[412]\tvalid_0's auc: 0.865249\tvalid_0's binary_logloss: 0.142005\n",
      "[414]\tvalid_0's auc: 0.865155\tvalid_0's binary_logloss: 0.142057\n",
      "[416]\tvalid_0's auc: 0.865054\tvalid_0's binary_logloss: 0.142105\n",
      "[418]\tvalid_0's auc: 0.864902\tvalid_0's binary_logloss: 0.142161\n",
      "[420]\tvalid_0's auc: 0.865014\tvalid_0's binary_logloss: 0.142136\n",
      "[422]\tvalid_0's auc: 0.865501\tvalid_0's binary_logloss: 0.142062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[424]\tvalid_0's auc: 0.865505\tvalid_0's binary_logloss: 0.142126\n",
      "[426]\tvalid_0's auc: 0.865799\tvalid_0's binary_logloss: 0.142074\n",
      "[428]\tvalid_0's auc: 0.865927\tvalid_0's binary_logloss: 0.142017\n",
      "[430]\tvalid_0's auc: 0.865969\tvalid_0's binary_logloss: 0.142044\n",
      "[432]\tvalid_0's auc: 0.866087\tvalid_0's binary_logloss: 0.142022\n",
      "[434]\tvalid_0's auc: 0.866287\tvalid_0's binary_logloss: 0.141933\n",
      "[436]\tvalid_0's auc: 0.866196\tvalid_0's binary_logloss: 0.141993\n",
      "[438]\tvalid_0's auc: 0.866151\tvalid_0's binary_logloss: 0.142046\n",
      "[440]\tvalid_0's auc: 0.866579\tvalid_0's binary_logloss: 0.14191\n",
      "[442]\tvalid_0's auc: 0.866442\tvalid_0's binary_logloss: 0.141969\n",
      "[444]\tvalid_0's auc: 0.866486\tvalid_0's binary_logloss: 0.141972\n",
      "[446]\tvalid_0's auc: 0.866847\tvalid_0's binary_logloss: 0.141895\n",
      "[448]\tvalid_0's auc: 0.866879\tvalid_0's binary_logloss: 0.141878\n",
      "[450]\tvalid_0's auc: 0.867231\tvalid_0's binary_logloss: 0.141769\n",
      "[452]\tvalid_0's auc: 0.86721\tvalid_0's binary_logloss: 0.141787\n",
      "[454]\tvalid_0's auc: 0.867583\tvalid_0's binary_logloss: 0.141682\n",
      "[456]\tvalid_0's auc: 0.867762\tvalid_0's binary_logloss: 0.141568\n",
      "[458]\tvalid_0's auc: 0.867606\tvalid_0's binary_logloss: 0.141597\n",
      "[460]\tvalid_0's auc: 0.867604\tvalid_0's binary_logloss: 0.14163\n",
      "[462]\tvalid_0's auc: 0.867554\tvalid_0's binary_logloss: 0.141622\n",
      "[464]\tvalid_0's auc: 0.867535\tvalid_0's binary_logloss: 0.141621\n",
      "[466]\tvalid_0's auc: 0.867598\tvalid_0's binary_logloss: 0.141622\n",
      "[468]\tvalid_0's auc: 0.867967\tvalid_0's binary_logloss: 0.14153\n",
      "[470]\tvalid_0's auc: 0.867864\tvalid_0's binary_logloss: 0.141537\n",
      "[472]\tvalid_0's auc: 0.867838\tvalid_0's binary_logloss: 0.141553\n",
      "[474]\tvalid_0's auc: 0.867735\tvalid_0's binary_logloss: 0.141592\n",
      "[476]\tvalid_0's auc: 0.867746\tvalid_0's binary_logloss: 0.141612\n",
      "[478]\tvalid_0's auc: 0.867864\tvalid_0's binary_logloss: 0.141599\n",
      "[480]\tvalid_0's auc: 0.868083\tvalid_0's binary_logloss: 0.141551\n",
      "[482]\tvalid_0's auc: 0.868063\tvalid_0's binary_logloss: 0.141588\n",
      "[484]\tvalid_0's auc: 0.868197\tvalid_0's binary_logloss: 0.141548\n",
      "[486]\tvalid_0's auc: 0.868208\tvalid_0's binary_logloss: 0.141589\n",
      "[488]\tvalid_0's auc: 0.868202\tvalid_0's binary_logloss: 0.1416\n",
      "[490]\tvalid_0's auc: 0.868484\tvalid_0's binary_logloss: 0.141567\n",
      "[492]\tvalid_0's auc: 0.868463\tvalid_0's binary_logloss: 0.141608\n",
      "[494]\tvalid_0's auc: 0.86859\tvalid_0's binary_logloss: 0.141567\n",
      "[496]\tvalid_0's auc: 0.868657\tvalid_0's binary_logloss: 0.141576\n",
      "[498]\tvalid_0's auc: 0.868781\tvalid_0's binary_logloss: 0.141551\n",
      "[500]\tvalid_0's auc: 0.868584\tvalid_0's binary_logloss: 0.141643\n",
      "[502]\tvalid_0's auc: 0.868741\tvalid_0's binary_logloss: 0.141636\n",
      "[504]\tvalid_0's auc: 0.868864\tvalid_0's binary_logloss: 0.14164\n",
      "[506]\tvalid_0's auc: 0.868853\tvalid_0's binary_logloss: 0.141673\n",
      "[508]\tvalid_0's auc: 0.869269\tvalid_0's binary_logloss: 0.141486\n",
      "[510]\tvalid_0's auc: 0.869821\tvalid_0's binary_logloss: 0.141334\n",
      "[512]\tvalid_0's auc: 0.869901\tvalid_0's binary_logloss: 0.141316\n",
      "[514]\tvalid_0's auc: 0.869806\tvalid_0's binary_logloss: 0.141371\n",
      "[516]\tvalid_0's auc: 0.869781\tvalid_0's binary_logloss: 0.141415\n",
      "[518]\tvalid_0's auc: 0.869818\tvalid_0's binary_logloss: 0.141393\n",
      "[520]\tvalid_0's auc: 0.869917\tvalid_0's binary_logloss: 0.141407\n",
      "[522]\tvalid_0's auc: 0.870008\tvalid_0's binary_logloss: 0.141372\n",
      "[524]\tvalid_0's auc: 0.870261\tvalid_0's binary_logloss: 0.14126\n",
      "[526]\tvalid_0's auc: 0.870353\tvalid_0's binary_logloss: 0.141239\n",
      "[528]\tvalid_0's auc: 0.870455\tvalid_0's binary_logloss: 0.141231\n",
      "[530]\tvalid_0's auc: 0.870358\tvalid_0's binary_logloss: 0.141316\n",
      "[532]\tvalid_0's auc: 0.870348\tvalid_0's binary_logloss: 0.141349\n",
      "[534]\tvalid_0's auc: 0.870444\tvalid_0's binary_logloss: 0.141311\n",
      "[536]\tvalid_0's auc: 0.870326\tvalid_0's binary_logloss: 0.141403\n",
      "[538]\tvalid_0's auc: 0.870173\tvalid_0's binary_logloss: 0.141473\n",
      "[540]\tvalid_0's auc: 0.870343\tvalid_0's binary_logloss: 0.141433\n",
      "[542]\tvalid_0's auc: 0.870405\tvalid_0's binary_logloss: 0.141443\n",
      "[544]\tvalid_0's auc: 0.870504\tvalid_0's binary_logloss: 0.141401\n",
      "[546]\tvalid_0's auc: 0.870552\tvalid_0's binary_logloss: 0.141392\n",
      "[548]\tvalid_0's auc: 0.87059\tvalid_0's binary_logloss: 0.141356\n",
      "[550]\tvalid_0's auc: 0.870475\tvalid_0's binary_logloss: 0.14141\n",
      "[552]\tvalid_0's auc: 0.87065\tvalid_0's binary_logloss: 0.141379\n",
      "[554]\tvalid_0's auc: 0.870603\tvalid_0's binary_logloss: 0.141404\n",
      "[556]\tvalid_0's auc: 0.870592\tvalid_0's binary_logloss: 0.141404\n",
      "[558]\tvalid_0's auc: 0.870589\tvalid_0's binary_logloss: 0.14146\n",
      "[560]\tvalid_0's auc: 0.870487\tvalid_0's binary_logloss: 0.141546\n",
      "[562]\tvalid_0's auc: 0.870843\tvalid_0's binary_logloss: 0.141443\n",
      "[564]\tvalid_0's auc: 0.870981\tvalid_0's binary_logloss: 0.141398\n",
      "[566]\tvalid_0's auc: 0.870932\tvalid_0's binary_logloss: 0.14147\n",
      "[568]\tvalid_0's auc: 0.871071\tvalid_0's binary_logloss: 0.141434\n",
      "[570]\tvalid_0's auc: 0.87118\tvalid_0's binary_logloss: 0.141433\n",
      "[572]\tvalid_0's auc: 0.871278\tvalid_0's binary_logloss: 0.141384\n",
      "[574]\tvalid_0's auc: 0.871318\tvalid_0's binary_logloss: 0.141354\n",
      "[576]\tvalid_0's auc: 0.871384\tvalid_0's binary_logloss: 0.141321\n",
      "[578]\tvalid_0's auc: 0.871544\tvalid_0's binary_logloss: 0.141275\n",
      "[580]\tvalid_0's auc: 0.871269\tvalid_0's binary_logloss: 0.141406\n",
      "[582]\tvalid_0's auc: 0.871528\tvalid_0's binary_logloss: 0.141348\n",
      "[584]\tvalid_0's auc: 0.87137\tvalid_0's binary_logloss: 0.141455\n",
      "[586]\tvalid_0's auc: 0.871392\tvalid_0's binary_logloss: 0.14148\n",
      "[588]\tvalid_0's auc: 0.871052\tvalid_0's binary_logloss: 0.141627\n",
      "[590]\tvalid_0's auc: 0.871163\tvalid_0's binary_logloss: 0.141632\n",
      "[592]\tvalid_0's auc: 0.871414\tvalid_0's binary_logloss: 0.141559\n",
      "[594]\tvalid_0's auc: 0.87132\tvalid_0's binary_logloss: 0.141623\n",
      "[596]\tvalid_0's auc: 0.871327\tvalid_0's binary_logloss: 0.141692\n",
      "[598]\tvalid_0's auc: 0.871316\tvalid_0's binary_logloss: 0.141727\n",
      "[600]\tvalid_0's auc: 0.87146\tvalid_0's binary_logloss: 0.141685\n",
      "[602]\tvalid_0's auc: 0.871505\tvalid_0's binary_logloss: 0.141689\n",
      "[604]\tvalid_0's auc: 0.871854\tvalid_0's binary_logloss: 0.141617\n",
      "[606]\tvalid_0's auc: 0.871779\tvalid_0's binary_logloss: 0.141717\n",
      "[608]\tvalid_0's auc: 0.871705\tvalid_0's binary_logloss: 0.141744\n",
      "[610]\tvalid_0's auc: 0.871816\tvalid_0's binary_logloss: 0.141721\n",
      "[612]\tvalid_0's auc: 0.871801\tvalid_0's binary_logloss: 0.14176\n",
      "[614]\tvalid_0's auc: 0.871815\tvalid_0's binary_logloss: 0.141752\n",
      "[616]\tvalid_0's auc: 0.871639\tvalid_0's binary_logloss: 0.141821\n",
      "[618]\tvalid_0's auc: 0.871584\tvalid_0's binary_logloss: 0.141836\n",
      "[620]\tvalid_0's auc: 0.871635\tvalid_0's binary_logloss: 0.141827\n",
      "[622]\tvalid_0's auc: 0.871672\tvalid_0's binary_logloss: 0.141825\n",
      "[624]\tvalid_0's auc: 0.871717\tvalid_0's binary_logloss: 0.141803\n",
      "[626]\tvalid_0's auc: 0.87177\tvalid_0's binary_logloss: 0.141814\n",
      "[628]\tvalid_0's auc: 0.871726\tvalid_0's binary_logloss: 0.141863\n",
      "[630]\tvalid_0's auc: 0.871654\tvalid_0's binary_logloss: 0.141909\n",
      "[632]\tvalid_0's auc: 0.871831\tvalid_0's binary_logloss: 0.141887\n",
      "[634]\tvalid_0's auc: 0.871771\tvalid_0's binary_logloss: 0.141925\n",
      "[636]\tvalid_0's auc: 0.871723\tvalid_0's binary_logloss: 0.141978\n",
      "[638]\tvalid_0's auc: 0.871588\tvalid_0's binary_logloss: 0.142037\n",
      "[640]\tvalid_0's auc: 0.871732\tvalid_0's binary_logloss: 0.141951\n",
      "[642]\tvalid_0's auc: 0.871708\tvalid_0's binary_logloss: 0.141969\n",
      "[644]\tvalid_0's auc: 0.871514\tvalid_0's binary_logloss: 0.142074\n",
      "[646]\tvalid_0's auc: 0.871674\tvalid_0's binary_logloss: 0.142027\n",
      "[648]\tvalid_0's auc: 0.871655\tvalid_0's binary_logloss: 0.142038\n",
      "[650]\tvalid_0's auc: 0.871676\tvalid_0's binary_logloss: 0.142053\n",
      "[652]\tvalid_0's auc: 0.871887\tvalid_0's binary_logloss: 0.141986\n",
      "[654]\tvalid_0's auc: 0.871807\tvalid_0's binary_logloss: 0.142014\n",
      "[656]\tvalid_0's auc: 0.871933\tvalid_0's binary_logloss: 0.142015\n",
      "[658]\tvalid_0's auc: 0.872207\tvalid_0's binary_logloss: 0.141944\n",
      "[660]\tvalid_0's auc: 0.872148\tvalid_0's binary_logloss: 0.141969\n",
      "[662]\tvalid_0's auc: 0.87219\tvalid_0's binary_logloss: 0.14196\n",
      "[664]\tvalid_0's auc: 0.872183\tvalid_0's binary_logloss: 0.141961\n",
      "[666]\tvalid_0's auc: 0.872061\tvalid_0's binary_logloss: 0.142\n",
      "[668]\tvalid_0's auc: 0.872117\tvalid_0's binary_logloss: 0.141997\n",
      "[670]\tvalid_0's auc: 0.872053\tvalid_0's binary_logloss: 0.142068\n",
      "[672]\tvalid_0's auc: 0.872191\tvalid_0's binary_logloss: 0.142014\n",
      "[674]\tvalid_0's auc: 0.872104\tvalid_0's binary_logloss: 0.14209\n",
      "[676]\tvalid_0's auc: 0.872091\tvalid_0's binary_logloss: 0.14209\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's auc: 0.871676\tvalid_0's binary_logloss: 0.141198\n"
     ]
    }
   ],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state=RAND):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 15000),\n",
    "        \"learning_rate\": trial.suggest_float(\"Learning_rate\", 0.001, 0.3),\n",
    "        \"random_state\": trial.suggest_categorical(\"random_state:\", [RAND]),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", [percent_of_negative_class])\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "        model = LGBMClassifier (**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric=\"auc\",\n",
    "                  early_stopping_rounds=100,\n",
    "                  callbacks=[pruning_callback],\n",
    "                  verbose=0)\n",
    "        \n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_predicts[idx] = roc_auc_score(y_test, preds[:,1])\n",
    "\n",
    "    return np.mean(cv_predicts)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LightGBM\")\n",
    "func = lambda trial: objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "\n",
    "study.optimize(func, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "lgb_grid = LGBMClassifier(**study.best_params)\n",
    "lgb_grid.fit(X_train_,\n",
    "             y_train_,\n",
    "             eval_metric=\"auc\",\n",
    "             eval_set=eval_set,\n",
    "             verbose=2,\n",
    "             early_stopping_rounds=100)\n",
    "\n",
    "y_pred = lgb_grid.predict(X_test)\n",
    "y_pred_prob = lgb_grid.predict_proba(X_test)\n",
    "metrics = get_metrics(y_test, y_pred, y_pred_prob, name='LightGBM_fitted')\n",
    "\n",
    "y_pred = lgb_grid.predict(X_train_)\n",
    "y_pred_prob = lgb_grid.predict_proba(X_train_)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_, y_pred, y_pred_prob, name='LightGBM_fitted_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f46c00fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 7329,\n",
       " 'Learning_rate': 0.17203026361943966,\n",
       " 'random_state:': 10,\n",
       " 'scale_pos_weight': 0.9528}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa8f1603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted</td>\n",
       "      <td>0.957349</td>\n",
       "      <td>0.869912</td>\n",
       "      <td>0.676152</td>\n",
       "      <td>0.179626</td>\n",
       "      <td>0.283845</td>\n",
       "      <td>0.138004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted_train</td>\n",
       "      <td>0.982490</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.635827</td>\n",
       "      <td>0.773887</td>\n",
       "      <td>0.054545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0        LightGBM_fitted  0.957349  0.869912   0.676152  0.179626  0.283845   \n",
       "0  LightGBM_fitted_train  0.982490  0.992391   0.988532  0.635827  0.773887   \n",
       "\n",
       "    Logloss  \n",
       "0  0.138004  \n",
       "0  0.054545  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff28a07",
   "metadata": {},
   "source": [
    "Видим на этом этапе переобучение, но это не критично, т.к. мы ещё не задействовали ни одного регуляризатора. Подберём другие гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae1928",
   "metadata": {},
   "source": [
    "## num_leaves, max_depth, min_data_in_leaf, lambda_l1, lambda_l2, bagging_fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266b2dd",
   "metadata": {},
   "source": [
    "- max_depth - максимальная глубина базовых деревьев\n",
    "- num_leaves - количество листьев в одном дереве\n",
    "- min_data_in_leaf - минимальное количество объектов, которые должны попасть в узел дерева для его добавления\n",
    "- lambda_l1 – коэффициент для L1 регулиризации\n",
    "- lambda_l2 – коэффициент для L2 регулиризации\n",
    "- bagging_fraction - указывает процент train выборок, которые будут использоваться для обучения каждого дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6672cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 15:16:40,686]\u001b[0m A new study created in memory with name: LightGBM\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11a80741294471a1099973181b1f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=68035, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4645074558216473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4645074558216473\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68035, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4645074558216473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4645074558216473\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68035, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4645074558216473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4645074558216473\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68035, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4645074558216473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4645074558216473\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=68035, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=68035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4645074558216473, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4645074558216473\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "\u001b[32m[I 2022-09-15 15:16:41,630]\u001b[0m Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 75, 'max_depth': 8, 'min_data_in_leaf': 68035, 'lambda_l1': 85, 'lambda_l2': 95, 'bagging_fraction': 0.4645074558216473}. Best is trial 0 with value: 0.5.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35395, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4941054926528827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4941054926528827\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=64, reg_lambda=0.0 will be ignored. Current value: lambda_l2=64\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35395, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4941054926528827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4941054926528827\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=64, reg_lambda=0.0 will be ignored. Current value: lambda_l2=64\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35395, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4941054926528827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4941054926528827\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=64, reg_lambda=0.0 will be ignored. Current value: lambda_l2=64\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35395, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4941054926528827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4941054926528827\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=64, reg_lambda=0.0 will be ignored. Current value: lambda_l2=64\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35395, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35395\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4941054926528827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4941054926528827\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=64, reg_lambda=0.0 will be ignored. Current value: lambda_l2=64\n",
      "\u001b[32m[I 2022-09-15 15:16:44,201]\u001b[0m Trial 1 finished with value: 0.6201707025320428 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 3947, 'max_depth': 9, 'min_data_in_leaf': 35395, 'lambda_l1': 45, 'lambda_l2': 64, 'bagging_fraction': 0.4941054926528827}. Best is trial 1 with value: 0.6201707025320428.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73090, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73090\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6703513980034435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703513980034435\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=82, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73090, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73090\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6703513980034435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703513980034435\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=82, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73090, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73090\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6703513980034435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703513980034435\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=82, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73090, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73090\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6703513980034435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703513980034435\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=82, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73090, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73090\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6703513980034435, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6703513980034435\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] lambda_l2 is set=82, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82\n",
      "\u001b[32m[I 2022-09-15 15:16:45,269]\u001b[0m Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 310, 'max_depth': 4, 'min_data_in_leaf': 73090, 'lambda_l1': 6, 'lambda_l2': 82, 'bagging_fraction': 0.6703513980034435}. Best is trial 1 with value: 0.6201707025320428.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3375993049329612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3375993049329612\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] lambda_l2 is set=74, reg_lambda=0.0 will be ignored. Current value: lambda_l2=74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=99398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3375993049329612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3375993049329612\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] lambda_l2 is set=74, reg_lambda=0.0 will be ignored. Current value: lambda_l2=74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3375993049329612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3375993049329612\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] lambda_l2 is set=74, reg_lambda=0.0 will be ignored. Current value: lambda_l2=74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3375993049329612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3375993049329612\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] lambda_l2 is set=74, reg_lambda=0.0 will be ignored. Current value: lambda_l2=74\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99398, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3375993049329612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3375993049329612\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] lambda_l2 is set=74, reg_lambda=0.0 will be ignored. Current value: lambda_l2=74\n",
      "\u001b[32m[I 2022-09-15 15:16:46,206]\u001b[0m Trial 3 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 982, 'max_depth': 8, 'min_data_in_leaf': 99398, 'lambda_l1': 9, 'lambda_l2': 74, 'bagging_fraction': 0.3375993049329612}. Best is trial 1 with value: 0.6201707025320428.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23966, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5198070005752842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5198070005752842\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23966, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5198070005752842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5198070005752842\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23966, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5198070005752842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5198070005752842\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23966, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5198070005752842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5198070005752842\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23966, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5198070005752842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5198070005752842\n",
      "[LightGBM] [Warning] lambda_l1 is set=2, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "\u001b[32m[I 2022-09-15 15:17:32,656]\u001b[0m Trial 4 finished with value: 0.7047859357105766 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 2961, 'max_depth': 5, 'min_data_in_leaf': 23966, 'lambda_l1': 2, 'lambda_l2': 16, 'bagging_fraction': 0.5198070005752842}. Best is trial 4 with value: 0.7047859357105766.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55456, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2792026319587183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2792026319587183\n",
      "[LightGBM] [Warning] lambda_l1 is set=44, reg_alpha=0.0 will be ignored. Current value: lambda_l1=44\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55456, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2792026319587183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2792026319587183\n",
      "[LightGBM] [Warning] lambda_l1 is set=44, reg_alpha=0.0 will be ignored. Current value: lambda_l1=44\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55456, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2792026319587183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2792026319587183\n",
      "[LightGBM] [Warning] lambda_l1 is set=44, reg_alpha=0.0 will be ignored. Current value: lambda_l1=44\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55456, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2792026319587183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2792026319587183\n",
      "[LightGBM] [Warning] lambda_l1 is set=44, reg_alpha=0.0 will be ignored. Current value: lambda_l1=44\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55456, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55456\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2792026319587183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2792026319587183\n",
      "[LightGBM] [Warning] lambda_l1 is set=44, reg_alpha=0.0 will be ignored. Current value: lambda_l1=44\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "\u001b[32m[I 2022-09-15 15:17:33,650]\u001b[0m Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 411, 'max_depth': 9, 'min_data_in_leaf': 55456, 'lambda_l1': 44, 'lambda_l2': 4, 'bagging_fraction': 0.2792026319587183}. Best is trial 4 with value: 0.7047859357105766.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57674, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57674\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43162928697065517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43162928697065517\n",
      "[LightGBM] [Warning] lambda_l1 is set=84, reg_alpha=0.0 will be ignored. Current value: lambda_l1=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=72, reg_lambda=0.0 will be ignored. Current value: lambda_l2=72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=57674, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57674\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43162928697065517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43162928697065517\n",
      "[LightGBM] [Warning] lambda_l1 is set=84, reg_alpha=0.0 will be ignored. Current value: lambda_l1=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=72, reg_lambda=0.0 will be ignored. Current value: lambda_l2=72\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57674, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57674\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43162928697065517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43162928697065517\n",
      "[LightGBM] [Warning] lambda_l1 is set=84, reg_alpha=0.0 will be ignored. Current value: lambda_l1=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=72, reg_lambda=0.0 will be ignored. Current value: lambda_l2=72\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57674, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57674\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43162928697065517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43162928697065517\n",
      "[LightGBM] [Warning] lambda_l1 is set=84, reg_alpha=0.0 will be ignored. Current value: lambda_l1=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=72, reg_lambda=0.0 will be ignored. Current value: lambda_l2=72\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=57674, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=57674\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43162928697065517, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43162928697065517\n",
      "[LightGBM] [Warning] lambda_l1 is set=84, reg_alpha=0.0 will be ignored. Current value: lambda_l1=84\n",
      "[LightGBM] [Warning] lambda_l2 is set=72, reg_lambda=0.0 will be ignored. Current value: lambda_l2=72\n",
      "\u001b[32m[I 2022-09-15 15:17:34,618]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1669, 'max_depth': 9, 'min_data_in_leaf': 57674, 'lambda_l1': 84, 'lambda_l2': 72, 'bagging_fraction': 0.43162928697065517}. Best is trial 4 with value: 0.7047859357105766.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5366149427145894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5366149427145894\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5366149427145894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5366149427145894\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5366149427145894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5366149427145894\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5366149427145894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5366149427145894\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=91296, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=91296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5366149427145894, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5366149427145894\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "\u001b[32m[I 2022-09-15 15:17:35,585]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 2019, 'max_depth': 9, 'min_data_in_leaf': 91296, 'lambda_l1': 3, 'lambda_l2': 15, 'bagging_fraction': 0.5366149427145894}. Best is trial 4 with value: 0.7047859357105766.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55539, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42637609185332037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42637609185332037\n",
      "[LightGBM] [Warning] lambda_l1 is set=92, reg_alpha=0.0 will be ignored. Current value: lambda_l1=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=86, reg_lambda=0.0 will be ignored. Current value: lambda_l2=86\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55539, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42637609185332037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42637609185332037\n",
      "[LightGBM] [Warning] lambda_l1 is set=92, reg_alpha=0.0 will be ignored. Current value: lambda_l1=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=86, reg_lambda=0.0 will be ignored. Current value: lambda_l2=86\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55539, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42637609185332037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42637609185332037\n",
      "[LightGBM] [Warning] lambda_l1 is set=92, reg_alpha=0.0 will be ignored. Current value: lambda_l1=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=86, reg_lambda=0.0 will be ignored. Current value: lambda_l2=86\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55539, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42637609185332037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42637609185332037\n",
      "[LightGBM] [Warning] lambda_l1 is set=92, reg_alpha=0.0 will be ignored. Current value: lambda_l1=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=86, reg_lambda=0.0 will be ignored. Current value: lambda_l2=86\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=55539, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=55539\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42637609185332037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42637609185332037\n",
      "[LightGBM] [Warning] lambda_l1 is set=92, reg_alpha=0.0 will be ignored. Current value: lambda_l1=92\n",
      "[LightGBM] [Warning] lambda_l2 is set=86, reg_lambda=0.0 will be ignored. Current value: lambda_l2=86\n",
      "\u001b[32m[I 2022-09-15 15:17:36,528]\u001b[0m Trial 8 finished with value: 0.5 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 182, 'max_depth': 5, 'min_data_in_leaf': 55539, 'lambda_l1': 92, 'lambda_l2': 86, 'bagging_fraction': 0.42637609185332037}. Best is trial 4 with value: 0.7047859357105766.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15347, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.673041997429236, subsample=1.0 will be ignored. Current value: bagging_fraction=0.673041997429236\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15347, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.673041997429236, subsample=1.0 will be ignored. Current value: bagging_fraction=0.673041997429236\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15347, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.673041997429236, subsample=1.0 will be ignored. Current value: bagging_fraction=0.673041997429236\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15347, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.673041997429236, subsample=1.0 will be ignored. Current value: bagging_fraction=0.673041997429236\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=73\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15347, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15347\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.673041997429236, subsample=1.0 will be ignored. Current value: bagging_fraction=0.673041997429236\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=73, reg_lambda=0.0 will be ignored. Current value: lambda_l2=73\n",
      "\u001b[32m[I 2022-09-15 15:20:26,045]\u001b[0m Trial 9 finished with value: 0.8268206845673447 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1073, 'max_depth': 9, 'min_data_in_leaf': 15347, 'lambda_l1': 3, 'lambda_l2': 73, 'bagging_fraction': 0.673041997429236}. Best is trial 9 with value: 0.8268206845673447.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1073, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9650558888513634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9650558888513634\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=39, reg_lambda=0.0 will be ignored. Current value: lambda_l2=39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1073, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9650558888513634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9650558888513634\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=39, reg_lambda=0.0 will be ignored. Current value: lambda_l2=39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1073, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9650558888513634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9650558888513634\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=39, reg_lambda=0.0 will be ignored. Current value: lambda_l2=39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1073, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9650558888513634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9650558888513634\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=39, reg_lambda=0.0 will be ignored. Current value: lambda_l2=39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1073, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9650558888513634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9650558888513634\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=39, reg_lambda=0.0 will be ignored. Current value: lambda_l2=39\n",
      "\u001b[32m[I 2022-09-15 15:20:30,310]\u001b[0m Trial 10 finished with value: 0.8056622382853279 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1260, 'max_depth': 12, 'min_data_in_leaf': 1073, 'lambda_l1': 27, 'lambda_l2': 39, 'bagging_fraction': 0.9650558888513634}. Best is trial 9 with value: 0.8268206845673447.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943814120757293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943814120757293\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=48, reg_lambda=0.0 will be ignored. Current value: lambda_l2=48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943814120757293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943814120757293\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=48, reg_lambda=0.0 will be ignored. Current value: lambda_l2=48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943814120757293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943814120757293\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=48, reg_lambda=0.0 will be ignored. Current value: lambda_l2=48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943814120757293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943814120757293\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=48, reg_lambda=0.0 will be ignored. Current value: lambda_l2=48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2997, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2997\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8943814120757293, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8943814120757293\n",
      "[LightGBM] [Warning] lambda_l1 is set=27, reg_alpha=0.0 will be ignored. Current value: lambda_l1=27\n",
      "[LightGBM] [Warning] lambda_l2 is set=48, reg_lambda=0.0 will be ignored. Current value: lambda_l2=48\n",
      "\u001b[32m[I 2022-09-15 15:20:34,924]\u001b[0m Trial 11 finished with value: 0.8059604435612092 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1220, 'max_depth': 12, 'min_data_in_leaf': 2997, 'lambda_l1': 27, 'lambda_l2': 48, 'bagging_fraction': 0.8943814120757293}. Best is trial 9 with value: 0.8268206845673447.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3780, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3780\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186263937009877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186263937009877\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] lambda_l2 is set=49, reg_lambda=0.0 will be ignored. Current value: lambda_l2=49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3780, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3780\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186263937009877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186263937009877\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] lambda_l2 is set=49, reg_lambda=0.0 will be ignored. Current value: lambda_l2=49\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3780, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3780\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186263937009877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186263937009877\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] lambda_l2 is set=49, reg_lambda=0.0 will be ignored. Current value: lambda_l2=49\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3780, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3780\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186263937009877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186263937009877\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] lambda_l2 is set=49, reg_lambda=0.0 will be ignored. Current value: lambda_l2=49\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3780, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3780\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8186263937009877, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8186263937009877\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] lambda_l2 is set=49, reg_lambda=0.0 will be ignored. Current value: lambda_l2=49\n",
      "\u001b[32m[I 2022-09-15 15:20:39,757]\u001b[0m Trial 12 finished with value: 0.8125108662830133 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1101, 'max_depth': 12, 'min_data_in_leaf': 3780, 'lambda_l1': 25, 'lambda_l2': 49, 'bagging_fraction': 0.8186263937009877}. Best is trial 9 with value: 0.8268206845673447.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20440, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20440\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7811295647977446, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7811295647977446\n",
      "[LightGBM] [Warning] lambda_l1 is set=23, reg_alpha=0.0 will be ignored. Current value: lambda_l1=23\n",
      "[LightGBM] [Warning] lambda_l2 is set=37, reg_lambda=0.0 will be ignored. Current value: lambda_l2=37\n",
      "\u001b[32m[I 2022-09-15 15:20:40,150]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 15:20:40,541]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 15:20:40,870]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 15:20:41,309]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 15:20:41,607]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "\u001b[32m[I 2022-09-15 15:20:52,791]\u001b[0m Trial 18 finished with value: 0.8328108289869839 and parameters: {'n_estimators': 7329, 'Learning_rate': 0.17, 'random_state:': 10, 'scale_pos_weight': 0.9528, 'num_leaves': 1480, 'max_depth': 10, 'min_data_in_leaf': 6735, 'lambda_l1': 16, 'lambda_l2': 97, 'bagging_fraction': 0.6322273209124994}. Best is trial 18 with value: 0.8328108289869839.\u001b[0m\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28613, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28613\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6194951544214886, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6194951544214886\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "\u001b[32m[I 2022-09-15 15:20:53,151]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 101.\u001b[0m\n",
      "Training until validation scores don't improve for 70 rounds\n",
      "[2]\tvalid_0's auc: 0.701467\tvalid_0's binary_logloss: 0.193283\n",
      "[4]\tvalid_0's auc: 0.717912\tvalid_0's binary_logloss: 0.190573\n",
      "[6]\tvalid_0's auc: 0.723607\tvalid_0's binary_logloss: 0.188552\n",
      "[8]\tvalid_0's auc: 0.729185\tvalid_0's binary_logloss: 0.18693\n",
      "[10]\tvalid_0's auc: 0.733816\tvalid_0's binary_logloss: 0.185471\n",
      "[12]\tvalid_0's auc: 0.73713\tvalid_0's binary_logloss: 0.184217\n",
      "[14]\tvalid_0's auc: 0.739469\tvalid_0's binary_logloss: 0.18317\n",
      "[16]\tvalid_0's auc: 0.742309\tvalid_0's binary_logloss: 0.182157\n",
      "[18]\tvalid_0's auc: 0.744356\tvalid_0's binary_logloss: 0.181265\n",
      "[20]\tvalid_0's auc: 0.747533\tvalid_0's binary_logloss: 0.180338\n",
      "[22]\tvalid_0's auc: 0.751726\tvalid_0's binary_logloss: 0.179398\n",
      "[24]\tvalid_0's auc: 0.755976\tvalid_0's binary_logloss: 0.178456\n",
      "[26]\tvalid_0's auc: 0.759202\tvalid_0's binary_logloss: 0.177664\n",
      "[28]\tvalid_0's auc: 0.760825\tvalid_0's binary_logloss: 0.177083\n",
      "[30]\tvalid_0's auc: 0.762506\tvalid_0's binary_logloss: 0.176612\n",
      "[32]\tvalid_0's auc: 0.763304\tvalid_0's binary_logloss: 0.176297\n",
      "[34]\tvalid_0's auc: 0.764263\tvalid_0's binary_logloss: 0.175898\n",
      "[36]\tvalid_0's auc: 0.766358\tvalid_0's binary_logloss: 0.175437\n",
      "[38]\tvalid_0's auc: 0.767078\tvalid_0's binary_logloss: 0.175127\n",
      "[40]\tvalid_0's auc: 0.767779\tvalid_0's binary_logloss: 0.174857\n",
      "[42]\tvalid_0's auc: 0.769\tvalid_0's binary_logloss: 0.174578\n",
      "[44]\tvalid_0's auc: 0.769958\tvalid_0's binary_logloss: 0.174302\n",
      "[46]\tvalid_0's auc: 0.771124\tvalid_0's binary_logloss: 0.173967\n",
      "[48]\tvalid_0's auc: 0.771647\tvalid_0's binary_logloss: 0.173785\n",
      "[50]\tvalid_0's auc: 0.772284\tvalid_0's binary_logloss: 0.173657\n",
      "[52]\tvalid_0's auc: 0.773085\tvalid_0's binary_logloss: 0.173417\n",
      "[54]\tvalid_0's auc: 0.774\tvalid_0's binary_logloss: 0.173208\n",
      "[56]\tvalid_0's auc: 0.774344\tvalid_0's binary_logloss: 0.173057\n",
      "[58]\tvalid_0's auc: 0.774579\tvalid_0's binary_logloss: 0.172955\n",
      "[60]\tvalid_0's auc: 0.775416\tvalid_0's binary_logloss: 0.172717\n",
      "[62]\tvalid_0's auc: 0.776078\tvalid_0's binary_logloss: 0.172526\n",
      "[64]\tvalid_0's auc: 0.776649\tvalid_0's binary_logloss: 0.172332\n",
      "[66]\tvalid_0's auc: 0.777164\tvalid_0's binary_logloss: 0.172128\n",
      "[68]\tvalid_0's auc: 0.777727\tvalid_0's binary_logloss: 0.171969\n",
      "[70]\tvalid_0's auc: 0.7782\tvalid_0's binary_logloss: 0.171872\n",
      "[72]\tvalid_0's auc: 0.778792\tvalid_0's binary_logloss: 0.171691\n",
      "[74]\tvalid_0's auc: 0.779316\tvalid_0's binary_logloss: 0.171534\n",
      "[76]\tvalid_0's auc: 0.780156\tvalid_0's binary_logloss: 0.171347\n",
      "[78]\tvalid_0's auc: 0.780467\tvalid_0's binary_logloss: 0.171236\n",
      "[80]\tvalid_0's auc: 0.781359\tvalid_0's binary_logloss: 0.171018\n",
      "[82]\tvalid_0's auc: 0.781438\tvalid_0's binary_logloss: 0.170959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84]\tvalid_0's auc: 0.782021\tvalid_0's binary_logloss: 0.170807\n",
      "[86]\tvalid_0's auc: 0.782322\tvalid_0's binary_logloss: 0.170701\n",
      "[88]\tvalid_0's auc: 0.783204\tvalid_0's binary_logloss: 0.170468\n",
      "[90]\tvalid_0's auc: 0.783546\tvalid_0's binary_logloss: 0.170328\n",
      "[92]\tvalid_0's auc: 0.7839\tvalid_0's binary_logloss: 0.170208\n",
      "[94]\tvalid_0's auc: 0.784011\tvalid_0's binary_logloss: 0.170137\n",
      "[96]\tvalid_0's auc: 0.784849\tvalid_0's binary_logloss: 0.169945\n",
      "[98]\tvalid_0's auc: 0.785375\tvalid_0's binary_logloss: 0.169809\n",
      "[100]\tvalid_0's auc: 0.786362\tvalid_0's binary_logloss: 0.16958\n",
      "[102]\tvalid_0's auc: 0.787282\tvalid_0's binary_logloss: 0.169376\n",
      "[104]\tvalid_0's auc: 0.787701\tvalid_0's binary_logloss: 0.169267\n",
      "[106]\tvalid_0's auc: 0.787971\tvalid_0's binary_logloss: 0.169187\n",
      "[108]\tvalid_0's auc: 0.788555\tvalid_0's binary_logloss: 0.169035\n",
      "[110]\tvalid_0's auc: 0.789263\tvalid_0's binary_logloss: 0.16888\n",
      "[112]\tvalid_0's auc: 0.789585\tvalid_0's binary_logloss: 0.168792\n",
      "[114]\tvalid_0's auc: 0.790093\tvalid_0's binary_logloss: 0.168678\n",
      "[116]\tvalid_0's auc: 0.790621\tvalid_0's binary_logloss: 0.168548\n",
      "[118]\tvalid_0's auc: 0.790858\tvalid_0's binary_logloss: 0.168465\n",
      "[120]\tvalid_0's auc: 0.791293\tvalid_0's binary_logloss: 0.168354\n",
      "[122]\tvalid_0's auc: 0.791567\tvalid_0's binary_logloss: 0.168288\n",
      "[124]\tvalid_0's auc: 0.791851\tvalid_0's binary_logloss: 0.168227\n",
      "[126]\tvalid_0's auc: 0.792169\tvalid_0's binary_logloss: 0.168168\n",
      "[128]\tvalid_0's auc: 0.792435\tvalid_0's binary_logloss: 0.168093\n",
      "[130]\tvalid_0's auc: 0.793035\tvalid_0's binary_logloss: 0.167955\n",
      "[132]\tvalid_0's auc: 0.793352\tvalid_0's binary_logloss: 0.167865\n",
      "[134]\tvalid_0's auc: 0.79407\tvalid_0's binary_logloss: 0.167744\n",
      "[136]\tvalid_0's auc: 0.794467\tvalid_0's binary_logloss: 0.167633\n",
      "[138]\tvalid_0's auc: 0.795094\tvalid_0's binary_logloss: 0.167503\n",
      "[140]\tvalid_0's auc: 0.795378\tvalid_0's binary_logloss: 0.167442\n",
      "[142]\tvalid_0's auc: 0.795845\tvalid_0's binary_logloss: 0.167345\n",
      "[144]\tvalid_0's auc: 0.796272\tvalid_0's binary_logloss: 0.167226\n",
      "[146]\tvalid_0's auc: 0.796657\tvalid_0's binary_logloss: 0.167138\n",
      "[148]\tvalid_0's auc: 0.797014\tvalid_0's binary_logloss: 0.167053\n",
      "[150]\tvalid_0's auc: 0.797273\tvalid_0's binary_logloss: 0.166984\n",
      "[152]\tvalid_0's auc: 0.797644\tvalid_0's binary_logloss: 0.166913\n",
      "[154]\tvalid_0's auc: 0.798032\tvalid_0's binary_logloss: 0.166814\n",
      "[156]\tvalid_0's auc: 0.798437\tvalid_0's binary_logloss: 0.166738\n",
      "[158]\tvalid_0's auc: 0.798526\tvalid_0's binary_logloss: 0.166696\n",
      "[160]\tvalid_0's auc: 0.798896\tvalid_0's binary_logloss: 0.166606\n",
      "[162]\tvalid_0's auc: 0.799224\tvalid_0's binary_logloss: 0.166523\n",
      "[164]\tvalid_0's auc: 0.799589\tvalid_0's binary_logloss: 0.16644\n",
      "[166]\tvalid_0's auc: 0.799639\tvalid_0's binary_logloss: 0.166391\n",
      "[168]\tvalid_0's auc: 0.800196\tvalid_0's binary_logloss: 0.166239\n",
      "[170]\tvalid_0's auc: 0.800452\tvalid_0's binary_logloss: 0.166179\n",
      "[172]\tvalid_0's auc: 0.800713\tvalid_0's binary_logloss: 0.166115\n",
      "[174]\tvalid_0's auc: 0.800897\tvalid_0's binary_logloss: 0.166076\n",
      "[176]\tvalid_0's auc: 0.80109\tvalid_0's binary_logloss: 0.166029\n",
      "[178]\tvalid_0's auc: 0.801457\tvalid_0's binary_logloss: 0.165949\n",
      "[180]\tvalid_0's auc: 0.80166\tvalid_0's binary_logloss: 0.165898\n",
      "[182]\tvalid_0's auc: 0.802007\tvalid_0's binary_logloss: 0.165815\n",
      "[184]\tvalid_0's auc: 0.802354\tvalid_0's binary_logloss: 0.165755\n",
      "[186]\tvalid_0's auc: 0.802551\tvalid_0's binary_logloss: 0.165721\n",
      "[188]\tvalid_0's auc: 0.802576\tvalid_0's binary_logloss: 0.165672\n",
      "[190]\tvalid_0's auc: 0.802719\tvalid_0's binary_logloss: 0.165626\n",
      "[192]\tvalid_0's auc: 0.80302\tvalid_0's binary_logloss: 0.165571\n",
      "[194]\tvalid_0's auc: 0.803231\tvalid_0's binary_logloss: 0.165491\n",
      "[196]\tvalid_0's auc: 0.803283\tvalid_0's binary_logloss: 0.165468\n",
      "[198]\tvalid_0's auc: 0.803693\tvalid_0's binary_logloss: 0.165376\n",
      "[200]\tvalid_0's auc: 0.803765\tvalid_0's binary_logloss: 0.165344\n",
      "[202]\tvalid_0's auc: 0.803832\tvalid_0's binary_logloss: 0.165296\n",
      "[204]\tvalid_0's auc: 0.804311\tvalid_0's binary_logloss: 0.165208\n",
      "[206]\tvalid_0's auc: 0.804512\tvalid_0's binary_logloss: 0.165157\n",
      "[208]\tvalid_0's auc: 0.805135\tvalid_0's binary_logloss: 0.165039\n",
      "[210]\tvalid_0's auc: 0.80535\tvalid_0's binary_logloss: 0.164954\n",
      "[212]\tvalid_0's auc: 0.80545\tvalid_0's binary_logloss: 0.164919\n",
      "[214]\tvalid_0's auc: 0.805661\tvalid_0's binary_logloss: 0.164871\n",
      "[216]\tvalid_0's auc: 0.805906\tvalid_0's binary_logloss: 0.164797\n",
      "[218]\tvalid_0's auc: 0.80632\tvalid_0's binary_logloss: 0.164668\n",
      "[220]\tvalid_0's auc: 0.806587\tvalid_0's binary_logloss: 0.164588\n",
      "[222]\tvalid_0's auc: 0.807\tvalid_0's binary_logloss: 0.164486\n",
      "[224]\tvalid_0's auc: 0.807055\tvalid_0's binary_logloss: 0.164455\n",
      "[226]\tvalid_0's auc: 0.807345\tvalid_0's binary_logloss: 0.164384\n",
      "[228]\tvalid_0's auc: 0.807538\tvalid_0's binary_logloss: 0.164309\n",
      "[230]\tvalid_0's auc: 0.807828\tvalid_0's binary_logloss: 0.164223\n",
      "[232]\tvalid_0's auc: 0.808117\tvalid_0's binary_logloss: 0.164173\n",
      "[234]\tvalid_0's auc: 0.808041\tvalid_0's binary_logloss: 0.164152\n",
      "[236]\tvalid_0's auc: 0.808441\tvalid_0's binary_logloss: 0.164065\n",
      "[238]\tvalid_0's auc: 0.808735\tvalid_0's binary_logloss: 0.163991\n",
      "[240]\tvalid_0's auc: 0.809049\tvalid_0's binary_logloss: 0.163909\n",
      "[242]\tvalid_0's auc: 0.809357\tvalid_0's binary_logloss: 0.163846\n",
      "[244]\tvalid_0's auc: 0.809477\tvalid_0's binary_logloss: 0.163806\n",
      "[246]\tvalid_0's auc: 0.809716\tvalid_0's binary_logloss: 0.163717\n",
      "[248]\tvalid_0's auc: 0.80991\tvalid_0's binary_logloss: 0.163671\n",
      "[250]\tvalid_0's auc: 0.810402\tvalid_0's binary_logloss: 0.163562\n",
      "[252]\tvalid_0's auc: 0.810474\tvalid_0's binary_logloss: 0.163527\n",
      "[254]\tvalid_0's auc: 0.810922\tvalid_0's binary_logloss: 0.163428\n",
      "[256]\tvalid_0's auc: 0.811072\tvalid_0's binary_logloss: 0.163356\n",
      "[258]\tvalid_0's auc: 0.811394\tvalid_0's binary_logloss: 0.163278\n",
      "[260]\tvalid_0's auc: 0.81184\tvalid_0's binary_logloss: 0.163185\n",
      "[262]\tvalid_0's auc: 0.811977\tvalid_0's binary_logloss: 0.16313\n",
      "[264]\tvalid_0's auc: 0.812211\tvalid_0's binary_logloss: 0.163043\n",
      "[266]\tvalid_0's auc: 0.812192\tvalid_0's binary_logloss: 0.163033\n",
      "[268]\tvalid_0's auc: 0.812323\tvalid_0's binary_logloss: 0.162985\n",
      "[270]\tvalid_0's auc: 0.812725\tvalid_0's binary_logloss: 0.162894\n",
      "[272]\tvalid_0's auc: 0.812913\tvalid_0's binary_logloss: 0.162842\n",
      "[274]\tvalid_0's auc: 0.813006\tvalid_0's binary_logloss: 0.162806\n",
      "[276]\tvalid_0's auc: 0.813216\tvalid_0's binary_logloss: 0.162748\n",
      "[278]\tvalid_0's auc: 0.813482\tvalid_0's binary_logloss: 0.162674\n",
      "[280]\tvalid_0's auc: 0.813517\tvalid_0's binary_logloss: 0.162613\n",
      "[282]\tvalid_0's auc: 0.813642\tvalid_0's binary_logloss: 0.162567\n",
      "[284]\tvalid_0's auc: 0.813736\tvalid_0's binary_logloss: 0.16253\n",
      "[286]\tvalid_0's auc: 0.813983\tvalid_0's binary_logloss: 0.162449\n",
      "[288]\tvalid_0's auc: 0.814211\tvalid_0's binary_logloss: 0.162406\n",
      "[290]\tvalid_0's auc: 0.814215\tvalid_0's binary_logloss: 0.162374\n",
      "[292]\tvalid_0's auc: 0.814371\tvalid_0's binary_logloss: 0.162325\n",
      "[294]\tvalid_0's auc: 0.814509\tvalid_0's binary_logloss: 0.162287\n",
      "[296]\tvalid_0's auc: 0.814713\tvalid_0's binary_logloss: 0.162215\n",
      "[298]\tvalid_0's auc: 0.814903\tvalid_0's binary_logloss: 0.162146\n",
      "[300]\tvalid_0's auc: 0.815409\tvalid_0's binary_logloss: 0.162009\n",
      "[302]\tvalid_0's auc: 0.815729\tvalid_0's binary_logloss: 0.161952\n",
      "[304]\tvalid_0's auc: 0.816031\tvalid_0's binary_logloss: 0.161894\n",
      "[306]\tvalid_0's auc: 0.816157\tvalid_0's binary_logloss: 0.161848\n",
      "[308]\tvalid_0's auc: 0.816402\tvalid_0's binary_logloss: 0.161787\n",
      "[310]\tvalid_0's auc: 0.816495\tvalid_0's binary_logloss: 0.161721\n",
      "[312]\tvalid_0's auc: 0.816733\tvalid_0's binary_logloss: 0.161656\n",
      "[314]\tvalid_0's auc: 0.816819\tvalid_0's binary_logloss: 0.16163\n",
      "[316]\tvalid_0's auc: 0.816942\tvalid_0's binary_logloss: 0.161591\n",
      "[318]\tvalid_0's auc: 0.81707\tvalid_0's binary_logloss: 0.161551\n",
      "[320]\tvalid_0's auc: 0.817102\tvalid_0's binary_logloss: 0.161534\n",
      "[322]\tvalid_0's auc: 0.817179\tvalid_0's binary_logloss: 0.161491\n",
      "[324]\tvalid_0's auc: 0.817154\tvalid_0's binary_logloss: 0.161479\n",
      "[326]\tvalid_0's auc: 0.817202\tvalid_0's binary_logloss: 0.161439\n",
      "[328]\tvalid_0's auc: 0.817509\tvalid_0's binary_logloss: 0.161365\n",
      "[330]\tvalid_0's auc: 0.817803\tvalid_0's binary_logloss: 0.161284\n",
      "[332]\tvalid_0's auc: 0.817957\tvalid_0's binary_logloss: 0.161242\n",
      "[334]\tvalid_0's auc: 0.818036\tvalid_0's binary_logloss: 0.161227\n",
      "[336]\tvalid_0's auc: 0.81801\tvalid_0's binary_logloss: 0.161215\n",
      "[338]\tvalid_0's auc: 0.81809\tvalid_0's binary_logloss: 0.1612\n",
      "[340]\tvalid_0's auc: 0.818216\tvalid_0's binary_logloss: 0.161145\n",
      "[342]\tvalid_0's auc: 0.818413\tvalid_0's binary_logloss: 0.161093\n",
      "[344]\tvalid_0's auc: 0.818585\tvalid_0's binary_logloss: 0.16107\n",
      "[346]\tvalid_0's auc: 0.818535\tvalid_0's binary_logloss: 0.161069\n",
      "[348]\tvalid_0's auc: 0.818861\tvalid_0's binary_logloss: 0.160982\n",
      "[350]\tvalid_0's auc: 0.818971\tvalid_0's binary_logloss: 0.160958\n",
      "[352]\tvalid_0's auc: 0.819112\tvalid_0's binary_logloss: 0.160897\n",
      "[354]\tvalid_0's auc: 0.81913\tvalid_0's binary_logloss: 0.160866\n",
      "[356]\tvalid_0's auc: 0.819395\tvalid_0's binary_logloss: 0.160785\n",
      "[358]\tvalid_0's auc: 0.819391\tvalid_0's binary_logloss: 0.160773\n",
      "[360]\tvalid_0's auc: 0.819757\tvalid_0's binary_logloss: 0.160674\n",
      "[362]\tvalid_0's auc: 0.819836\tvalid_0's binary_logloss: 0.160632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[364]\tvalid_0's auc: 0.819897\tvalid_0's binary_logloss: 0.160597\n",
      "[366]\tvalid_0's auc: 0.820041\tvalid_0's binary_logloss: 0.16055\n",
      "[368]\tvalid_0's auc: 0.820068\tvalid_0's binary_logloss: 0.160516\n",
      "[370]\tvalid_0's auc: 0.820148\tvalid_0's binary_logloss: 0.160479\n",
      "[372]\tvalid_0's auc: 0.820449\tvalid_0's binary_logloss: 0.160413\n",
      "[374]\tvalid_0's auc: 0.820445\tvalid_0's binary_logloss: 0.160384\n",
      "[376]\tvalid_0's auc: 0.820815\tvalid_0's binary_logloss: 0.160293\n",
      "[378]\tvalid_0's auc: 0.820903\tvalid_0's binary_logloss: 0.160266\n",
      "[380]\tvalid_0's auc: 0.820984\tvalid_0's binary_logloss: 0.160222\n",
      "[382]\tvalid_0's auc: 0.821056\tvalid_0's binary_logloss: 0.160184\n",
      "[384]\tvalid_0's auc: 0.821195\tvalid_0's binary_logloss: 0.160141\n",
      "[386]\tvalid_0's auc: 0.821354\tvalid_0's binary_logloss: 0.160111\n",
      "[388]\tvalid_0's auc: 0.82162\tvalid_0's binary_logloss: 0.160052\n",
      "[390]\tvalid_0's auc: 0.821996\tvalid_0's binary_logloss: 0.159972\n",
      "[392]\tvalid_0's auc: 0.822245\tvalid_0's binary_logloss: 0.159909\n",
      "[394]\tvalid_0's auc: 0.822396\tvalid_0's binary_logloss: 0.159872\n",
      "[396]\tvalid_0's auc: 0.822499\tvalid_0's binary_logloss: 0.159827\n",
      "[398]\tvalid_0's auc: 0.822751\tvalid_0's binary_logloss: 0.159772\n",
      "[400]\tvalid_0's auc: 0.822887\tvalid_0's binary_logloss: 0.159724\n",
      "[402]\tvalid_0's auc: 0.822983\tvalid_0's binary_logloss: 0.159675\n",
      "[404]\tvalid_0's auc: 0.823296\tvalid_0's binary_logloss: 0.159588\n",
      "[406]\tvalid_0's auc: 0.823547\tvalid_0's binary_logloss: 0.159522\n",
      "[408]\tvalid_0's auc: 0.823779\tvalid_0's binary_logloss: 0.159482\n",
      "[410]\tvalid_0's auc: 0.823807\tvalid_0's binary_logloss: 0.159451\n",
      "[412]\tvalid_0's auc: 0.82397\tvalid_0's binary_logloss: 0.159394\n",
      "[414]\tvalid_0's auc: 0.824039\tvalid_0's binary_logloss: 0.159366\n",
      "[416]\tvalid_0's auc: 0.824226\tvalid_0's binary_logloss: 0.159318\n",
      "[418]\tvalid_0's auc: 0.824165\tvalid_0's binary_logloss: 0.159285\n",
      "[420]\tvalid_0's auc: 0.824277\tvalid_0's binary_logloss: 0.159218\n",
      "[422]\tvalid_0's auc: 0.824293\tvalid_0's binary_logloss: 0.15918\n",
      "[424]\tvalid_0's auc: 0.824481\tvalid_0's binary_logloss: 0.159137\n",
      "[426]\tvalid_0's auc: 0.824674\tvalid_0's binary_logloss: 0.159086\n",
      "[428]\tvalid_0's auc: 0.824769\tvalid_0's binary_logloss: 0.159049\n",
      "[430]\tvalid_0's auc: 0.824904\tvalid_0's binary_logloss: 0.158972\n",
      "[432]\tvalid_0's auc: 0.824913\tvalid_0's binary_logloss: 0.158959\n",
      "[434]\tvalid_0's auc: 0.825031\tvalid_0's binary_logloss: 0.158917\n",
      "[436]\tvalid_0's auc: 0.825119\tvalid_0's binary_logloss: 0.158868\n",
      "[438]\tvalid_0's auc: 0.825229\tvalid_0's binary_logloss: 0.158834\n",
      "[440]\tvalid_0's auc: 0.825357\tvalid_0's binary_logloss: 0.158775\n",
      "[442]\tvalid_0's auc: 0.825587\tvalid_0's binary_logloss: 0.158701\n",
      "[444]\tvalid_0's auc: 0.825809\tvalid_0's binary_logloss: 0.158653\n",
      "[446]\tvalid_0's auc: 0.825873\tvalid_0's binary_logloss: 0.158625\n",
      "[448]\tvalid_0's auc: 0.826022\tvalid_0's binary_logloss: 0.158597\n",
      "[450]\tvalid_0's auc: 0.82622\tvalid_0's binary_logloss: 0.15856\n",
      "[452]\tvalid_0's auc: 0.82628\tvalid_0's binary_logloss: 0.158527\n",
      "[454]\tvalid_0's auc: 0.826433\tvalid_0's binary_logloss: 0.158485\n",
      "[456]\tvalid_0's auc: 0.826528\tvalid_0's binary_logloss: 0.158434\n",
      "[458]\tvalid_0's auc: 0.826695\tvalid_0's binary_logloss: 0.158394\n",
      "[460]\tvalid_0's auc: 0.826771\tvalid_0's binary_logloss: 0.15836\n",
      "[462]\tvalid_0's auc: 0.826897\tvalid_0's binary_logloss: 0.158314\n",
      "[464]\tvalid_0's auc: 0.827061\tvalid_0's binary_logloss: 0.158265\n",
      "[466]\tvalid_0's auc: 0.827226\tvalid_0's binary_logloss: 0.158225\n",
      "[468]\tvalid_0's auc: 0.827368\tvalid_0's binary_logloss: 0.158183\n",
      "[470]\tvalid_0's auc: 0.82745\tvalid_0's binary_logloss: 0.158134\n",
      "[472]\tvalid_0's auc: 0.827467\tvalid_0's binary_logloss: 0.158112\n",
      "[474]\tvalid_0's auc: 0.827642\tvalid_0's binary_logloss: 0.158066\n",
      "[476]\tvalid_0's auc: 0.827784\tvalid_0's binary_logloss: 0.158013\n",
      "[478]\tvalid_0's auc: 0.827939\tvalid_0's binary_logloss: 0.157979\n",
      "[480]\tvalid_0's auc: 0.828099\tvalid_0's binary_logloss: 0.157938\n",
      "[482]\tvalid_0's auc: 0.828191\tvalid_0's binary_logloss: 0.157906\n",
      "[484]\tvalid_0's auc: 0.828277\tvalid_0's binary_logloss: 0.157896\n",
      "[486]\tvalid_0's auc: 0.8284\tvalid_0's binary_logloss: 0.157859\n",
      "[488]\tvalid_0's auc: 0.828453\tvalid_0's binary_logloss: 0.157822\n",
      "[490]\tvalid_0's auc: 0.828699\tvalid_0's binary_logloss: 0.157766\n",
      "[492]\tvalid_0's auc: 0.828809\tvalid_0's binary_logloss: 0.157734\n",
      "[494]\tvalid_0's auc: 0.828795\tvalid_0's binary_logloss: 0.157717\n",
      "[496]\tvalid_0's auc: 0.828825\tvalid_0's binary_logloss: 0.157687\n",
      "[498]\tvalid_0's auc: 0.828975\tvalid_0's binary_logloss: 0.157647\n",
      "[500]\tvalid_0's auc: 0.829102\tvalid_0's binary_logloss: 0.157604\n",
      "[502]\tvalid_0's auc: 0.829212\tvalid_0's binary_logloss: 0.157558\n",
      "[504]\tvalid_0's auc: 0.829227\tvalid_0's binary_logloss: 0.157535\n",
      "[506]\tvalid_0's auc: 0.829334\tvalid_0's binary_logloss: 0.1575\n",
      "[508]\tvalid_0's auc: 0.829403\tvalid_0's binary_logloss: 0.157452\n",
      "[510]\tvalid_0's auc: 0.829435\tvalid_0's binary_logloss: 0.157442\n",
      "[512]\tvalid_0's auc: 0.829562\tvalid_0's binary_logloss: 0.157391\n",
      "[514]\tvalid_0's auc: 0.829697\tvalid_0's binary_logloss: 0.157354\n",
      "[516]\tvalid_0's auc: 0.829715\tvalid_0's binary_logloss: 0.157344\n",
      "[518]\tvalid_0's auc: 0.829735\tvalid_0's binary_logloss: 0.157338\n",
      "[520]\tvalid_0's auc: 0.829733\tvalid_0's binary_logloss: 0.157317\n",
      "[522]\tvalid_0's auc: 0.82985\tvalid_0's binary_logloss: 0.157272\n",
      "[524]\tvalid_0's auc: 0.830043\tvalid_0's binary_logloss: 0.157192\n",
      "[526]\tvalid_0's auc: 0.830227\tvalid_0's binary_logloss: 0.157148\n",
      "[528]\tvalid_0's auc: 0.830231\tvalid_0's binary_logloss: 0.157135\n",
      "[530]\tvalid_0's auc: 0.830309\tvalid_0's binary_logloss: 0.15709\n",
      "[532]\tvalid_0's auc: 0.830424\tvalid_0's binary_logloss: 0.157061\n",
      "[534]\tvalid_0's auc: 0.830522\tvalid_0's binary_logloss: 0.157024\n",
      "[536]\tvalid_0's auc: 0.830613\tvalid_0's binary_logloss: 0.156995\n",
      "[538]\tvalid_0's auc: 0.830695\tvalid_0's binary_logloss: 0.156967\n",
      "[540]\tvalid_0's auc: 0.830672\tvalid_0's binary_logloss: 0.156957\n",
      "[542]\tvalid_0's auc: 0.830777\tvalid_0's binary_logloss: 0.156937\n",
      "[544]\tvalid_0's auc: 0.830829\tvalid_0's binary_logloss: 0.156908\n",
      "[546]\tvalid_0's auc: 0.830995\tvalid_0's binary_logloss: 0.156869\n",
      "[548]\tvalid_0's auc: 0.83104\tvalid_0's binary_logloss: 0.156841\n",
      "[550]\tvalid_0's auc: 0.831279\tvalid_0's binary_logloss: 0.156773\n",
      "[552]\tvalid_0's auc: 0.8313\tvalid_0's binary_logloss: 0.156746\n",
      "[554]\tvalid_0's auc: 0.831623\tvalid_0's binary_logloss: 0.156662\n",
      "[556]\tvalid_0's auc: 0.831814\tvalid_0's binary_logloss: 0.156602\n",
      "[558]\tvalid_0's auc: 0.831971\tvalid_0's binary_logloss: 0.15656\n",
      "[560]\tvalid_0's auc: 0.832093\tvalid_0's binary_logloss: 0.156524\n",
      "[562]\tvalid_0's auc: 0.832194\tvalid_0's binary_logloss: 0.156503\n",
      "[564]\tvalid_0's auc: 0.832262\tvalid_0's binary_logloss: 0.156486\n",
      "[566]\tvalid_0's auc: 0.832271\tvalid_0's binary_logloss: 0.156482\n",
      "[568]\tvalid_0's auc: 0.832279\tvalid_0's binary_logloss: 0.156472\n",
      "[570]\tvalid_0's auc: 0.832473\tvalid_0's binary_logloss: 0.156422\n",
      "[572]\tvalid_0's auc: 0.8325\tvalid_0's binary_logloss: 0.156413\n",
      "[574]\tvalid_0's auc: 0.832549\tvalid_0's binary_logloss: 0.156401\n",
      "[576]\tvalid_0's auc: 0.832566\tvalid_0's binary_logloss: 0.156399\n",
      "[578]\tvalid_0's auc: 0.832622\tvalid_0's binary_logloss: 0.156384\n",
      "[580]\tvalid_0's auc: 0.832624\tvalid_0's binary_logloss: 0.156343\n",
      "[582]\tvalid_0's auc: 0.832675\tvalid_0's binary_logloss: 0.156325\n",
      "[584]\tvalid_0's auc: 0.832667\tvalid_0's binary_logloss: 0.156312\n",
      "[586]\tvalid_0's auc: 0.83281\tvalid_0's binary_logloss: 0.156283\n",
      "[588]\tvalid_0's auc: 0.832806\tvalid_0's binary_logloss: 0.156279\n",
      "[590]\tvalid_0's auc: 0.832822\tvalid_0's binary_logloss: 0.156261\n",
      "[592]\tvalid_0's auc: 0.832835\tvalid_0's binary_logloss: 0.156249\n",
      "[594]\tvalid_0's auc: 0.832953\tvalid_0's binary_logloss: 0.156222\n",
      "[596]\tvalid_0's auc: 0.832986\tvalid_0's binary_logloss: 0.156205\n",
      "[598]\tvalid_0's auc: 0.83333\tvalid_0's binary_logloss: 0.156097\n",
      "[600]\tvalid_0's auc: 0.833582\tvalid_0's binary_logloss: 0.156028\n",
      "[602]\tvalid_0's auc: 0.833648\tvalid_0's binary_logloss: 0.156028\n",
      "[604]\tvalid_0's auc: 0.833621\tvalid_0's binary_logloss: 0.156025\n",
      "[606]\tvalid_0's auc: 0.833691\tvalid_0's binary_logloss: 0.156013\n",
      "[608]\tvalid_0's auc: 0.83372\tvalid_0's binary_logloss: 0.155999\n",
      "[610]\tvalid_0's auc: 0.833772\tvalid_0's binary_logloss: 0.155977\n",
      "[612]\tvalid_0's auc: 0.833774\tvalid_0's binary_logloss: 0.155961\n",
      "[614]\tvalid_0's auc: 0.833827\tvalid_0's binary_logloss: 0.155928\n",
      "[616]\tvalid_0's auc: 0.833832\tvalid_0's binary_logloss: 0.155909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[618]\tvalid_0's auc: 0.833922\tvalid_0's binary_logloss: 0.155885\n",
      "[620]\tvalid_0's auc: 0.834016\tvalid_0's binary_logloss: 0.155857\n",
      "[622]\tvalid_0's auc: 0.834152\tvalid_0's binary_logloss: 0.155836\n",
      "[624]\tvalid_0's auc: 0.834234\tvalid_0's binary_logloss: 0.155813\n",
      "[626]\tvalid_0's auc: 0.834249\tvalid_0's binary_logloss: 0.155797\n",
      "[628]\tvalid_0's auc: 0.834244\tvalid_0's binary_logloss: 0.155779\n",
      "[630]\tvalid_0's auc: 0.834315\tvalid_0's binary_logloss: 0.155766\n",
      "[632]\tvalid_0's auc: 0.834386\tvalid_0's binary_logloss: 0.155739\n",
      "[634]\tvalid_0's auc: 0.834402\tvalid_0's binary_logloss: 0.15572\n",
      "[636]\tvalid_0's auc: 0.834477\tvalid_0's binary_logloss: 0.155696\n",
      "[638]\tvalid_0's auc: 0.834517\tvalid_0's binary_logloss: 0.155684\n",
      "[640]\tvalid_0's auc: 0.834621\tvalid_0's binary_logloss: 0.155651\n",
      "[642]\tvalid_0's auc: 0.834707\tvalid_0's binary_logloss: 0.155616\n",
      "[644]\tvalid_0's auc: 0.834753\tvalid_0's binary_logloss: 0.155595\n",
      "[646]\tvalid_0's auc: 0.834848\tvalid_0's binary_logloss: 0.15557\n",
      "[648]\tvalid_0's auc: 0.834883\tvalid_0's binary_logloss: 0.15556\n",
      "[650]\tvalid_0's auc: 0.83492\tvalid_0's binary_logloss: 0.155525\n",
      "[652]\tvalid_0's auc: 0.835089\tvalid_0's binary_logloss: 0.155477\n",
      "[654]\tvalid_0's auc: 0.835137\tvalid_0's binary_logloss: 0.155463\n",
      "[656]\tvalid_0's auc: 0.83515\tvalid_0's binary_logloss: 0.155436\n",
      "[658]\tvalid_0's auc: 0.835215\tvalid_0's binary_logloss: 0.155422\n",
      "[660]\tvalid_0's auc: 0.83529\tvalid_0's binary_logloss: 0.155392\n",
      "[662]\tvalid_0's auc: 0.835281\tvalid_0's binary_logloss: 0.15537\n",
      "[664]\tvalid_0's auc: 0.835323\tvalid_0's binary_logloss: 0.155349\n",
      "[666]\tvalid_0's auc: 0.835371\tvalid_0's binary_logloss: 0.155336\n",
      "[668]\tvalid_0's auc: 0.835426\tvalid_0's binary_logloss: 0.155306\n",
      "[670]\tvalid_0's auc: 0.835389\tvalid_0's binary_logloss: 0.155306\n",
      "[672]\tvalid_0's auc: 0.835398\tvalid_0's binary_logloss: 0.155303\n",
      "[674]\tvalid_0's auc: 0.835461\tvalid_0's binary_logloss: 0.155279\n",
      "[676]\tvalid_0's auc: 0.835526\tvalid_0's binary_logloss: 0.155241\n",
      "[678]\tvalid_0's auc: 0.835621\tvalid_0's binary_logloss: 0.155216\n",
      "[680]\tvalid_0's auc: 0.835801\tvalid_0's binary_logloss: 0.155175\n",
      "[682]\tvalid_0's auc: 0.835916\tvalid_0's binary_logloss: 0.155147\n",
      "[684]\tvalid_0's auc: 0.836049\tvalid_0's binary_logloss: 0.155106\n",
      "[686]\tvalid_0's auc: 0.83612\tvalid_0's binary_logloss: 0.155083\n",
      "[688]\tvalid_0's auc: 0.836238\tvalid_0's binary_logloss: 0.155056\n",
      "[690]\tvalid_0's auc: 0.836388\tvalid_0's binary_logloss: 0.155026\n",
      "[692]\tvalid_0's auc: 0.836388\tvalid_0's binary_logloss: 0.155008\n",
      "[694]\tvalid_0's auc: 0.836378\tvalid_0's binary_logloss: 0.154997\n",
      "[696]\tvalid_0's auc: 0.836394\tvalid_0's binary_logloss: 0.154974\n",
      "[698]\tvalid_0's auc: 0.836416\tvalid_0's binary_logloss: 0.154962\n",
      "[700]\tvalid_0's auc: 0.83646\tvalid_0's binary_logloss: 0.154944\n",
      "[702]\tvalid_0's auc: 0.836381\tvalid_0's binary_logloss: 0.15495\n",
      "[704]\tvalid_0's auc: 0.836569\tvalid_0's binary_logloss: 0.154902\n",
      "[706]\tvalid_0's auc: 0.836701\tvalid_0's binary_logloss: 0.154858\n",
      "[708]\tvalid_0's auc: 0.836779\tvalid_0's binary_logloss: 0.154824\n",
      "[710]\tvalid_0's auc: 0.836851\tvalid_0's binary_logloss: 0.1548\n",
      "[712]\tvalid_0's auc: 0.836932\tvalid_0's binary_logloss: 0.154776\n",
      "[714]\tvalid_0's auc: 0.837027\tvalid_0's binary_logloss: 0.154752\n",
      "[716]\tvalid_0's auc: 0.837135\tvalid_0's binary_logloss: 0.154722\n",
      "[718]\tvalid_0's auc: 0.837172\tvalid_0's binary_logloss: 0.154705\n",
      "[720]\tvalid_0's auc: 0.837189\tvalid_0's binary_logloss: 0.154687\n",
      "[722]\tvalid_0's auc: 0.837161\tvalid_0's binary_logloss: 0.154685\n",
      "[724]\tvalid_0's auc: 0.837316\tvalid_0's binary_logloss: 0.154647\n",
      "[726]\tvalid_0's auc: 0.837342\tvalid_0's binary_logloss: 0.154623\n",
      "[728]\tvalid_0's auc: 0.837375\tvalid_0's binary_logloss: 0.154608\n",
      "[730]\tvalid_0's auc: 0.837545\tvalid_0's binary_logloss: 0.154571\n",
      "[732]\tvalid_0's auc: 0.837639\tvalid_0's binary_logloss: 0.154538\n",
      "[734]\tvalid_0's auc: 0.837708\tvalid_0's binary_logloss: 0.154517\n",
      "[736]\tvalid_0's auc: 0.837765\tvalid_0's binary_logloss: 0.154499\n",
      "[738]\tvalid_0's auc: 0.837806\tvalid_0's binary_logloss: 0.154478\n",
      "[740]\tvalid_0's auc: 0.837868\tvalid_0's binary_logloss: 0.15445\n",
      "[742]\tvalid_0's auc: 0.837876\tvalid_0's binary_logloss: 0.154433\n",
      "[744]\tvalid_0's auc: 0.83794\tvalid_0's binary_logloss: 0.154408\n",
      "[746]\tvalid_0's auc: 0.837948\tvalid_0's binary_logloss: 0.154401\n",
      "[748]\tvalid_0's auc: 0.837988\tvalid_0's binary_logloss: 0.154383\n",
      "[750]\tvalid_0's auc: 0.838089\tvalid_0's binary_logloss: 0.154338\n",
      "[752]\tvalid_0's auc: 0.838071\tvalid_0's binary_logloss: 0.154334\n",
      "[754]\tvalid_0's auc: 0.838039\tvalid_0's binary_logloss: 0.154339\n",
      "[756]\tvalid_0's auc: 0.838006\tvalid_0's binary_logloss: 0.154338\n",
      "[758]\tvalid_0's auc: 0.838029\tvalid_0's binary_logloss: 0.154327\n",
      "[760]\tvalid_0's auc: 0.838043\tvalid_0's binary_logloss: 0.154324\n",
      "[762]\tvalid_0's auc: 0.838043\tvalid_0's binary_logloss: 0.154323\n",
      "[764]\tvalid_0's auc: 0.838\tvalid_0's binary_logloss: 0.154329\n",
      "[766]\tvalid_0's auc: 0.838026\tvalid_0's binary_logloss: 0.154324\n",
      "[768]\tvalid_0's auc: 0.837973\tvalid_0's binary_logloss: 0.154338\n",
      "[770]\tvalid_0's auc: 0.837964\tvalid_0's binary_logloss: 0.15433\n",
      "[772]\tvalid_0's auc: 0.838015\tvalid_0's binary_logloss: 0.154318\n",
      "[774]\tvalid_0's auc: 0.838106\tvalid_0's binary_logloss: 0.15428\n",
      "[776]\tvalid_0's auc: 0.838172\tvalid_0's binary_logloss: 0.154257\n",
      "[778]\tvalid_0's auc: 0.838187\tvalid_0's binary_logloss: 0.154242\n",
      "[780]\tvalid_0's auc: 0.838281\tvalid_0's binary_logloss: 0.154209\n",
      "[782]\tvalid_0's auc: 0.838415\tvalid_0's binary_logloss: 0.154167\n",
      "[784]\tvalid_0's auc: 0.838431\tvalid_0's binary_logloss: 0.154153\n",
      "[786]\tvalid_0's auc: 0.838524\tvalid_0's binary_logloss: 0.154114\n",
      "[788]\tvalid_0's auc: 0.838586\tvalid_0's binary_logloss: 0.154106\n",
      "[790]\tvalid_0's auc: 0.838696\tvalid_0's binary_logloss: 0.154066\n",
      "[792]\tvalid_0's auc: 0.838792\tvalid_0's binary_logloss: 0.154034\n",
      "[794]\tvalid_0's auc: 0.83876\tvalid_0's binary_logloss: 0.154035\n",
      "[796]\tvalid_0's auc: 0.838928\tvalid_0's binary_logloss: 0.153991\n",
      "[798]\tvalid_0's auc: 0.838952\tvalid_0's binary_logloss: 0.153982\n",
      "[800]\tvalid_0's auc: 0.839036\tvalid_0's binary_logloss: 0.153941\n",
      "[802]\tvalid_0's auc: 0.839116\tvalid_0's binary_logloss: 0.153908\n",
      "[804]\tvalid_0's auc: 0.839213\tvalid_0's binary_logloss: 0.153881\n",
      "[806]\tvalid_0's auc: 0.839292\tvalid_0's binary_logloss: 0.153843\n",
      "[808]\tvalid_0's auc: 0.839428\tvalid_0's binary_logloss: 0.153804\n",
      "[810]\tvalid_0's auc: 0.839554\tvalid_0's binary_logloss: 0.153752\n",
      "[812]\tvalid_0's auc: 0.839572\tvalid_0's binary_logloss: 0.153722\n",
      "[814]\tvalid_0's auc: 0.839728\tvalid_0's binary_logloss: 0.153688\n",
      "[816]\tvalid_0's auc: 0.839721\tvalid_0's binary_logloss: 0.153665\n",
      "[818]\tvalid_0's auc: 0.839859\tvalid_0's binary_logloss: 0.153619\n",
      "[820]\tvalid_0's auc: 0.839969\tvalid_0's binary_logloss: 0.153598\n",
      "[822]\tvalid_0's auc: 0.83999\tvalid_0's binary_logloss: 0.15359\n",
      "[824]\tvalid_0's auc: 0.840067\tvalid_0's binary_logloss: 0.153565\n",
      "[826]\tvalid_0's auc: 0.84016\tvalid_0's binary_logloss: 0.153539\n",
      "[828]\tvalid_0's auc: 0.840226\tvalid_0's binary_logloss: 0.153524\n",
      "[830]\tvalid_0's auc: 0.840309\tvalid_0's binary_logloss: 0.153514\n",
      "[832]\tvalid_0's auc: 0.840354\tvalid_0's binary_logloss: 0.153478\n",
      "[834]\tvalid_0's auc: 0.840381\tvalid_0's binary_logloss: 0.153457\n",
      "[836]\tvalid_0's auc: 0.840455\tvalid_0's binary_logloss: 0.153436\n",
      "[838]\tvalid_0's auc: 0.840569\tvalid_0's binary_logloss: 0.153401\n",
      "[840]\tvalid_0's auc: 0.840619\tvalid_0's binary_logloss: 0.153377\n",
      "[842]\tvalid_0's auc: 0.840749\tvalid_0's binary_logloss: 0.153338\n",
      "[844]\tvalid_0's auc: 0.840814\tvalid_0's binary_logloss: 0.153317\n",
      "[846]\tvalid_0's auc: 0.84087\tvalid_0's binary_logloss: 0.153297\n",
      "[848]\tvalid_0's auc: 0.840973\tvalid_0's binary_logloss: 0.153275\n",
      "[850]\tvalid_0's auc: 0.841071\tvalid_0's binary_logloss: 0.153246\n",
      "[852]\tvalid_0's auc: 0.841135\tvalid_0's binary_logloss: 0.153224\n",
      "[854]\tvalid_0's auc: 0.841204\tvalid_0's binary_logloss: 0.153208\n",
      "[856]\tvalid_0's auc: 0.841249\tvalid_0's binary_logloss: 0.153188\n",
      "[858]\tvalid_0's auc: 0.841409\tvalid_0's binary_logloss: 0.153153\n",
      "[860]\tvalid_0's auc: 0.841422\tvalid_0's binary_logloss: 0.153139\n",
      "[862]\tvalid_0's auc: 0.841542\tvalid_0's binary_logloss: 0.153105\n",
      "[864]\tvalid_0's auc: 0.841651\tvalid_0's binary_logloss: 0.153081\n",
      "[866]\tvalid_0's auc: 0.841732\tvalid_0's binary_logloss: 0.153054\n",
      "[868]\tvalid_0's auc: 0.841834\tvalid_0's binary_logloss: 0.15303\n",
      "[870]\tvalid_0's auc: 0.841836\tvalid_0's binary_logloss: 0.153021\n",
      "[872]\tvalid_0's auc: 0.841908\tvalid_0's binary_logloss: 0.153\n",
      "[874]\tvalid_0's auc: 0.841933\tvalid_0's binary_logloss: 0.152992\n",
      "[876]\tvalid_0's auc: 0.841968\tvalid_0's binary_logloss: 0.152981\n",
      "[878]\tvalid_0's auc: 0.842029\tvalid_0's binary_logloss: 0.152951\n",
      "[880]\tvalid_0's auc: 0.84204\tvalid_0's binary_logloss: 0.152937\n",
      "[882]\tvalid_0's auc: 0.84211\tvalid_0's binary_logloss: 0.152908\n",
      "[884]\tvalid_0's auc: 0.84214\tvalid_0's binary_logloss: 0.152892\n",
      "[886]\tvalid_0's auc: 0.842206\tvalid_0's binary_logloss: 0.152872\n",
      "[888]\tvalid_0's auc: 0.842248\tvalid_0's binary_logloss: 0.152861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[890]\tvalid_0's auc: 0.842316\tvalid_0's binary_logloss: 0.152841\n",
      "[892]\tvalid_0's auc: 0.84237\tvalid_0's binary_logloss: 0.152817\n",
      "[894]\tvalid_0's auc: 0.842471\tvalid_0's binary_logloss: 0.152795\n",
      "[896]\tvalid_0's auc: 0.84253\tvalid_0's binary_logloss: 0.15278\n",
      "[898]\tvalid_0's auc: 0.842674\tvalid_0's binary_logloss: 0.152739\n",
      "[900]\tvalid_0's auc: 0.842697\tvalid_0's binary_logloss: 0.152732\n",
      "[902]\tvalid_0's auc: 0.842743\tvalid_0's binary_logloss: 0.152711\n",
      "[904]\tvalid_0's auc: 0.842759\tvalid_0's binary_logloss: 0.152703\n",
      "[906]\tvalid_0's auc: 0.842757\tvalid_0's binary_logloss: 0.152689\n",
      "[908]\tvalid_0's auc: 0.842882\tvalid_0's binary_logloss: 0.152643\n",
      "[910]\tvalid_0's auc: 0.842897\tvalid_0's binary_logloss: 0.15263\n",
      "[912]\tvalid_0's auc: 0.842929\tvalid_0's binary_logloss: 0.152616\n",
      "[914]\tvalid_0's auc: 0.84297\tvalid_0's binary_logloss: 0.152596\n",
      "[916]\tvalid_0's auc: 0.84296\tvalid_0's binary_logloss: 0.152599\n",
      "[918]\tvalid_0's auc: 0.843153\tvalid_0's binary_logloss: 0.15257\n",
      "[920]\tvalid_0's auc: 0.843231\tvalid_0's binary_logloss: 0.152554\n",
      "[922]\tvalid_0's auc: 0.843243\tvalid_0's binary_logloss: 0.152538\n",
      "[924]\tvalid_0's auc: 0.843306\tvalid_0's binary_logloss: 0.152518\n",
      "[926]\tvalid_0's auc: 0.843334\tvalid_0's binary_logloss: 0.152508\n",
      "[928]\tvalid_0's auc: 0.843294\tvalid_0's binary_logloss: 0.152498\n",
      "[930]\tvalid_0's auc: 0.843319\tvalid_0's binary_logloss: 0.152487\n",
      "[932]\tvalid_0's auc: 0.843462\tvalid_0's binary_logloss: 0.152442\n",
      "[934]\tvalid_0's auc: 0.843541\tvalid_0's binary_logloss: 0.15242\n",
      "[936]\tvalid_0's auc: 0.843609\tvalid_0's binary_logloss: 0.152399\n",
      "[938]\tvalid_0's auc: 0.843637\tvalid_0's binary_logloss: 0.152384\n",
      "[940]\tvalid_0's auc: 0.843708\tvalid_0's binary_logloss: 0.152363\n",
      "[942]\tvalid_0's auc: 0.843765\tvalid_0's binary_logloss: 0.152347\n",
      "[944]\tvalid_0's auc: 0.843785\tvalid_0's binary_logloss: 0.15234\n",
      "[946]\tvalid_0's auc: 0.843753\tvalid_0's binary_logloss: 0.152341\n",
      "[948]\tvalid_0's auc: 0.843815\tvalid_0's binary_logloss: 0.152316\n",
      "[950]\tvalid_0's auc: 0.843935\tvalid_0's binary_logloss: 0.152287\n",
      "[952]\tvalid_0's auc: 0.843979\tvalid_0's binary_logloss: 0.152266\n",
      "[954]\tvalid_0's auc: 0.844053\tvalid_0's binary_logloss: 0.152248\n",
      "[956]\tvalid_0's auc: 0.844081\tvalid_0's binary_logloss: 0.152234\n",
      "[958]\tvalid_0's auc: 0.844136\tvalid_0's binary_logloss: 0.152215\n",
      "[960]\tvalid_0's auc: 0.84415\tvalid_0's binary_logloss: 0.152196\n",
      "[962]\tvalid_0's auc: 0.844243\tvalid_0's binary_logloss: 0.152172\n",
      "[964]\tvalid_0's auc: 0.844273\tvalid_0's binary_logloss: 0.152157\n",
      "[966]\tvalid_0's auc: 0.844342\tvalid_0's binary_logloss: 0.152147\n",
      "[968]\tvalid_0's auc: 0.844382\tvalid_0's binary_logloss: 0.152135\n",
      "[970]\tvalid_0's auc: 0.844416\tvalid_0's binary_logloss: 0.152122\n",
      "[972]\tvalid_0's auc: 0.844452\tvalid_0's binary_logloss: 0.152111\n",
      "[974]\tvalid_0's auc: 0.84446\tvalid_0's binary_logloss: 0.1521\n",
      "[976]\tvalid_0's auc: 0.844479\tvalid_0's binary_logloss: 0.152095\n",
      "[978]\tvalid_0's auc: 0.844469\tvalid_0's binary_logloss: 0.152095\n",
      "[980]\tvalid_0's auc: 0.844492\tvalid_0's binary_logloss: 0.152083\n",
      "[982]\tvalid_0's auc: 0.84449\tvalid_0's binary_logloss: 0.152085\n",
      "[984]\tvalid_0's auc: 0.844531\tvalid_0's binary_logloss: 0.152078\n",
      "[986]\tvalid_0's auc: 0.844537\tvalid_0's binary_logloss: 0.152072\n",
      "[988]\tvalid_0's auc: 0.84454\tvalid_0's binary_logloss: 0.152072\n",
      "[990]\tvalid_0's auc: 0.844571\tvalid_0's binary_logloss: 0.152065\n",
      "[992]\tvalid_0's auc: 0.844571\tvalid_0's binary_logloss: 0.152062\n",
      "[994]\tvalid_0's auc: 0.844552\tvalid_0's binary_logloss: 0.152063\n",
      "[996]\tvalid_0's auc: 0.844564\tvalid_0's binary_logloss: 0.152058\n",
      "[998]\tvalid_0's auc: 0.844565\tvalid_0's binary_logloss: 0.152056\n",
      "[1000]\tvalid_0's auc: 0.844576\tvalid_0's binary_logloss: 0.152052\n",
      "[1002]\tvalid_0's auc: 0.844574\tvalid_0's binary_logloss: 0.152051\n",
      "[1004]\tvalid_0's auc: 0.844571\tvalid_0's binary_logloss: 0.152051\n",
      "[1006]\tvalid_0's auc: 0.844564\tvalid_0's binary_logloss: 0.152053\n",
      "[1008]\tvalid_0's auc: 0.844554\tvalid_0's binary_logloss: 0.152055\n",
      "[1010]\tvalid_0's auc: 0.844543\tvalid_0's binary_logloss: 0.152057\n",
      "[1012]\tvalid_0's auc: 0.844544\tvalid_0's binary_logloss: 0.152057\n",
      "[1014]\tvalid_0's auc: 0.844515\tvalid_0's binary_logloss: 0.152059\n",
      "[1016]\tvalid_0's auc: 0.844524\tvalid_0's binary_logloss: 0.152057\n",
      "[1018]\tvalid_0's auc: 0.844534\tvalid_0's binary_logloss: 0.152049\n",
      "[1020]\tvalid_0's auc: 0.844536\tvalid_0's binary_logloss: 0.152047\n",
      "[1022]\tvalid_0's auc: 0.844547\tvalid_0's binary_logloss: 0.152039\n",
      "[1024]\tvalid_0's auc: 0.844634\tvalid_0's binary_logloss: 0.152014\n",
      "[1026]\tvalid_0's auc: 0.844685\tvalid_0's binary_logloss: 0.151997\n",
      "[1028]\tvalid_0's auc: 0.844712\tvalid_0's binary_logloss: 0.151988\n",
      "[1030]\tvalid_0's auc: 0.844706\tvalid_0's binary_logloss: 0.151986\n",
      "[1032]\tvalid_0's auc: 0.844689\tvalid_0's binary_logloss: 0.151989\n",
      "[1034]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1036]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1038]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1040]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1042]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1044]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1046]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1048]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1050]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1052]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1054]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1056]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1058]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1060]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1062]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1064]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1066]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1068]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1070]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1072]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1074]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1076]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1078]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1080]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1082]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1084]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1086]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1088]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1090]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1092]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1094]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1096]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "[1098]\tvalid_0's auc: 0.844688\tvalid_0's binary_logloss: 0.151987\n",
      "Early stopping, best iteration is:\n",
      "[1029]\tvalid_0's auc: 0.844715\tvalid_0's binary_logloss: 0.151988\n"
     ]
    }
   ],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state=RAND):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [7329]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"Learning_rate\", [0.17]),\n",
    "        \"random_state\": trial.suggest_categorical(\"random_state:\", [RAND]),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", [percent_of_negative_class]),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 4096),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100, 100000),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.1, 1.0),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "        model = LGBMClassifier (**lgb_params)\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  eval_metric=\"auc\",\n",
    "                  early_stopping_rounds=100,\n",
    "                  callbacks=[pruning_callback],\n",
    "                  verbose=0)\n",
    "        \n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_predicts[idx] = roc_auc_score(y_test, preds[:,1])\n",
    "\n",
    "    return np.mean(cv_predicts)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"LightGBM\")\n",
    "func = lambda trial: objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "\n",
    "study.optimize(func, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "lgb_grid = LGBMClassifier(**study.best_params)\n",
    "lgb_grid.fit(X_train_,\n",
    "             y_train_,\n",
    "             eval_metric=\"auc\",\n",
    "             eval_set=eval_set,\n",
    "             verbose=2,\n",
    "             early_stopping_rounds=70)\n",
    "\n",
    "y_pred = lgb_grid.predict(X_test)\n",
    "y_pred_prob = lgb_grid.predict_proba(X_test)\n",
    "metrics = get_metrics(y_test, y_pred, y_pred_prob, name='LightGBM_fitted')\n",
    "\n",
    "y_pred = lgb_grid.predict(X_train_)\n",
    "y_pred_prob = lgb_grid.predict_proba(X_train_)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_, y_pred, y_pred_prob, name='LightGBM_fitted_train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a08fddf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 7329,\n",
       " 'Learning_rate': 0.17,\n",
       " 'random_state:': 10,\n",
       " 'scale_pos_weight': 0.9528,\n",
       " 'num_leaves': 1480,\n",
       " 'max_depth': 10,\n",
       " 'min_data_in_leaf': 6735,\n",
       " 'lambda_l1': 16,\n",
       " 'lambda_l2': 97,\n",
       " 'bagging_fraction': 0.6322273209124994}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a1615b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted</td>\n",
       "      <td>0.954097</td>\n",
       "      <td>0.838937</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.045356</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>0.148219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted_train</td>\n",
       "      <td>0.955345</td>\n",
       "      <td>0.879878</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.065121</td>\n",
       "      <td>0.120845</td>\n",
       "      <td>0.137544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0        LightGBM_fitted  0.954097  0.838937   0.684783  0.045356  0.085078   \n",
       "0  LightGBM_fitted_train  0.955345  0.879878   0.837398  0.065121  0.120845   \n",
       "\n",
       "    Logloss  \n",
       "0  0.148219  \n",
       "0  0.137544  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e1d80",
   "metadata": {},
   "source": [
    "Итак, видим, что удалось улучшить roc_auc на тестовой выборке по-сравнению с бейзлайном, а также полностью убрать эффект переобучения. Как итог, мы получили очень хороший алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2cd36",
   "metadata": {},
   "source": [
    "## Cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf6521",
   "metadata": {},
   "source": [
    "Проведём в качестве финальной проверки 5-кратную кросс-валидацию и посмотрим метрику roc_auc на каждом фолде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65375550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: Learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: random_state:\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] Unknown parameter: Learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: random_state:\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] Unknown parameter: Learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: random_state:\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] Unknown parameter: Learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: random_state:\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[LightGBM] [Warning] Unknown parameter: Learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: random_state:\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6735, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6735\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6322273209124994, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6322273209124994\n",
      "[LightGBM] [Warning] lambda_l2 is set=97, reg_lambda=0.0 will be ignored. Current value: lambda_l2=97\n",
      "[0.82567778 0.83110929 0.82437418 0.83766784 0.84186028]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "cv_predicts = np.empty(N_FOLDS)\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_test_ = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_, y_test_ = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        \n",
    "    model = LGBMClassifier(**study.best_params)\n",
    "    model.fit(X_train_,\n",
    "            y_train_,\n",
    "            eval_set=[(X_test_, y_test_)],\n",
    "            eval_metric=\"auc\",\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=0)\n",
    "        \n",
    "    preds = model.predict_proba(X_test_)\n",
    "    cv_predicts[idx] = roc_auc_score(y_test_, preds[:,1])\n",
    "\n",
    "print(cv_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa8ac4",
   "metadata": {},
   "source": [
    "Видим, что на всех фолдах roc_auc примерно одинаковый"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e799eed",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deafb48",
   "metadata": {},
   "source": [
    "Проделаем те же шаги c optuna для нашего зверя Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eccd066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', \n",
    "            'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', \n",
    "            'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID']\n",
    "\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc06ea5",
   "metadata": {},
   "source": [
    "## learning_rate и n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f0a86",
   "metadata": {},
   "source": [
    "- n_estimators - кол-во базовых алгоритмов\n",
    "- learning rate - скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d64a7095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 19:04:47,395]\u001b[0m A new study created in memory with name: Catboost\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2636b594e344cc98636f65ed0c7f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 19:12:19,676]\u001b[0m Trial 0 finished with value: 0.8651664105966101 and parameters: {'n_estimators': 579, 'Learning_rate': 0.10950343750810351, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 0 with value: 0.8651664105966101.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 19:28:25,938]\u001b[0m Trial 1 finished with value: 0.89405954328465 and parameters: {'n_estimators': 633, 'Learning_rate': 0.2969979204816421, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 19:32:57,637]\u001b[0m Trial 2 finished with value: 0.8656724999678568 and parameters: {'n_estimators': 358, 'Learning_rate': 0.19269190636272726, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 19:39:46,806]\u001b[0m Trial 3 finished with value: 0.859807778550684 and parameters: {'n_estimators': 527, 'Learning_rate': 0.10666833946178957, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 19:53:17,519]\u001b[0m Trial 4 finished with value: 0.8927336957253782 and parameters: {'n_estimators': 918, 'Learning_rate': 0.1570682343332074, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:03:45,944]\u001b[0m Trial 5 finished with value: 0.8583856089397723 and parameters: {'n_estimators': 732, 'Learning_rate': 0.07483738143720794, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:10:01,586]\u001b[0m Trial 6 finished with value: 0.8672262019521455 and parameters: {'n_estimators': 666, 'Learning_rate': 0.10187874687659806, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:17:12,999]\u001b[0m Trial 7 finished with value: 0.8649989734415383 and parameters: {'n_estimators': 459, 'Learning_rate': 0.1548942910719307, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:24:39,124]\u001b[0m Trial 8 finished with value: 0.8883523281520542 and parameters: {'n_estimators': 615, 'Learning_rate': 0.213754121104873, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:29:16,383]\u001b[0m Trial 9 finished with value: 0.8668650969513184 and parameters: {'n_estimators': 462, 'Learning_rate': 0.1587301933902287, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:31:21,755]\u001b[0m Trial 10 finished with value: 0.8578737999988695 and parameters: {'n_estimators': 212, 'Learning_rate': 0.2943323160051259, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 1 with value: 0.89405954328465.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:46:30,115]\u001b[0m Trial 11 finished with value: 0.902042920474466 and parameters: {'n_estimators': 964, 'Learning_rate': 0.2892237810208027, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 11 with value: 0.902042920474466.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 20:58:21,508]\u001b[0m Trial 12 finished with value: 0.9036729307658569 and parameters: {'n_estimators': 950, 'Learning_rate': 0.28330409101534126, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 21:06:50,110]\u001b[0m Trial 13 finished with value: 0.7264422000907779 and parameters: {'n_estimators': 927, 'Learning_rate': 0.0014752476615093324, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 21:18:11,974]\u001b[0m Trial 14 finished with value: 0.8981306496644696 and parameters: {'n_estimators': 800, 'Learning_rate': 0.2429713955987361, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 21:30:54,656]\u001b[0m Trial 15 finished with value: 0.9031552908260245 and parameters: {'n_estimators': 996, 'Learning_rate': 0.24529752611789468, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 21:42:15,114]\u001b[0m Trial 16 finished with value: 0.8968911975644833 and parameters: {'n_estimators': 823, 'Learning_rate': 0.24785215379337577, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 21:52:19,555]\u001b[0m Trial 17 finished with value: 0.8979053297404322 and parameters: {'n_estimators': 836, 'Learning_rate': 0.24708012644731442, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 22:04:57,898]\u001b[0m Trial 18 finished with value: 0.8996076348068829 and parameters: {'n_estimators': 980, 'Learning_rate': 0.19685776323122645, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 22:13:21,612]\u001b[0m Trial 19 finished with value: 0.8962557101000426 and parameters: {'n_estimators': 732, 'Learning_rate': 0.2632456987736783, 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'scale_pos_weight': 0.9528}. Best is trial 12 with value: 0.9036729307658569.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"Learning_rate\", 0.001, 0.3),\n",
    "        \"cat_features\":\n",
    "        trial.suggest_categorical(\"cat_features\", [cat_features]),\n",
    "        \"loss_function\":\n",
    "        trial.suggest_categorical(\"loss_function\", [\"Logloss\"]),\n",
    "        \"use_best_model\":\n",
    "        trial.suggest_categorical(\"use_best_model\", [True]),\n",
    "        \"eval_metric\":\n",
    "        trial.suggest_categorical(\"eval_metric\", [\"Logloss\"]),\n",
    "        \"random_state\":\n",
    "        RAND,\n",
    "        \"scale_pos_weight\": \n",
    "        trial.suggest_categorical(\"scale_pos_weight\", [percent_of_negative_class])\n",
    "    }\n",
    "       \n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_predicts[idx] = roc_auc_score(y_test, preds[:,1])\n",
    "\n",
    "    return np.mean(cv_predicts)\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"Catboost\")\n",
    "func = lambda trial: objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_features)\n",
    "\n",
    "study_cat.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8006f",
   "metadata": {},
   "source": [
    "Не знаю, почему в learning_rate первая буква всегда меняется на заглавную, но Catboost это не очень одобряет, поэтому придётся поправить:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8819bd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 950,\n",
       " 'cat_features': ['DISC_ID',\n",
       "  'TYPE_NAME',\n",
       "  'GENDER',\n",
       "  'CITIZENSHIP',\n",
       "  'EXAM_TYPE',\n",
       "  'EXAM_SUBJECT_1',\n",
       "  'EXAM_SUBJECT_2',\n",
       "  'EXAM_SUBJECT_3',\n",
       "  'ADMITTED_SUBJECT_PRIZE_LEVEL',\n",
       "  'REGION_ID'],\n",
       " 'loss_function': 'Logloss',\n",
       " 'use_best_model': True,\n",
       " 'eval_metric': 'Logloss',\n",
       " 'scale_pos_weight': 0.9528,\n",
       " 'learning_rate': 0.28330409101534126}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = dict(study_cat.best_params)\n",
    "best_params['learning_rate'] = study_cat.best_params['Learning_rate']\n",
    "del best_params['Learning_rate']\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3516c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x20fb72c7b80>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(**best_params)\n",
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         eval_set=eval_set,\n",
    "         early_stopping_rounds=100,\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "100396fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_fitted</td>\n",
       "      <td>0.963887</td>\n",
       "      <td>0.914199</td>\n",
       "      <td>0.769616</td>\n",
       "      <td>0.331893</td>\n",
       "      <td>0.463783</td>\n",
       "      <td>0.111745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0  Catboost_fitted  0.963887  0.914199   0.769616  0.331893  0.463783   \n",
       "\n",
       "    Logloss  \n",
       "0  0.111745  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "get_metrics(y_test, y_pred, y_pred_prob, name='Catboost_fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fb10063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_fitted_train</td>\n",
       "      <td>0.97007</td>\n",
       "      <td>0.952349</td>\n",
       "      <td>0.893458</td>\n",
       "      <td>0.419851</td>\n",
       "      <td>0.571258</td>\n",
       "      <td>0.09151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0  Catboost_fitted_train   0.97007  0.952349   0.893458  0.419851  0.571258   \n",
       "\n",
       "   Logloss  \n",
       "0  0.09151  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_)\n",
    "y_pred_prob = model.predict_proba(X_train_)\n",
    "get_metrics(y_train_, y_pred, y_pred_prob, name='Catboost_fitted_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba44368",
   "metadata": {},
   "source": [
    "Как видим, результаты просто шикарные, и этот алгоритм уже сильно бьёт затюненный LightGBM, но по roc_auc до своего бейзлайна совсем чуть-чуть недотягивает. Попробуем исправить ситуацию подбором других гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98576feb",
   "metadata": {},
   "source": [
    "## max_depth, l2_leaf_reg, bootstrap_type, border_count, grow_policy, auto_class_weights, \n",
    "\n",
    "- max_depth - глубина дерева\n",
    "- l2_leaf_reg - коэффициент при L2 регуляризации\n",
    "- bootstrap_type - способ формирования бутстрэп-выборки\n",
    "- grow_policy - способ построения дерева (симметричное, по глубине и т.д.)\n",
    "- auto_class_weights - множитель весов объектов\n",
    "- border_count - количество разбиений для числовых признаков (при выборе критерия разбиения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8738de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [950]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.28]),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"l2_leaf_reg\":\n",
    "        trial.suggest_uniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
    "        #\"random_strength\":\n",
    "        #trial.suggest_uniform('random_strength', 10, 50),\n",
    "        \"bootstrap_type\":\n",
    "        trial.suggest_categorical(\"bootstrap_type\",\n",
    "                                  [\"Bayesian\", \"Bernoulli\", \"MVS\", \"No\"]),\n",
    "        \"border_count\":\n",
    "        trial.suggest_categorical('border_count', [128, 254]),\n",
    "        \"grow_policy\":\n",
    "        trial.suggest_categorical('grow_policy',\n",
    "                                  [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
    "        \"auto_class_weights\":\n",
    "        trial.suggest_categorical(\"auto_class_weights\",\n",
    "                                  [\"None\", \"Balanced\", \"SqrtBalanced\"]),\n",
    "        #\"od_wait\":\n",
    "        #trial.suggest_int('od_wait', 500, 2000),\n",
    "        #\"leaf_estimation_iterations\":\n",
    "        #trial.suggest_int('leaf_estimation_iterations', 1, 15),\n",
    "        \"cat_features\":\n",
    "        trial.suggest_categorical(\"cat_features\", [cat_features]),\n",
    "        \"loss_function\":\n",
    "        trial.suggest_categorical(\"loss_function\", [\"Logloss\"]),\n",
    "        \"use_best_model\":\n",
    "        trial.suggest_categorical(\"use_best_model\", [True]),\n",
    "        \"eval_metric\":\n",
    "        trial.suggest_categorical(\"eval_metric\", [\"Logloss\"]),\n",
    "        \"random_state\":\n",
    "        random_state\n",
    "    }\n",
    "\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\n",
    "            \"bagging_temperature\", 0, 10)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\",\n",
    "                                                  0.1,\n",
    "                                                  1,\n",
    "                                                  log=True)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "        \n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_predicts[idx] = roc_auc_score(y_test, preds[:,1])\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f908df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 23:19:43,494]\u001b[0m A new study created in memory with name: Catboost\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b2d84f11a941059f52b2700ed04b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-15 23:28:07,798]\u001b[0m Trial 0 finished with value: 0.9201138011927812 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 8, 'l2_leaf_reg': 73.83322775347744, 'bootstrap_type': 'No', 'border_count': 254, 'grow_policy': 'Depthwise', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 0 with value: 0.9201138011927812.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 23:32:56,767]\u001b[0m Trial 1 finished with value: 0.89244243183782 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 10, 'l2_leaf_reg': 38.272629250341815, 'bootstrap_type': 'Bernoulli', 'border_count': 254, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'subsample': 0.2839838551483898}. Best is trial 0 with value: 0.9201138011927812.\u001b[0m\n",
      "\u001b[32m[I 2022-09-15 23:53:47,473]\u001b[0m Trial 2 finished with value: 0.8664580006682989 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 11, 'l2_leaf_reg': 42.08256063659244, 'bootstrap_type': 'Bayesian', 'border_count': 254, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'bagging_temperature': 5.947990219797599}. Best is trial 0 with value: 0.9201138011927812.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 00:01:58,793]\u001b[0m Trial 3 finished with value: 0.8569806134743889 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 4, 'l2_leaf_reg': 23.44874013196757, 'bootstrap_type': 'MVS', 'border_count': 254, 'grow_policy': 'Lossguide', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 0 with value: 0.9201138011927812.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 00:31:08,736]\u001b[0m Trial 4 finished with value: 0.9224979234482509 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 10, 'l2_leaf_reg': 36.592054621362124, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'Depthwise', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 4 with value: 0.9224979234482509.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 00:38:01,506]\u001b[0m Trial 5 finished with value: 0.9224937185510861 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 10, 'l2_leaf_reg': 28.856807433264, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 4 with value: 0.9224979234482509.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 01:06:10,900]\u001b[0m Trial 6 finished with value: 0.9199018529290781 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 12, 'l2_leaf_reg': 9.274788238577353, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 4 with value: 0.9224979234482509.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 01:55:04,630]\u001b[0m Trial 7 finished with value: 0.908448146991342 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 11, 'l2_leaf_reg': 86.2227691752541, 'bootstrap_type': 'Bernoulli', 'border_count': 254, 'grow_policy': 'Depthwise', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'subsample': 0.3317514687278419}. Best is trial 4 with value: 0.9224979234482509.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:02:10,761]\u001b[0m Trial 8 finished with value: 0.9249237064399862 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 9, 'l2_leaf_reg': 38.55993812132333, 'bootstrap_type': 'No', 'border_count': 254, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:10:36,003]\u001b[0m Trial 9 finished with value: 0.896068492224131 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 5, 'l2_leaf_reg': 70.21271866275202, 'bootstrap_type': 'MVS', 'border_count': 128, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'SqrtBalanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:31:46,683]\u001b[0m Trial 10 finished with value: 0.9212068840120204 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 7, 'l2_leaf_reg': 54.90292453725921, 'bootstrap_type': 'Bayesian', 'border_count': 254, 'grow_policy': 'Lossguide', 'auto_class_weights': 'SqrtBalanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'bagging_temperature': 0.20001322858457193}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:39:17,673]\u001b[0m Trial 11 finished with value: 0.9216629532164277 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 8, 'l2_leaf_reg': 56.30466520756275, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'Depthwise', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:46:47,214]\u001b[0m Trial 12 finished with value: 0.9205051976177707 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 9, 'l2_leaf_reg': 2.8886160083884604, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'Depthwise', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 02:51:19,631]\u001b[0m Trial 13 finished with value: 0.9175760487683717 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 7, 'l2_leaf_reg': 25.08591791472198, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'Depthwise', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-16 03:08:54,535]\u001b[0m Trial 14 finished with value: 0.9163696469999263 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 9, 'l2_leaf_reg': 99.9124253335511, 'bootstrap_type': 'No', 'border_count': 254, 'grow_policy': 'Lossguide', 'auto_class_weights': 'SqrtBalanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 03:18:30,650]\u001b[0m Trial 15 finished with value: 0.8775600650131435 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 6, 'l2_leaf_reg': 45.75059338247975, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 03:21:56,903]\u001b[0m Trial 16 finished with value: 0.7920264315591243 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 3, 'l2_leaf_reg': 13.75969274417178, 'bootstrap_type': 'Bayesian', 'border_count': 254, 'grow_policy': 'Depthwise', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'bagging_temperature': 9.964069563602388}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 03:55:16,050]\u001b[0m Trial 17 finished with value: 0.8882781375520221 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 12, 'l2_leaf_reg': 64.82421983630424, 'bootstrap_type': 'Bernoulli', 'border_count': 128, 'grow_policy': 'SymmetricTree', 'auto_class_weights': 'None', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss', 'subsample': 0.10253559201667574}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 04:02:15,075]\u001b[0m Trial 18 finished with value: 0.9214369969088549 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 9, 'l2_leaf_reg': 35.433823487788864, 'bootstrap_type': 'MVS', 'border_count': 254, 'grow_policy': 'Depthwise', 'auto_class_weights': 'Balanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n",
      "\u001b[32m[I 2022-09-16 04:21:23,515]\u001b[0m Trial 19 finished with value: 0.922208884293223 and parameters: {'n_estimators': 950, 'learning_rate': 0.28, 'max_depth': 10, 'l2_leaf_reg': 53.10788514765244, 'bootstrap_type': 'No', 'border_count': 128, 'grow_policy': 'Lossguide', 'auto_class_weights': 'SqrtBalanced', 'cat_features': ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', 'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', 'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID'], 'loss_function': 'Logloss', 'use_best_model': True, 'eval_metric': 'Logloss'}. Best is trial 8 with value: 0.9249237064399862.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"Catboost\")\n",
    "func = lambda trial: objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_features)\n",
    "\n",
    "study_cat.optimize(func, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9ca15093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 950,\n",
       " 'learning_rate': 0.28,\n",
       " 'max_depth': 9,\n",
       " 'l2_leaf_reg': 38.55993812132333,\n",
       " 'bootstrap_type': 'No',\n",
       " 'border_count': 254,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'auto_class_weights': 'Balanced',\n",
       " 'cat_features': ['DISC_ID',\n",
       "  'TYPE_NAME',\n",
       "  'GENDER',\n",
       "  'CITIZENSHIP',\n",
       "  'EXAM_TYPE',\n",
       "  'EXAM_SUBJECT_1',\n",
       "  'EXAM_SUBJECT_2',\n",
       "  'EXAM_SUBJECT_3',\n",
       "  'ADMITTED_SUBJECT_PRIZE_LEVEL',\n",
       "  'REGION_ID'],\n",
       " 'loss_function': 'Logloss',\n",
       " 'use_best_model': True,\n",
       " 'eval_metric': 'Logloss'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_cat.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efceb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = dict(study_cat.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1768de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x20fb725e4c0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = Pool(data=X_train, label=y_train, cat_features=cat_features)\n",
    "eval_data = Pool(data=X_test, label=y_test, cat_features=cat_features)\n",
    "\n",
    "model = CatBoostClassifier(**study_cat.best_params)\n",
    "model.fit(train_data,\n",
    "         eval_set=eval_data,\n",
    "         early_stopping_rounds=100,\n",
    "         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "42519dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted</td>\n",
       "      <td>0.954097</td>\n",
       "      <td>0.838937</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.045356</td>\n",
       "      <td>0.085078</td>\n",
       "      <td>0.148219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_fitted_train</td>\n",
       "      <td>0.955345</td>\n",
       "      <td>0.879878</td>\n",
       "      <td>0.837398</td>\n",
       "      <td>0.065121</td>\n",
       "      <td>0.120845</td>\n",
       "      <td>0.137544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_fitted</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.937393</td>\n",
       "      <td>0.334437</td>\n",
       "      <td>0.800216</td>\n",
       "      <td>0.471724</td>\n",
       "      <td>0.238022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_train</td>\n",
       "      <td>0.926082</td>\n",
       "      <td>0.976876</td>\n",
       "      <td>0.384154</td>\n",
       "      <td>0.922361</td>\n",
       "      <td>0.542403</td>\n",
       "      <td>0.217075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0        LightGBM_fitted  0.954097  0.838937   0.684783  0.045356  0.085078   \n",
       "0  LightGBM_fitted_train  0.955345  0.879878   0.837398  0.065121  0.120845   \n",
       "0        CatBoost_fitted  0.915663  0.937393   0.334437  0.800216  0.471724   \n",
       "0         Catboost_train  0.926082  0.976876   0.384154  0.922361  0.542403   \n",
       "\n",
       "    Logloss  \n",
       "0  0.148219  \n",
       "0  0.137544  \n",
       "0  0.238022  \n",
       "0  0.217075  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test, y_pred, y_pred_prob, name='CatBoost_fitted'))\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "y_pred_prob = model.predict_proba(X_train)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train, y_pred, y_pred_prob, name='Catboost_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c638b3d",
   "metadata": {},
   "source": [
    "Видим улучшение roc_auc на целых 2% относительно бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d8ae6",
   "metadata": {},
   "source": [
    "## Cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09640461",
   "metadata": {},
   "source": [
    "Аналогично LightGBM, сделаем проверку нашего алгоритма на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5bcaa557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91724988 0.91887531 0.92316864 0.92941474 0.93187569]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "cv_predicts = np.empty(N_FOLDS)\n",
    "\n",
    "for idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_test_ = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_, y_test_ = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    train_data = Pool(data=X_train_, label=y_train_, cat_features=cat_features)\n",
    "    eval_data = Pool(data=X_test_, label=y_test_, cat_features=cat_features)\n",
    "\n",
    "    model = CatBoostClassifier(**study_cat.best_params)\n",
    "    model.fit(train_data,\n",
    "              eval_set=eval_data,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "        \n",
    "    preds = model.predict_proba(X_test_)\n",
    "    cv_predicts[idx] = roc_auc_score(y_test_, preds[:,1])\n",
    "\n",
    "print(cv_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a689e3",
   "metadata": {},
   "source": [
    "Видим, что всё стабильно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
