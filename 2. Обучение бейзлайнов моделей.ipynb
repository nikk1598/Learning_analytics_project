{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNhT1pNbD6Jm","outputId":"a32bbbbf-1977-4277-920c-72062c5029e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8280dcc1"},"source":["# Импорт библиотек"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db3a8f28","outputId":"851bce6c-30d3-42bb-8f24-b56094099a2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.6)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"]}],"source":["!pip install xgboost\n","!pip install lightgbm\n","!pip install catboost\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n","\n","from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n","    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n","    precision_recall_curve, roc_curve\n","\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","RAND = 10\n","percent_of_negative_class = 0.97"]},{"cell_type":"markdown","metadata":{"id":"51d487ef"},"source":["# Метод для подсчёта метрик"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c68d090"},"outputs":[],"source":["def get_metrics(y_test, y_pred, y_score, name):\n","    df_metrics = pd.DataFrame()\n","    \n","    df_metrics['model'] = [name]\n","    \n","    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n","    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:,1])]\n","    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n","    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n","    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n","    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n","    \n","    return df_metrics"]},{"cell_type":"markdown","metadata":{"id":"834a4a43"},"source":["# Подготовка данных к обучению"]},{"cell_type":"markdown","metadata":{"id":"1e15fb3e"},"source":["Выгрузим данные, сохранённые на этапе EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db2dfaa7","outputId":"c1b579e2-caa7-4577-8cc0-2f653c49417e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e8311f81-19cb-4259-830a-eafadd8c4d80\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SEMESTER</th>\n","      <th>DISC_ID</th>\n","      <th>TYPE_NAME</th>\n","      <th>DEBT</th>\n","      <th>GENDER</th>\n","      <th>CITIZENSHIP</th>\n","      <th>EXAM_TYPE</th>\n","      <th>EXAM_SUBJECT_1</th>\n","      <th>EXAM_SUBJECT_2</th>\n","      <th>EXAM_SUBJECT_3</th>\n","      <th>...</th>\n","      <th>DISC_DEP_12779834774062657273</th>\n","      <th>DISC_DEP_12795149246808839444</th>\n","      <th>DISC_DEP_12866670834530293829</th>\n","      <th>DISC_DEP_12896073176567118977</th>\n","      <th>DISC_DEP_13705271043836613455</th>\n","      <th>DISC_DEP_16131140458546037814</th>\n","      <th>DISC_DEP_16828277449727897492</th>\n","      <th>DISC_DEP_17522523368314118110</th>\n","      <th>DISC_DEP_18446744073709551615</th>\n","      <th>mean_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>10502311854018326223</td>\n","      <td>Зачет</td>\n","      <td>0</td>\n","      <td>М</td>\n","      <td>15601729049989747827</td>\n","      <td>ЕГЭ</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.666667</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1601392918367593206</td>\n","      <td>Зачет</td>\n","      <td>0</td>\n","      <td>М</td>\n","      <td>15601729049989747827</td>\n","      <td>ЕГЭ</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.666667</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>9559803959325174929</td>\n","      <td>Зачет</td>\n","      <td>0</td>\n","      <td>М</td>\n","      <td>15601729049989747827</td>\n","      <td>ЕГЭ</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.666667</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>8955667882044263414</td>\n","      <td>Зачет</td>\n","      <td>0</td>\n","      <td>М</td>\n","      <td>15601729049989747827</td>\n","      <td>ЕГЭ</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.666667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>17741967398854095262</td>\n","      <td>Экзамен</td>\n","      <td>0</td>\n","      <td>М</td>\n","      <td>15601729049989747827</td>\n","      <td>ЕГЭ</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>82.666667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 890 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8311f81-19cb-4259-830a-eafadd8c4d80')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e8311f81-19cb-4259-830a-eafadd8c4d80 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e8311f81-19cb-4259-830a-eafadd8c4d80');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   SEMESTER               DISC_ID TYPE_NAME  DEBT GENDER  \\\n","0         1  10502311854018326223     Зачет     0      М   \n","1         1   1601392918367593206     Зачет     0      М   \n","2         1   9559803959325174929     Зачет     0      М   \n","3         1   8955667882044263414     Зачет     0      М   \n","4         1  17741967398854095262   Экзамен     0      М   \n","\n","            CITIZENSHIP EXAM_TYPE     EXAM_SUBJECT_1       EXAM_SUBJECT_2  \\\n","0  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n","1  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n","2  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n","3  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n","4  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n","\n","        EXAM_SUBJECT_3  ...  DISC_DEP_12779834774062657273  \\\n","0  8388269026169219461  ...                              0   \n","1  8388269026169219461  ...                              0   \n","2  8388269026169219461  ...                              0   \n","3  8388269026169219461  ...                              0   \n","4  8388269026169219461  ...                              0   \n","\n","   DISC_DEP_12795149246808839444  DISC_DEP_12866670834530293829  \\\n","0                              0                              0   \n","1                              0                              0   \n","2                              0                              0   \n","3                              0                              0   \n","4                              0                              0   \n","\n","  DISC_DEP_12896073176567118977  DISC_DEP_13705271043836613455  \\\n","0                             0                              0   \n","1                             0                              0   \n","2                             0                              0   \n","3                             0                              0   \n","4                             0                              0   \n","\n","   DISC_DEP_16131140458546037814  DISC_DEP_16828277449727897492  \\\n","0                              0                              0   \n","1                              0                              0   \n","2                              0                              0   \n","3                              0                              0   \n","4                              0                              0   \n","\n","   DISC_DEP_17522523368314118110  DISC_DEP_18446744073709551615  mean_score  \n","0                              0                              0   82.666667  \n","1                              0                              0   82.666667  \n","2                              0                              0   82.666667  \n","3                              0                              0   82.666667  \n","4                              0                              0   82.666667  \n","\n","[5 rows x 890 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_parquet('/content/drive/MyDrive/data_test3.parquet.gzip')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"052630c4"},"source":["## Бинаризация"]},{"cell_type":"markdown","metadata":{"id":"106d3001"},"source":["Проведём бинаризацию датафрейма"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4a6f824","outputId":"d8f38b96-9d15-454d-b5c3-ccbea346716a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b220e2f5-a845-429f-ac4c-c1d49d8cff9b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SEMESTER</th>\n","      <th>DISC_ID</th>\n","      <th>DEBT</th>\n","      <th>CITIZENSHIP</th>\n","      <th>EXAM_SUBJECT_1</th>\n","      <th>EXAM_SUBJECT_2</th>\n","      <th>EXAM_SUBJECT_3</th>\n","      <th>ADMITTED_EXAM_1</th>\n","      <th>ADMITTED_EXAM_2</th>\n","      <th>ADMITTED_EXAM_3</th>\n","      <th>...</th>\n","      <th>TYPE_NAME_Курсовой проект</th>\n","      <th>TYPE_NAME_Экзамен</th>\n","      <th>GENDER_М</th>\n","      <th>EXAM_TYPE_ЕГЭ</th>\n","      <th>EXAM_TYPE_ОЛИМПИАДА</th>\n","      <th>ADMITTED_SUBJECT_PRIZE_LEVEL_1.0</th>\n","      <th>ADMITTED_SUBJECT_PRIZE_LEVEL_2.0</th>\n","      <th>ADMITTED_SUBJECT_PRIZE_LEVEL_3.0</th>\n","      <th>ADMITTED_SUBJECT_PRIZE_LEVEL_4.0</th>\n","      <th>ADMITTED_SUBJECT_PRIZE_LEVEL_ЕГЭ</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>10502311854018326223</td>\n","      <td>0</td>\n","      <td>15601729049989747827</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>78.0</td>\n","      <td>79.0</td>\n","      <td>91.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1601392918367593206</td>\n","      <td>0</td>\n","      <td>15601729049989747827</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>78.0</td>\n","      <td>79.0</td>\n","      <td>91.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>9559803959325174929</td>\n","      <td>0</td>\n","      <td>15601729049989747827</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>78.0</td>\n","      <td>79.0</td>\n","      <td>91.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>8955667882044263414</td>\n","      <td>0</td>\n","      <td>15601729049989747827</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>78.0</td>\n","      <td>79.0</td>\n","      <td>91.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>17741967398854095262</td>\n","      <td>0</td>\n","      <td>15601729049989747827</td>\n","      <td>70786669040476600</td>\n","      <td>5533732657842394915</td>\n","      <td>8388269026169219461</td>\n","      <td>78.0</td>\n","      <td>79.0</td>\n","      <td>91.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 897 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b220e2f5-a845-429f-ac4c-c1d49d8cff9b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b220e2f5-a845-429f-ac4c-c1d49d8cff9b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b220e2f5-a845-429f-ac4c-c1d49d8cff9b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   SEMESTER               DISC_ID  DEBT           CITIZENSHIP  \\\n","0         1  10502311854018326223     0  15601729049989747827   \n","1         1   1601392918367593206     0  15601729049989747827   \n","2         1   9559803959325174929     0  15601729049989747827   \n","3         1   8955667882044263414     0  15601729049989747827   \n","4         1  17741967398854095262     0  15601729049989747827   \n","\n","      EXAM_SUBJECT_1       EXAM_SUBJECT_2       EXAM_SUBJECT_3  \\\n","0  70786669040476600  5533732657842394915  8388269026169219461   \n","1  70786669040476600  5533732657842394915  8388269026169219461   \n","2  70786669040476600  5533732657842394915  8388269026169219461   \n","3  70786669040476600  5533732657842394915  8388269026169219461   \n","4  70786669040476600  5533732657842394915  8388269026169219461   \n","\n","   ADMITTED_EXAM_1  ADMITTED_EXAM_2  ADMITTED_EXAM_3  ...  \\\n","0             78.0             79.0             91.0  ...   \n","1             78.0             79.0             91.0  ...   \n","2             78.0             79.0             91.0  ...   \n","3             78.0             79.0             91.0  ...   \n","4             78.0             79.0             91.0  ...   \n","\n","   TYPE_NAME_Курсовой проект  TYPE_NAME_Экзамен  GENDER_М  EXAM_TYPE_ЕГЭ  \\\n","0                          0                  0         1              1   \n","1                          0                  0         1              1   \n","2                          0                  0         1              1   \n","3                          0                  0         1              1   \n","4                          0                  1         1              1   \n","\n","   EXAM_TYPE_ОЛИМПИАДА  ADMITTED_SUBJECT_PRIZE_LEVEL_1.0  \\\n","0                    0                                 0   \n","1                    0                                 0   \n","2                    0                                 0   \n","3                    0                                 0   \n","4                    0                                 0   \n","\n","   ADMITTED_SUBJECT_PRIZE_LEVEL_2.0  ADMITTED_SUBJECT_PRIZE_LEVEL_3.0  \\\n","0                                 0                                 0   \n","1                                 0                                 0   \n","2                                 0                                 0   \n","3                                 0                                 0   \n","4                                 0                                 0   \n","\n","   ADMITTED_SUBJECT_PRIZE_LEVEL_4.0  ADMITTED_SUBJECT_PRIZE_LEVEL_ЕГЭ  \n","0                                 0                                 1  \n","1                                 0                                 1  \n","2                                 0                                 1  \n","3                                 0                                 1  \n","4                                 0                                 1  \n","\n","[5 rows x 897 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_bin = pd.get_dummies(df, drop_first=True)\n","df_bin.head()"]},{"cell_type":"markdown","metadata":{"id":"945dd771"},"source":["## Разбиение на train/test"]},{"cell_type":"markdown","metadata":{"id":"333b96cc"},"source":["Разобьём датафрейм на обучающую и тестовую выборки для обоих датафреймов (бинаризованного и небинаризованного, чтобы в зависимости от модели подавать на вход тот или иной вариант)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22adee6b"},"outputs":[],"source":["feature_cols = df.drop(columns = ['DEBT'])\n","\n","X_train, X_test, y_train, y_test = train_test_split(feature_cols,\n","                                                    df['DEBT'],\n","                                                    test_size=0.16,\n","                                                    random_state=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9d4733a7"},"outputs":[],"source":["feature_cols_bin = df_bin.drop(columns = ['DEBT'])\n","\n","X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(feature_cols_bin,\n","                                                    df_bin['DEBT'],\n","                                                    test_size=0.16,\n","                                                    random_state=10)"]},{"cell_type":"markdown","metadata":{"id":"d91ea60f"},"source":["## Нормализация"]},{"cell_type":"markdown","metadata":{"id":"a97ee81e"},"source":["Приведём все признаки к одной шкале с помощью MinMaxScaler для бинаризованных данных - это будет третья и последняя вариация формата наших выборок"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ec26d68"},"outputs":[],"source":["st = MinMaxScaler()\n","X_train_bin_scaled = st.fit_transform(X_train_bin)\n","X_test_bin_scaled = st.transform(X_test_bin)"]},{"cell_type":"markdown","metadata":{"id":"50c8e2aa"},"source":["# Logistic regression"]},{"cell_type":"markdown","metadata":{"id":"31bdf908"},"source":["Приступим к обучению наших бейзлайн моделей"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"275199e2","outputId":"4eaec14b-2366-4490-c64a-d00558b4ba6f"},"outputs":[{"data":{"text/plain":["LogisticRegression(class_weight='balanced', random_state=10)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["lr = LogisticRegression(class_weight='balanced', random_state=RAND)\n","lr.fit(X_train_bin_scaled, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56175b15","outputId":"b4bee28e-41bd-4a9f-89e8-7f5976c46bff"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-517736bd-517a-4217-938f-a32c73379c25\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-517736bd-517a-4217-938f-a32c73379c25')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-517736bd-517a-4217-938f-a32c73379c25 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-517736bd-517a-4217-938f-a32c73379c25');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = lr.predict(X_test_bin_scaled)\n","y_pred_prob = lr.predict_proba(X_test_bin_scaled)\n","metrics = get_metrics(y_test, y_pred, y_pred_prob, name='LogisticRegression')\n","\n","y_pred_train = lr.predict(X_train_bin_scaled)\n","y_pred_prob_train = lr.predict_proba(X_train_bin_scaled)\n","metrics = metrics.append(\n","    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='LogisticRegression_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"3371f86f"},"source":["# Decision tree"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3654ed9b","outputId":"9988e40f-d6d7-456b-98c4-c2de20ddca60"},"outputs":[{"data":{"text/plain":["DecisionTreeClassifier(class_weight='balanced', random_state=10)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dt = DecisionTreeClassifier(class_weight='balanced', random_state=RAND)\n","dt.fit(X_train_bin, y_train_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef91894f","outputId":"f3bf92dd-1d00-4800-953e-461e9ba7d8f1"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f921fba1-5e1d-4609-9cfc-66252e0d2400\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f921fba1-5e1d-4609-9cfc-66252e0d2400')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f921fba1-5e1d-4609-9cfc-66252e0d2400 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f921fba1-5e1d-4609-9cfc-66252e0d2400');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = dt.predict(X_test_bin)\n","y_pred_prob = dt.predict_proba(X_test_bin)\n","metrics = metrics.append(\n","    get_metrics(y_test_bin, y_pred, y_pred_prob, name='Decision_tree'))\n","\n","y_pred_train = dt.predict(X_train_bin)\n","y_pred_prob_train = dt.predict_proba(X_train_bin)\n","metrics = metrics.append(\n","    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='Decision_tree_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"hLP52RFrCYov"},"source":["Видим переобучение"]},{"cell_type":"markdown","metadata":{"id":"Mztgb05dIKKn"},"source":["# Random forest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2f0f2051","outputId":"e7e82c7c-d2c2-4668-b22b-4b06f1e55b15"},"outputs":[{"data":{"text/plain":["RandomForestClassifier(bootstrap=False, class_weight='balanced',\n","                       random_state=10)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["rf = RandomForestClassifier(class_weight='balanced', bootstrap=False, random_state=RAND)\n","rf.fit(X_train_bin, y_train_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa112a36","outputId":"5b6e7228-369f-4db1-b40e-6ee7b5dfa8dd"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-cdcc80bf-b738-4126-96ce-ab437deea47a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdcc80bf-b738-4126-96ce-ab437deea47a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cdcc80bf-b738-4126-96ce-ab437deea47a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cdcc80bf-b738-4126-96ce-ab437deea47a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = rf.predict(X_test_bin)\n","y_pred_prob = rf.predict_proba(X_test_bin)\n","metrics = metrics.append(\n","    get_metrics(y_test_bin, y_pred, y_pred_prob, name='Random_forest'))\n","\n","y_pred_train = rf.predict(X_train_bin)\n","y_pred_prob_train = rf.predict_proba(X_train_bin)\n","metrics = metrics.append(\n","    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='Random_forest_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"8DQm9W2kCYow"},"source":["Аналогично, видим переобучение"]},{"cell_type":"markdown","metadata":{"id":"cd2134b9"},"source":["# Bagging classifier (logistic regression)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89350aaf","outputId":"cae0c6d2-5ebc-4bb8-f9b7-bd9d0f3c838a"},"outputs":[{"data":{"text/plain":["BaggingClassifier(base_estimator=LogisticRegression(), random_state=10)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["bg = BaggingClassifier(base_estimator=LogisticRegression(),\n","                      random_state=RAND)\n","bg.fit(pd.DataFrame(X_train_bin_scaled), y_train_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"152c6ed1","outputId":"b11ed65e-3238-42c9-fc2e-d3f45a85ed55"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-4bd728c0-e54f-4823-8a31-b7a0c2a20ef5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bd728c0-e54f-4823-8a31-b7a0c2a20ef5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4bd728c0-e54f-4823-8a31-b7a0c2a20ef5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4bd728c0-e54f-4823-8a31-b7a0c2a20ef5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = bg.predict(X_test_bin_scaled)\n","y_pred_prob = bg.predict_proba(X_test_bin_scaled)\n","metrics = metrics.append(get_metrics(y_test, y_pred, y_pred_prob, name='Bagging_classifier'))\n","\n","y_pred_train = bg.predict(X_train_bin_scaled)\n","y_pred_prob_train = bg.predict_proba(X_train_bin_scaled)\n","metrics = metrics.append(\n","    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='Bagging_classifier_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"5725bfd7"},"source":["# XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgKOBmJdLbH-"},"outputs":[],"source":["# Реализация f1-метрики для XGBoost\n","def f1_metric(y_pred, dtrain):\n","    y_true = dtrain.get_label()\n","    err = 1 - f1_score(y_true, np.round(y_pred))\n","    return 'f1_err', err"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93bdfa9b","outputId":"9e70ed6c-7b3a-4c54-ff7b-0e70845b465e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0]\tvalidation_0-error:0.027647\tvalidation_0-f1_err:0.898161\n","Multiple eval metrics have been passed: 'validation_0-f1_err' will be used for early stopping.\n","\n","Will train until validation_0-f1_err hasn't improved in 100 rounds.\n","[2]\tvalidation_0-error:0.027778\tvalidation_0-f1_err:0.908832\n","[4]\tvalidation_0-error:0.027255\tvalidation_0-f1_err:0.909884\n","[6]\tvalidation_0-error:0.027255\tvalidation_0-f1_err:0.909884\n","[8]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.964126\n","[10]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.964126\n","[12]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.964126\n","[14]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.964126\n","[16]\tvalidation_0-error:0.028126\tvalidation_0-f1_err:0.967066\n","[18]\tvalidation_0-error:0.028126\tvalidation_0-f1_err:0.967066\n","[20]\tvalidation_0-error:0.028431\tvalidation_0-f1_err:0.987897\n","[22]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[24]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[26]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[28]\tvalidation_0-error:0.028431\tvalidation_0-f1_err:0.987897\n","[30]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[32]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[34]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.984894\n","[36]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.9819\n","[38]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.978947\n","[40]\tvalidation_0-error:0.028387\tvalidation_0-f1_err:0.981928\n","[42]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.978947\n","[44]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.978947\n","[46]\tvalidation_0-error:0.0283\tvalidation_0-f1_err:0.975976\n","[48]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.978947\n","[50]\tvalidation_0-error:0.028344\tvalidation_0-f1_err:0.976012\n","[52]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.958395\n","[54]\tvalidation_0-error:0.028126\tvalidation_0-f1_err:0.96131\n","[56]\tvalidation_0-error:0.028083\tvalidation_0-f1_err:0.958395\n","[58]\tvalidation_0-error:0.027952\tvalidation_0-f1_err:0.949704\n","[60]\tvalidation_0-error:0.027908\tvalidation_0-f1_err:0.946824\n","[62]\tvalidation_0-error:0.027908\tvalidation_0-f1_err:0.946824\n","[64]\tvalidation_0-error:0.027778\tvalidation_0-f1_err:0.935484\n","[66]\tvalidation_0-error:0.027734\tvalidation_0-f1_err:0.93265\n","[68]\tvalidation_0-error:0.027691\tvalidation_0-f1_err:0.929825\n","[70]\tvalidation_0-error:0.027604\tvalidation_0-f1_err:0.924198\n","[72]\tvalidation_0-error:0.02756\tvalidation_0-f1_err:0.921397\n","[74]\tvalidation_0-error:0.02756\tvalidation_0-f1_err:0.921397\n","[76]\tvalidation_0-error:0.02756\tvalidation_0-f1_err:0.921397\n","[78]\tvalidation_0-error:0.027212\tvalidation_0-f1_err:0.899281\n","[80]\tvalidation_0-error:0.027429\tvalidation_0-f1_err:0.913043\n","[82]\tvalidation_0-error:0.027081\tvalidation_0-f1_err:0.891117\n","[84]\tvalidation_0-error:0.026951\tvalidation_0-f1_err:0.883024\n","[86]\tvalidation_0-error:0.027299\tvalidation_0-f1_err:0.904762\n","[88]\tvalidation_0-error:0.027255\tvalidation_0-f1_err:0.902017\n","[90]\tvalidation_0-error:0.027212\tvalidation_0-f1_err:0.899281\n","[92]\tvalidation_0-error:0.026863\tvalidation_0-f1_err:0.877667\n","[94]\tvalidation_0-error:0.026733\tvalidation_0-f1_err:0.869688\n","[96]\tvalidation_0-error:0.026733\tvalidation_0-f1_err:0.869688\n","[98]\tvalidation_0-error:0.026123\tvalidation_0-f1_err:0.833333\n","[99]\tvalidation_0-error:0.026123\tvalidation_0-f1_err:0.833333\n"]},{"data":{"text/plain":["XGBClassifier(random_state=10, scale_pos_weight=0.958)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Выборки для проверки после каждой итерации обучения\n","X_train_, X_val, y_train_, y_val = train_test_split(X_train_bin,\n","                                                    y_train_bin,\n","                                                    test_size=0.16,\n","                                                    shuffle=True,\n","                                                    random_state=RAND)\n","eval_set = [(X_val, y_val)]\n","\n","clf = XGBClassifier(random_state=RAND, scale_pos_weight = percent_of_negative_class)\n","\n","clf.fit(X_train_,\n","        y_train_,\n","        eval_metric=f1_metric,\n","        eval_set=eval_set,\n","        early_stopping_rounds=100,\n","        verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"b76eb3a7","outputId":"1a67eeb0-d04d-4fae-c5ef-fb5ed02cdfdc"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d85cd2c8-61ae-4fb1-9180-f1370f7c5163\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost</td>\n","      <td>0.973192</td>\n","      <td>0.861562</td>\n","      <td>0.904762</td>\n","      <td>0.072704</td>\n","      <td>0.134593</td>\n","      <td>0.100149</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost_train</td>\n","      <td>0.971720</td>\n","      <td>0.861385</td>\n","      <td>0.879479</td>\n","      <td>0.074115</td>\n","      <td>0.136709</td>\n","      <td>0.103957</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d85cd2c8-61ae-4fb1-9180-f1370f7c5163')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d85cd2c8-61ae-4fb1-9180-f1370f7c5163 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d85cd2c8-61ae-4fb1-9180-f1370f7c5163');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","0                   XGBoost  0.973192  0.861562   0.904762  0.072704   \n","0             XGBoost_train  0.971720  0.861385   0.879479  0.074115   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  \n","0  0.134593  0.100149  \n","0  0.136709  0.103957  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf.predict(X_test_bin)\n","y_pred_prob = clf.predict_proba(X_test_bin)\n","metrics = metrics.append(\n","    get_metrics(y_test_bin, y_pred, y_pred_prob, name='XGBoost'))\n","\n","y_pred_train = clf.predict(X_train_)\n","y_pred_prob_train = clf.predict_proba(X_train_)\n","metrics = metrics.append(\n","    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='XGBoost_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"c6e7e050"},"source":["# LightGBM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZSUReQEMOof"},"outputs":[],"source":["# Реализация f1-метрики для LightGBM\n","def f1_metric(labels, scores):\n","    pred = np.round(scores)\n","    return 'f1', f1_score(labels, pred), True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e14ad56e","outputId":"459ac46a-4f34-49d3-98b0-1adfb8f24f9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training until validation scores don't improve for 100 rounds.\n","[2]\tvalid_0's binary_logloss: 0.115064\tvalid_0's f1: 0.101449\n","[4]\tvalid_0's binary_logloss: 0.1111\tvalid_0's f1: 0.106936\n","[6]\tvalid_0's binary_logloss: 0.107991\tvalid_0's f1: 0.112392\n","[8]\tvalid_0's binary_logloss: 0.105188\tvalid_0's f1: 0.115108\n","[10]\tvalid_0's binary_logloss: 0.103158\tvalid_0's f1: 0.120516\n","[12]\tvalid_0's binary_logloss: 0.10142\tvalid_0's f1: 0.128388\n","[14]\tvalid_0's binary_logloss: 0.100046\tvalid_0's f1: 0.13881\n","[16]\tvalid_0's binary_logloss: 0.0989617\tvalid_0's f1: 0.148668\n","[18]\tvalid_0's binary_logloss: 0.0978376\tvalid_0's f1: 0.150628\n","[20]\tvalid_0's binary_logloss: 0.0964321\tvalid_0's f1: 0.164384\n","[22]\tvalid_0's binary_logloss: 0.0949505\tvalid_0's f1: 0.17415\n","[24]\tvalid_0's binary_logloss: 0.0942052\tvalid_0's f1: 0.188425\n","[26]\tvalid_0's binary_logloss: 0.0933336\tvalid_0's f1: 0.209549\n","[28]\tvalid_0's binary_logloss: 0.092577\tvalid_0's f1: 0.211921\n","[30]\tvalid_0's binary_logloss: 0.0919217\tvalid_0's f1: 0.218709\n","[32]\tvalid_0's binary_logloss: 0.0911738\tvalid_0's f1: 0.221053\n","[34]\tvalid_0's binary_logloss: 0.0906242\tvalid_0's f1: 0.223097\n","[36]\tvalid_0's binary_logloss: 0.0901745\tvalid_0's f1: 0.230065\n","[38]\tvalid_0's binary_logloss: 0.0896877\tvalid_0's f1: 0.240621\n","[40]\tvalid_0's binary_logloss: 0.0890978\tvalid_0's f1: 0.245161\n","[42]\tvalid_0's binary_logloss: 0.0887359\tvalid_0's f1: 0.254172\n","[44]\tvalid_0's binary_logloss: 0.0884708\tvalid_0's f1: 0.26087\n","[46]\tvalid_0's binary_logloss: 0.0881594\tvalid_0's f1: 0.26242\n","[48]\tvalid_0's binary_logloss: 0.0876798\tvalid_0's f1: 0.268015\n","[50]\tvalid_0's binary_logloss: 0.0872672\tvalid_0's f1: 0.272727\n","[52]\tvalid_0's binary_logloss: 0.0868192\tvalid_0's f1: 0.274559\n","[54]\tvalid_0's binary_logloss: 0.0865298\tvalid_0's f1: 0.276382\n","[56]\tvalid_0's binary_logloss: 0.0861505\tvalid_0's f1: 0.281054\n","[58]\tvalid_0's binary_logloss: 0.0858468\tvalid_0's f1: 0.285\n","[60]\tvalid_0's binary_logloss: 0.08568\tvalid_0's f1: 0.286783\n","[62]\tvalid_0's binary_logloss: 0.0854969\tvalid_0's f1: 0.286783\n","[64]\tvalid_0's binary_logloss: 0.0852091\tvalid_0's f1: 0.291045\n","[66]\tvalid_0's binary_logloss: 0.0849189\tvalid_0's f1: 0.292804\n","[68]\tvalid_0's binary_logloss: 0.0847092\tvalid_0's f1: 0.304079\n","[70]\tvalid_0's binary_logloss: 0.0843803\tvalid_0's f1: 0.304079\n","[72]\tvalid_0's binary_logloss: 0.0840578\tvalid_0's f1: 0.305795\n","[74]\tvalid_0's binary_logloss: 0.0837604\tvalid_0's f1: 0.303704\n","[76]\tvalid_0's binary_logloss: 0.083385\tvalid_0's f1: 0.301607\n","[78]\tvalid_0's binary_logloss: 0.0831363\tvalid_0's f1: 0.308261\n","[80]\tvalid_0's binary_logloss: 0.0829999\tvalid_0's f1: 0.310345\n","[82]\tvalid_0's binary_logloss: 0.0827832\tvalid_0's f1: 0.310345\n","[84]\tvalid_0's binary_logloss: 0.0823589\tvalid_0's f1: 0.314496\n","[86]\tvalid_0's binary_logloss: 0.0821918\tvalid_0's f1: 0.314496\n","[88]\tvalid_0's binary_logloss: 0.0820167\tvalid_0's f1: 0.314496\n","[90]\tvalid_0's binary_logloss: 0.081742\tvalid_0's f1: 0.314883\n","[92]\tvalid_0's binary_logloss: 0.0815564\tvalid_0's f1: 0.316953\n","[94]\tvalid_0's binary_logloss: 0.0813873\tvalid_0's f1: 0.319018\n","[96]\tvalid_0's binary_logloss: 0.0811439\tvalid_0's f1: 0.319018\n","[98]\tvalid_0's binary_logloss: 0.0808977\tvalid_0's f1: 0.322738\n","[100]\tvalid_0's binary_logloss: 0.0807526\tvalid_0's f1: 0.324786\n","Did not meet early stopping. Best iteration is:\n","[100]\tvalid_0's binary_logloss: 0.0807526\tvalid_0's f1: 0.324786\n"]},{"data":{"text/plain":["LGBMClassifier(random_state=10, scale_pos_weight=0.958)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Выборки для проверки после каждой итерации обучения\n","X_train_, X_val, y_train_, y_val = train_test_split(X_train,\n","                                                    y_train,\n","                                                    test_size=0.16,\n","                                                    shuffle=True,\n","                                                    random_state=RAND)\n","eval_set = [(X_val, y_val)]\n","\n","clf = LGBMClassifier(random_state=RAND, scale_pos_weight=percent_of_negative_class)\n","\n","eval_set = [(X_val, y_val)]\n","\n","clf.fit(X_train_,\n","        y_train_,\n","        eval_metric=f1_metric,\n","        eval_set=eval_set,\n","        early_stopping_rounds=100,\n","        verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"4add01dd","outputId":"74adef2b-b241-43d1-be28-f57247c54b18"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1ef62e25-8de1-421e-9288-68d1957e2228\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost</td>\n","      <td>0.973192</td>\n","      <td>0.861562</td>\n","      <td>0.904762</td>\n","      <td>0.072704</td>\n","      <td>0.134593</td>\n","      <td>0.100149</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost_train</td>\n","      <td>0.971720</td>\n","      <td>0.861385</td>\n","      <td>0.879479</td>\n","      <td>0.074115</td>\n","      <td>0.136709</td>\n","      <td>0.103957</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM</td>\n","      <td>0.975496</td>\n","      <td>0.930576</td>\n","      <td>0.875000</td>\n","      <td>0.169643</td>\n","      <td>0.284188</td>\n","      <td>0.079913</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM_train</td>\n","      <td>0.975775</td>\n","      <td>0.954605</td>\n","      <td>0.909297</td>\n","      <td>0.220148</td>\n","      <td>0.354475</td>\n","      <td>0.074276</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ef62e25-8de1-421e-9288-68d1957e2228')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ef62e25-8de1-421e-9288-68d1957e2228 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ef62e25-8de1-421e-9288-68d1957e2228');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","0                   XGBoost  0.973192  0.861562   0.904762  0.072704   \n","0             XGBoost_train  0.971720  0.861385   0.879479  0.074115   \n","0                  LightGBM  0.975496  0.930576   0.875000  0.169643   \n","0            LightGBM_train  0.975775  0.954605   0.909297  0.220148   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  \n","0  0.134593  0.100149  \n","0  0.136709  0.103957  \n","0  0.284188  0.079913  \n","0  0.354475  0.074276  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf.predict(X_test)\n","y_pred_prob = clf.predict_proba(X_test)\n","metrics = metrics.append(\n","    get_metrics(y_test, y_pred, y_pred_prob, name='LightGBM'))\n","\n","y_pred_train = clf.predict(X_train_)\n","y_pred_prob_train = clf.predict_proba(X_train_)\n","metrics = metrics.append(\n","    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='LightGBM_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"7631c53b"},"source":["# Catboost "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"507846b8","outputId":"dac62bba-9506-4162-a8bc-4ecb6267ff0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate set to 0.10351\n","0:\tlearn: 0.5376462\ttest: 0.5370327\tbest: 0.5370327 (0)\ttotal: 194ms\tremaining: 3m 13s\n","2:\tlearn: 0.3442423\ttest: 0.3424119\tbest: 0.3424119 (2)\ttotal: 618ms\tremaining: 3m 25s\n","4:\tlearn: 0.2454176\ttest: 0.2427825\tbest: 0.2427825 (4)\ttotal: 859ms\tremaining: 2m 51s\n","6:\tlearn: 0.1890580\ttest: 0.1855906\tbest: 0.1855906 (6)\ttotal: 1.19s\tremaining: 2m 48s\n","8:\tlearn: 0.1599901\ttest: 0.1559084\tbest: 0.1559084 (8)\ttotal: 1.44s\tremaining: 2m 38s\n","10:\tlearn: 0.1427467\ttest: 0.1380386\tbest: 0.1380386 (10)\ttotal: 1.81s\tremaining: 2m 42s\n","12:\tlearn: 0.1297972\ttest: 0.1248159\tbest: 0.1248159 (12)\ttotal: 2.14s\tremaining: 2m 42s\n","14:\tlearn: 0.1235834\ttest: 0.1183105\tbest: 0.1183105 (14)\ttotal: 2.49s\tremaining: 2m 43s\n","16:\tlearn: 0.1181298\ttest: 0.1127023\tbest: 0.1127023 (16)\ttotal: 2.85s\tremaining: 2m 45s\n","18:\tlearn: 0.1155584\ttest: 0.1099959\tbest: 0.1099959 (18)\ttotal: 3.18s\tremaining: 2m 44s\n","20:\tlearn: 0.1133832\ttest: 0.1076488\tbest: 0.1076488 (20)\ttotal: 3.52s\tremaining: 2m 44s\n","22:\tlearn: 0.1118181\ttest: 0.1060083\tbest: 0.1060083 (22)\ttotal: 3.86s\tremaining: 2m 43s\n","24:\tlearn: 0.1103875\ttest: 0.1045977\tbest: 0.1045977 (24)\ttotal: 4.21s\tremaining: 2m 44s\n","26:\tlearn: 0.1092801\ttest: 0.1035695\tbest: 0.1035695 (26)\ttotal: 4.54s\tremaining: 2m 43s\n","28:\tlearn: 0.1085479\ttest: 0.1029461\tbest: 0.1029461 (28)\ttotal: 4.92s\tremaining: 2m 44s\n","30:\tlearn: 0.1078811\ttest: 0.1024681\tbest: 0.1024681 (30)\ttotal: 5.28s\tremaining: 2m 45s\n","32:\tlearn: 0.1073281\ttest: 0.1019926\tbest: 0.1019926 (32)\ttotal: 5.62s\tremaining: 2m 44s\n","34:\tlearn: 0.1068067\ttest: 0.1016048\tbest: 0.1016048 (34)\ttotal: 5.99s\tremaining: 2m 45s\n","36:\tlearn: 0.1062153\ttest: 0.1010725\tbest: 0.1010725 (36)\ttotal: 6.33s\tremaining: 2m 44s\n","38:\tlearn: 0.1058107\ttest: 0.1008230\tbest: 0.1008230 (38)\ttotal: 6.69s\tremaining: 2m 44s\n","40:\tlearn: 0.1052106\ttest: 0.1002473\tbest: 0.1002473 (40)\ttotal: 7.03s\tremaining: 2m 44s\n","42:\tlearn: 0.1047756\ttest: 0.0998941\tbest: 0.0998941 (42)\ttotal: 7.38s\tremaining: 2m 44s\n","44:\tlearn: 0.1042694\ttest: 0.0993478\tbest: 0.0993478 (44)\ttotal: 7.72s\tremaining: 2m 43s\n","46:\tlearn: 0.1039385\ttest: 0.0991626\tbest: 0.0991626 (46)\ttotal: 8.04s\tremaining: 2m 43s\n","48:\tlearn: 0.1034288\ttest: 0.0987447\tbest: 0.0987447 (48)\ttotal: 8.37s\tremaining: 2m 42s\n","50:\tlearn: 0.1030092\ttest: 0.0984008\tbest: 0.0984008 (50)\ttotal: 8.73s\tremaining: 2m 42s\n","52:\tlearn: 0.1025472\ttest: 0.0979786\tbest: 0.0979786 (52)\ttotal: 9.14s\tremaining: 2m 43s\n","54:\tlearn: 0.1021880\ttest: 0.0977878\tbest: 0.0977878 (54)\ttotal: 9.51s\tremaining: 2m 43s\n","56:\tlearn: 0.1018809\ttest: 0.0976583\tbest: 0.0976583 (56)\ttotal: 9.88s\tremaining: 2m 43s\n","58:\tlearn: 0.1010238\ttest: 0.0969020\tbest: 0.0969020 (58)\ttotal: 10.2s\tremaining: 2m 42s\n","60:\tlearn: 0.1007139\ttest: 0.0966741\tbest: 0.0966741 (60)\ttotal: 10.6s\tremaining: 2m 42s\n","62:\tlearn: 0.0999662\ttest: 0.0960558\tbest: 0.0960558 (62)\ttotal: 10.9s\tremaining: 2m 42s\n","64:\tlearn: 0.0997023\ttest: 0.0958675\tbest: 0.0958675 (64)\ttotal: 11.3s\tremaining: 2m 42s\n","66:\tlearn: 0.0993765\ttest: 0.0956234\tbest: 0.0956234 (66)\ttotal: 11.7s\tremaining: 2m 42s\n","68:\tlearn: 0.0990650\ttest: 0.0953425\tbest: 0.0953425 (68)\ttotal: 12.1s\tremaining: 2m 42s\n","70:\tlearn: 0.0988300\ttest: 0.0951977\tbest: 0.0951977 (70)\ttotal: 12.4s\tremaining: 2m 42s\n","72:\tlearn: 0.0985819\ttest: 0.0949949\tbest: 0.0949949 (72)\ttotal: 12.7s\tremaining: 2m 41s\n","74:\tlearn: 0.0983390\ttest: 0.0948063\tbest: 0.0948063 (74)\ttotal: 13.1s\tremaining: 2m 41s\n","76:\tlearn: 0.0981503\ttest: 0.0947348\tbest: 0.0947348 (76)\ttotal: 13.5s\tremaining: 2m 41s\n","78:\tlearn: 0.0979619\ttest: 0.0946250\tbest: 0.0946250 (78)\ttotal: 13.8s\tremaining: 2m 41s\n","80:\tlearn: 0.0976626\ttest: 0.0943382\tbest: 0.0943382 (80)\ttotal: 14.2s\tremaining: 2m 40s\n","82:\tlearn: 0.0974911\ttest: 0.0942220\tbest: 0.0942220 (82)\ttotal: 14.5s\tremaining: 2m 40s\n","84:\tlearn: 0.0973376\ttest: 0.0941363\tbest: 0.0941363 (84)\ttotal: 14.9s\tremaining: 2m 40s\n","86:\tlearn: 0.0971464\ttest: 0.0939745\tbest: 0.0939745 (86)\ttotal: 15.2s\tremaining: 2m 39s\n","88:\tlearn: 0.0969525\ttest: 0.0938501\tbest: 0.0938501 (88)\ttotal: 15.6s\tremaining: 2m 39s\n","90:\tlearn: 0.0968105\ttest: 0.0937737\tbest: 0.0937737 (90)\ttotal: 15.9s\tremaining: 2m 38s\n","92:\tlearn: 0.0967012\ttest: 0.0936787\tbest: 0.0936787 (92)\ttotal: 16.3s\tremaining: 2m 38s\n","94:\tlearn: 0.0965568\ttest: 0.0936366\tbest: 0.0936366 (94)\ttotal: 16.6s\tremaining: 2m 38s\n","96:\tlearn: 0.0965258\ttest: 0.0936418\tbest: 0.0936366 (94)\ttotal: 16.9s\tremaining: 2m 37s\n","98:\tlearn: 0.0963239\ttest: 0.0935047\tbest: 0.0935047 (98)\ttotal: 17.2s\tremaining: 2m 36s\n","100:\tlearn: 0.0960772\ttest: 0.0933014\tbest: 0.0933014 (100)\ttotal: 17.6s\tremaining: 2m 36s\n","102:\tlearn: 0.0959258\ttest: 0.0932457\tbest: 0.0932457 (102)\ttotal: 17.9s\tremaining: 2m 36s\n","104:\tlearn: 0.0957357\ttest: 0.0931229\tbest: 0.0931229 (104)\ttotal: 18.3s\tremaining: 2m 35s\n","106:\tlearn: 0.0955091\ttest: 0.0928691\tbest: 0.0928691 (106)\ttotal: 18.6s\tremaining: 2m 35s\n","108:\tlearn: 0.0953829\ttest: 0.0928077\tbest: 0.0928077 (108)\ttotal: 19s\tremaining: 2m 35s\n","110:\tlearn: 0.0952415\ttest: 0.0927123\tbest: 0.0927123 (110)\ttotal: 19.5s\tremaining: 2m 35s\n","112:\tlearn: 0.0949058\ttest: 0.0924192\tbest: 0.0924192 (112)\ttotal: 19.9s\tremaining: 2m 36s\n","114:\tlearn: 0.0947420\ttest: 0.0923133\tbest: 0.0923133 (114)\ttotal: 20.4s\tremaining: 2m 37s\n","116:\tlearn: 0.0946554\ttest: 0.0922941\tbest: 0.0922937 (115)\ttotal: 21.2s\tremaining: 2m 40s\n","118:\tlearn: 0.0945329\ttest: 0.0921653\tbest: 0.0921653 (118)\ttotal: 21.7s\tremaining: 2m 40s\n","120:\tlearn: 0.0944498\ttest: 0.0921175\tbest: 0.0921175 (120)\ttotal: 22.1s\tremaining: 2m 40s\n","122:\tlearn: 0.0943538\ttest: 0.0920727\tbest: 0.0920727 (122)\ttotal: 22.5s\tremaining: 2m 40s\n","124:\tlearn: 0.0941214\ttest: 0.0918842\tbest: 0.0918842 (124)\ttotal: 22.9s\tremaining: 2m 40s\n","126:\tlearn: 0.0938994\ttest: 0.0917348\tbest: 0.0917348 (126)\ttotal: 23.4s\tremaining: 2m 40s\n","128:\tlearn: 0.0937147\ttest: 0.0916558\tbest: 0.0916558 (128)\ttotal: 23.8s\tremaining: 2m 40s\n","130:\tlearn: 0.0936455\ttest: 0.0916566\tbest: 0.0916558 (128)\ttotal: 24.3s\tremaining: 2m 40s\n","132:\tlearn: 0.0934894\ttest: 0.0915515\tbest: 0.0915515 (132)\ttotal: 24.7s\tremaining: 2m 41s\n","134:\tlearn: 0.0934175\ttest: 0.0915212\tbest: 0.0915165 (133)\ttotal: 25.3s\tremaining: 2m 41s\n","136:\tlearn: 0.0932469\ttest: 0.0913680\tbest: 0.0913680 (136)\ttotal: 25.8s\tremaining: 2m 42s\n","138:\tlearn: 0.0931181\ttest: 0.0912641\tbest: 0.0912641 (138)\ttotal: 26.2s\tremaining: 2m 42s\n","140:\tlearn: 0.0928488\ttest: 0.0910455\tbest: 0.0910455 (140)\ttotal: 26.5s\tremaining: 2m 41s\n","142:\tlearn: 0.0927118\ttest: 0.0909412\tbest: 0.0909412 (142)\ttotal: 26.9s\tremaining: 2m 41s\n","144:\tlearn: 0.0925962\ttest: 0.0908581\tbest: 0.0908581 (144)\ttotal: 27.2s\tremaining: 2m 40s\n","146:\tlearn: 0.0923232\ttest: 0.0906835\tbest: 0.0906835 (146)\ttotal: 27.6s\tremaining: 2m 39s\n","148:\tlearn: 0.0921477\ttest: 0.0905922\tbest: 0.0905922 (148)\ttotal: 27.8s\tremaining: 2m 39s\n","150:\tlearn: 0.0920174\ttest: 0.0904542\tbest: 0.0904542 (150)\ttotal: 28.2s\tremaining: 2m 38s\n","152:\tlearn: 0.0919188\ttest: 0.0904362\tbest: 0.0904362 (152)\ttotal: 28.6s\tremaining: 2m 38s\n","154:\tlearn: 0.0918289\ttest: 0.0904118\tbest: 0.0904118 (154)\ttotal: 28.9s\tremaining: 2m 37s\n","156:\tlearn: 0.0917649\ttest: 0.0903808\tbest: 0.0903808 (156)\ttotal: 29.3s\tremaining: 2m 37s\n","158:\tlearn: 0.0916840\ttest: 0.0903628\tbest: 0.0903586 (157)\ttotal: 29.7s\tremaining: 2m 36s\n","160:\tlearn: 0.0915708\ttest: 0.0902794\tbest: 0.0902750 (159)\ttotal: 30s\tremaining: 2m 36s\n","162:\tlearn: 0.0915110\ttest: 0.0902691\tbest: 0.0902689 (161)\ttotal: 30.4s\tremaining: 2m 35s\n","164:\tlearn: 0.0911122\ttest: 0.0899399\tbest: 0.0899397 (163)\ttotal: 30.7s\tremaining: 2m 35s\n","166:\tlearn: 0.0910556\ttest: 0.0898768\tbest: 0.0898758 (165)\ttotal: 31.1s\tremaining: 2m 34s\n","168:\tlearn: 0.0909024\ttest: 0.0897971\tbest: 0.0897971 (168)\ttotal: 31.4s\tremaining: 2m 34s\n","170:\tlearn: 0.0907384\ttest: 0.0897267\tbest: 0.0897267 (170)\ttotal: 31.8s\tremaining: 2m 33s\n","172:\tlearn: 0.0906490\ttest: 0.0896457\tbest: 0.0896457 (172)\ttotal: 32.1s\tremaining: 2m 33s\n","174:\tlearn: 0.0904359\ttest: 0.0894695\tbest: 0.0894695 (174)\ttotal: 32.5s\tremaining: 2m 33s\n","176:\tlearn: 0.0903157\ttest: 0.0893799\tbest: 0.0893799 (176)\ttotal: 32.8s\tremaining: 2m 32s\n","178:\tlearn: 0.0902242\ttest: 0.0893624\tbest: 0.0893576 (177)\ttotal: 33.2s\tremaining: 2m 32s\n","180:\tlearn: 0.0901337\ttest: 0.0893030\tbest: 0.0893030 (180)\ttotal: 33.5s\tremaining: 2m 31s\n","182:\tlearn: 0.0899701\ttest: 0.0891040\tbest: 0.0891040 (182)\ttotal: 33.9s\tremaining: 2m 31s\n","184:\tlearn: 0.0898561\ttest: 0.0890610\tbest: 0.0890610 (184)\ttotal: 34.2s\tremaining: 2m 30s\n","186:\tlearn: 0.0898173\ttest: 0.0890550\tbest: 0.0890515 (185)\ttotal: 34.6s\tremaining: 2m 30s\n","188:\tlearn: 0.0897609\ttest: 0.0890225\tbest: 0.0890225 (188)\ttotal: 35s\tremaining: 2m 30s\n","190:\tlearn: 0.0896607\ttest: 0.0890347\tbest: 0.0890225 (188)\ttotal: 35.3s\tremaining: 2m 29s\n","192:\tlearn: 0.0894715\ttest: 0.0889617\tbest: 0.0889617 (192)\ttotal: 35.7s\tremaining: 2m 29s\n","194:\tlearn: 0.0894127\ttest: 0.0889241\tbest: 0.0889241 (194)\ttotal: 36s\tremaining: 2m 28s\n","196:\tlearn: 0.0892719\ttest: 0.0888446\tbest: 0.0888446 (196)\ttotal: 36.4s\tremaining: 2m 28s\n","198:\tlearn: 0.0891511\ttest: 0.0887750\tbest: 0.0887750 (198)\ttotal: 36.7s\tremaining: 2m 27s\n","200:\tlearn: 0.0890792\ttest: 0.0887232\tbest: 0.0887232 (200)\ttotal: 37.1s\tremaining: 2m 27s\n","202:\tlearn: 0.0889485\ttest: 0.0885730\tbest: 0.0885730 (202)\ttotal: 37.5s\tremaining: 2m 27s\n","204:\tlearn: 0.0888105\ttest: 0.0884625\tbest: 0.0884625 (204)\ttotal: 37.8s\tremaining: 2m 26s\n","206:\tlearn: 0.0887235\ttest: 0.0884264\tbest: 0.0884264 (206)\ttotal: 38.2s\tremaining: 2m 26s\n","208:\tlearn: 0.0885648\ttest: 0.0883068\tbest: 0.0883068 (208)\ttotal: 38.6s\tremaining: 2m 25s\n","210:\tlearn: 0.0884886\ttest: 0.0882483\tbest: 0.0882483 (210)\ttotal: 38.9s\tremaining: 2m 25s\n","212:\tlearn: 0.0883484\ttest: 0.0881131\tbest: 0.0881131 (212)\ttotal: 39.3s\tremaining: 2m 25s\n","214:\tlearn: 0.0882762\ttest: 0.0880818\tbest: 0.0880818 (214)\ttotal: 39.6s\tremaining: 2m 24s\n","216:\tlearn: 0.0881423\ttest: 0.0879650\tbest: 0.0879650 (216)\ttotal: 40s\tremaining: 2m 24s\n","218:\tlearn: 0.0879852\ttest: 0.0878518\tbest: 0.0878518 (218)\ttotal: 40.4s\tremaining: 2m 23s\n","220:\tlearn: 0.0878980\ttest: 0.0877858\tbest: 0.0877858 (220)\ttotal: 40.7s\tremaining: 2m 23s\n","222:\tlearn: 0.0876457\ttest: 0.0875057\tbest: 0.0875057 (222)\ttotal: 41.1s\tremaining: 2m 23s\n","224:\tlearn: 0.0875265\ttest: 0.0874332\tbest: 0.0874332 (224)\ttotal: 41.5s\tremaining: 2m 22s\n","226:\tlearn: 0.0874485\ttest: 0.0873791\tbest: 0.0873791 (226)\ttotal: 41.8s\tremaining: 2m 22s\n","228:\tlearn: 0.0873242\ttest: 0.0873662\tbest: 0.0873662 (228)\ttotal: 42.2s\tremaining: 2m 21s\n","230:\tlearn: 0.0871496\ttest: 0.0871868\tbest: 0.0871868 (230)\ttotal: 42.5s\tremaining: 2m 21s\n","232:\tlearn: 0.0870615\ttest: 0.0871190\tbest: 0.0871187 (231)\ttotal: 42.9s\tremaining: 2m 21s\n","234:\tlearn: 0.0868431\ttest: 0.0869008\tbest: 0.0869008 (234)\ttotal: 43.2s\tremaining: 2m 20s\n","236:\tlearn: 0.0867975\ttest: 0.0869069\tbest: 0.0869008 (234)\ttotal: 43.6s\tremaining: 2m 20s\n","238:\tlearn: 0.0866989\ttest: 0.0868758\tbest: 0.0868758 (238)\ttotal: 43.9s\tremaining: 2m 19s\n","240:\tlearn: 0.0866268\ttest: 0.0868199\tbest: 0.0868199 (240)\ttotal: 44.3s\tremaining: 2m 19s\n","242:\tlearn: 0.0862963\ttest: 0.0865401\tbest: 0.0865401 (242)\ttotal: 44.6s\tremaining: 2m 18s\n","244:\tlearn: 0.0862268\ttest: 0.0865268\tbest: 0.0865268 (244)\ttotal: 45s\tremaining: 2m 18s\n","246:\tlearn: 0.0861409\ttest: 0.0865028\tbest: 0.0865028 (246)\ttotal: 45.3s\tremaining: 2m 18s\n","248:\tlearn: 0.0860703\ttest: 0.0864752\tbest: 0.0864752 (248)\ttotal: 45.7s\tremaining: 2m 17s\n","250:\tlearn: 0.0858854\ttest: 0.0863814\tbest: 0.0863814 (250)\ttotal: 46s\tremaining: 2m 17s\n","252:\tlearn: 0.0857771\ttest: 0.0862856\tbest: 0.0862856 (252)\ttotal: 46.4s\tremaining: 2m 16s\n","254:\tlearn: 0.0857123\ttest: 0.0862946\tbest: 0.0862856 (252)\ttotal: 46.7s\tremaining: 2m 16s\n","256:\tlearn: 0.0856050\ttest: 0.0862334\tbest: 0.0862334 (256)\ttotal: 47.1s\tremaining: 2m 16s\n","258:\tlearn: 0.0855231\ttest: 0.0862174\tbest: 0.0862174 (258)\ttotal: 47.4s\tremaining: 2m 15s\n","260:\tlearn: 0.0853157\ttest: 0.0859729\tbest: 0.0859729 (260)\ttotal: 47.8s\tremaining: 2m 15s\n","262:\tlearn: 0.0851605\ttest: 0.0858544\tbest: 0.0858544 (262)\ttotal: 48.2s\tremaining: 2m 14s\n","264:\tlearn: 0.0850797\ttest: 0.0857870\tbest: 0.0857870 (264)\ttotal: 48.6s\tremaining: 2m 14s\n","266:\tlearn: 0.0849360\ttest: 0.0856805\tbest: 0.0856805 (266)\ttotal: 48.9s\tremaining: 2m 14s\n","268:\tlearn: 0.0848172\ttest: 0.0856342\tbest: 0.0856342 (268)\ttotal: 49.3s\tremaining: 2m 13s\n","270:\tlearn: 0.0847270\ttest: 0.0856008\tbest: 0.0856008 (270)\ttotal: 49.7s\tremaining: 2m 13s\n","272:\tlearn: 0.0846685\ttest: 0.0855021\tbest: 0.0855021 (272)\ttotal: 50s\tremaining: 2m 13s\n","274:\tlearn: 0.0845250\ttest: 0.0853960\tbest: 0.0853960 (274)\ttotal: 50.4s\tremaining: 2m 12s\n","276:\tlearn: 0.0844141\ttest: 0.0853440\tbest: 0.0853440 (276)\ttotal: 50.7s\tremaining: 2m 12s\n","278:\tlearn: 0.0843234\ttest: 0.0852447\tbest: 0.0852447 (278)\ttotal: 51.1s\tremaining: 2m 11s\n","280:\tlearn: 0.0842910\ttest: 0.0852387\tbest: 0.0852387 (279)\ttotal: 51.4s\tremaining: 2m 11s\n","282:\tlearn: 0.0842528\ttest: 0.0851758\tbest: 0.0851758 (282)\ttotal: 51.7s\tremaining: 2m 11s\n","284:\tlearn: 0.0841701\ttest: 0.0851516\tbest: 0.0851516 (284)\ttotal: 52.1s\tremaining: 2m 10s\n","286:\tlearn: 0.0840774\ttest: 0.0850768\tbest: 0.0850768 (286)\ttotal: 52.5s\tremaining: 2m 10s\n","288:\tlearn: 0.0839549\ttest: 0.0850233\tbest: 0.0850233 (288)\ttotal: 52.8s\tremaining: 2m 9s\n","290:\tlearn: 0.0837828\ttest: 0.0849055\tbest: 0.0849055 (290)\ttotal: 53.2s\tremaining: 2m 9s\n","292:\tlearn: 0.0837274\ttest: 0.0848976\tbest: 0.0848858 (291)\ttotal: 53.5s\tremaining: 2m 9s\n","294:\tlearn: 0.0836332\ttest: 0.0848630\tbest: 0.0848630 (294)\ttotal: 53.9s\tremaining: 2m 8s\n","296:\tlearn: 0.0835861\ttest: 0.0848503\tbest: 0.0848503 (296)\ttotal: 54.2s\tremaining: 2m 8s\n","298:\tlearn: 0.0834917\ttest: 0.0847686\tbest: 0.0847686 (298)\ttotal: 54.6s\tremaining: 2m 8s\n","300:\tlearn: 0.0833813\ttest: 0.0847076\tbest: 0.0847076 (300)\ttotal: 55s\tremaining: 2m 7s\n","302:\tlearn: 0.0832544\ttest: 0.0846630\tbest: 0.0846630 (302)\ttotal: 55.3s\tremaining: 2m 7s\n","304:\tlearn: 0.0832374\ttest: 0.0846568\tbest: 0.0846561 (303)\ttotal: 55.7s\tremaining: 2m 6s\n","306:\tlearn: 0.0831622\ttest: 0.0846315\tbest: 0.0846315 (306)\ttotal: 56.1s\tremaining: 2m 6s\n","308:\tlearn: 0.0830909\ttest: 0.0846170\tbest: 0.0846170 (308)\ttotal: 56.5s\tremaining: 2m 6s\n","310:\tlearn: 0.0830278\ttest: 0.0846228\tbest: 0.0846095 (309)\ttotal: 56.8s\tremaining: 2m 5s\n","312:\tlearn: 0.0829368\ttest: 0.0845071\tbest: 0.0845066 (311)\ttotal: 57.2s\tremaining: 2m 5s\n","314:\tlearn: 0.0829069\ttest: 0.0844883\tbest: 0.0844791 (313)\ttotal: 57.6s\tremaining: 2m 5s\n","316:\tlearn: 0.0828552\ttest: 0.0844690\tbest: 0.0844690 (316)\ttotal: 57.9s\tremaining: 2m 4s\n","318:\tlearn: 0.0828023\ttest: 0.0844307\tbest: 0.0844307 (318)\ttotal: 58.3s\tremaining: 2m 4s\n","320:\tlearn: 0.0827383\ttest: 0.0843705\tbest: 0.0843705 (320)\ttotal: 58.7s\tremaining: 2m 4s\n","322:\tlearn: 0.0825271\ttest: 0.0841692\tbest: 0.0841692 (322)\ttotal: 59s\tremaining: 2m 3s\n","324:\tlearn: 0.0825028\ttest: 0.0841640\tbest: 0.0841640 (324)\ttotal: 59.4s\tremaining: 2m 3s\n","326:\tlearn: 0.0824562\ttest: 0.0841210\tbest: 0.0841210 (326)\ttotal: 59.7s\tremaining: 2m 2s\n","328:\tlearn: 0.0823497\ttest: 0.0840741\tbest: 0.0840741 (328)\ttotal: 1m\tremaining: 2m 2s\n","330:\tlearn: 0.0822773\ttest: 0.0840663\tbest: 0.0840663 (330)\ttotal: 1m\tremaining: 2m 2s\n","332:\tlearn: 0.0822039\ttest: 0.0840540\tbest: 0.0840540 (332)\ttotal: 1m\tremaining: 2m 1s\n","334:\tlearn: 0.0820843\ttest: 0.0839768\tbest: 0.0839768 (334)\ttotal: 1m 1s\tremaining: 2m 1s\n","336:\tlearn: 0.0820191\ttest: 0.0839609\tbest: 0.0839609 (336)\ttotal: 1m 1s\tremaining: 2m\n","338:\tlearn: 0.0819201\ttest: 0.0838935\tbest: 0.0838935 (338)\ttotal: 1m 1s\tremaining: 2m\n","340:\tlearn: 0.0818365\ttest: 0.0838091\tbest: 0.0838091 (340)\ttotal: 1m 2s\tremaining: 2m\n","342:\tlearn: 0.0817522\ttest: 0.0836911\tbest: 0.0836911 (342)\ttotal: 1m 2s\tremaining: 1m 59s\n","344:\tlearn: 0.0816764\ttest: 0.0836567\tbest: 0.0836567 (344)\ttotal: 1m 2s\tremaining: 1m 59s\n","346:\tlearn: 0.0816229\ttest: 0.0836582\tbest: 0.0836536 (345)\ttotal: 1m 3s\tremaining: 1m 59s\n","348:\tlearn: 0.0815926\ttest: 0.0836157\tbest: 0.0836157 (348)\ttotal: 1m 3s\tremaining: 1m 58s\n","350:\tlearn: 0.0815268\ttest: 0.0835825\tbest: 0.0835825 (350)\ttotal: 1m 3s\tremaining: 1m 58s\n","352:\tlearn: 0.0813447\ttest: 0.0834491\tbest: 0.0834491 (352)\ttotal: 1m 4s\tremaining: 1m 57s\n","354:\tlearn: 0.0812940\ttest: 0.0834418\tbest: 0.0834418 (354)\ttotal: 1m 4s\tremaining: 1m 57s\n","356:\tlearn: 0.0811729\ttest: 0.0833891\tbest: 0.0833891 (356)\ttotal: 1m 5s\tremaining: 1m 57s\n","358:\tlearn: 0.0810657\ttest: 0.0833497\tbest: 0.0833497 (358)\ttotal: 1m 5s\tremaining: 1m 56s\n","360:\tlearn: 0.0809362\ttest: 0.0832311\tbest: 0.0832311 (360)\ttotal: 1m 5s\tremaining: 1m 56s\n","362:\tlearn: 0.0808686\ttest: 0.0831986\tbest: 0.0831986 (362)\ttotal: 1m 6s\tremaining: 1m 56s\n","364:\tlearn: 0.0808201\ttest: 0.0831568\tbest: 0.0831556 (363)\ttotal: 1m 6s\tremaining: 1m 55s\n","366:\tlearn: 0.0807178\ttest: 0.0830949\tbest: 0.0830949 (366)\ttotal: 1m 6s\tremaining: 1m 55s\n","368:\tlearn: 0.0806221\ttest: 0.0830331\tbest: 0.0830331 (368)\ttotal: 1m 7s\tremaining: 1m 54s\n","370:\tlearn: 0.0805343\ttest: 0.0829777\tbest: 0.0829777 (370)\ttotal: 1m 7s\tremaining: 1m 54s\n","372:\tlearn: 0.0804891\ttest: 0.0829509\tbest: 0.0829509 (372)\ttotal: 1m 7s\tremaining: 1m 54s\n","374:\tlearn: 0.0804503\ttest: 0.0829287\tbest: 0.0829287 (374)\ttotal: 1m 8s\tremaining: 1m 53s\n","376:\tlearn: 0.0803630\ttest: 0.0828739\tbest: 0.0828739 (376)\ttotal: 1m 8s\tremaining: 1m 53s\n","378:\tlearn: 0.0803317\ttest: 0.0828560\tbest: 0.0828560 (378)\ttotal: 1m 8s\tremaining: 1m 52s\n","380:\tlearn: 0.0801863\ttest: 0.0827806\tbest: 0.0827806 (380)\ttotal: 1m 9s\tremaining: 1m 52s\n","382:\tlearn: 0.0801497\ttest: 0.0827726\tbest: 0.0827726 (382)\ttotal: 1m 9s\tremaining: 1m 52s\n","384:\tlearn: 0.0800946\ttest: 0.0827386\tbest: 0.0827386 (384)\ttotal: 1m 10s\tremaining: 1m 51s\n","386:\tlearn: 0.0800112\ttest: 0.0826834\tbest: 0.0826834 (386)\ttotal: 1m 10s\tremaining: 1m 51s\n","388:\tlearn: 0.0799172\ttest: 0.0826556\tbest: 0.0826556 (388)\ttotal: 1m 10s\tremaining: 1m 51s\n","390:\tlearn: 0.0798796\ttest: 0.0826555\tbest: 0.0826517 (389)\ttotal: 1m 11s\tremaining: 1m 50s\n","392:\tlearn: 0.0798125\ttest: 0.0826293\tbest: 0.0826293 (392)\ttotal: 1m 11s\tremaining: 1m 50s\n","394:\tlearn: 0.0797792\ttest: 0.0826048\tbest: 0.0826048 (394)\ttotal: 1m 11s\tremaining: 1m 49s\n","396:\tlearn: 0.0797477\ttest: 0.0825993\tbest: 0.0825985 (395)\ttotal: 1m 12s\tremaining: 1m 49s\n","398:\tlearn: 0.0797098\ttest: 0.0825872\tbest: 0.0825872 (398)\ttotal: 1m 12s\tremaining: 1m 49s\n","400:\tlearn: 0.0795714\ttest: 0.0824960\tbest: 0.0824960 (400)\ttotal: 1m 12s\tremaining: 1m 48s\n","402:\tlearn: 0.0794985\ttest: 0.0824642\tbest: 0.0824621 (401)\ttotal: 1m 13s\tremaining: 1m 48s\n","404:\tlearn: 0.0794544\ttest: 0.0824348\tbest: 0.0824348 (404)\ttotal: 1m 13s\tremaining: 1m 48s\n","406:\tlearn: 0.0793462\ttest: 0.0823408\tbest: 0.0823385 (405)\ttotal: 1m 13s\tremaining: 1m 47s\n","408:\tlearn: 0.0793113\ttest: 0.0823261\tbest: 0.0823261 (408)\ttotal: 1m 14s\tremaining: 1m 47s\n","410:\tlearn: 0.0792257\ttest: 0.0822656\tbest: 0.0822656 (410)\ttotal: 1m 14s\tremaining: 1m 47s\n","412:\tlearn: 0.0791960\ttest: 0.0822481\tbest: 0.0822481 (412)\ttotal: 1m 15s\tremaining: 1m 46s\n","414:\tlearn: 0.0791623\ttest: 0.0822419\tbest: 0.0822419 (414)\ttotal: 1m 15s\tremaining: 1m 46s\n","416:\tlearn: 0.0791334\ttest: 0.0822432\tbest: 0.0822419 (414)\ttotal: 1m 15s\tremaining: 1m 45s\n","418:\tlearn: 0.0790520\ttest: 0.0821923\tbest: 0.0821923 (418)\ttotal: 1m 16s\tremaining: 1m 45s\n","420:\tlearn: 0.0790378\ttest: 0.0821995\tbest: 0.0821923 (418)\ttotal: 1m 16s\tremaining: 1m 45s\n","422:\tlearn: 0.0789686\ttest: 0.0821599\tbest: 0.0821599 (422)\ttotal: 1m 16s\tremaining: 1m 44s\n","424:\tlearn: 0.0789026\ttest: 0.0821451\tbest: 0.0821451 (424)\ttotal: 1m 17s\tremaining: 1m 44s\n","426:\tlearn: 0.0788857\ttest: 0.0821490\tbest: 0.0821451 (424)\ttotal: 1m 17s\tremaining: 1m 44s\n","428:\tlearn: 0.0788208\ttest: 0.0820951\tbest: 0.0820951 (428)\ttotal: 1m 17s\tremaining: 1m 43s\n","430:\tlearn: 0.0787109\ttest: 0.0819685\tbest: 0.0819685 (430)\ttotal: 1m 18s\tremaining: 1m 43s\n","432:\tlearn: 0.0786631\ttest: 0.0819362\tbest: 0.0819362 (432)\ttotal: 1m 18s\tremaining: 1m 42s\n","434:\tlearn: 0.0785546\ttest: 0.0818922\tbest: 0.0818892 (433)\ttotal: 1m 18s\tremaining: 1m 42s\n","436:\tlearn: 0.0785047\ttest: 0.0818517\tbest: 0.0818517 (436)\ttotal: 1m 19s\tremaining: 1m 42s\n","438:\tlearn: 0.0784391\ttest: 0.0818351\tbest: 0.0818292 (437)\ttotal: 1m 19s\tremaining: 1m 41s\n","440:\tlearn: 0.0783904\ttest: 0.0818185\tbest: 0.0818185 (440)\ttotal: 1m 20s\tremaining: 1m 41s\n","442:\tlearn: 0.0783672\ttest: 0.0817986\tbest: 0.0817986 (442)\ttotal: 1m 20s\tremaining: 1m 41s\n","444:\tlearn: 0.0783205\ttest: 0.0817847\tbest: 0.0817817 (443)\ttotal: 1m 20s\tremaining: 1m 40s\n","446:\tlearn: 0.0782819\ttest: 0.0817793\tbest: 0.0817793 (446)\ttotal: 1m 21s\tremaining: 1m 40s\n","448:\tlearn: 0.0782116\ttest: 0.0817054\tbest: 0.0817054 (448)\ttotal: 1m 21s\tremaining: 1m 39s\n","450:\tlearn: 0.0781368\ttest: 0.0816385\tbest: 0.0816385 (450)\ttotal: 1m 21s\tremaining: 1m 39s\n","452:\tlearn: 0.0779569\ttest: 0.0814964\tbest: 0.0814964 (452)\ttotal: 1m 22s\tremaining: 1m 39s\n","454:\tlearn: 0.0778935\ttest: 0.0814822\tbest: 0.0814822 (454)\ttotal: 1m 22s\tremaining: 1m 38s\n","456:\tlearn: 0.0778654\ttest: 0.0814730\tbest: 0.0814729 (455)\ttotal: 1m 22s\tremaining: 1m 38s\n","458:\tlearn: 0.0778089\ttest: 0.0814639\tbest: 0.0814639 (458)\ttotal: 1m 23s\tremaining: 1m 38s\n","460:\tlearn: 0.0777404\ttest: 0.0814316\tbest: 0.0814316 (460)\ttotal: 1m 23s\tremaining: 1m 37s\n","462:\tlearn: 0.0776876\ttest: 0.0814238\tbest: 0.0814238 (462)\ttotal: 1m 23s\tremaining: 1m 37s\n","464:\tlearn: 0.0776382\ttest: 0.0814141\tbest: 0.0814081 (463)\ttotal: 1m 24s\tremaining: 1m 36s\n","466:\tlearn: 0.0776304\ttest: 0.0814157\tbest: 0.0814081 (463)\ttotal: 1m 24s\tremaining: 1m 36s\n","468:\tlearn: 0.0775770\ttest: 0.0814061\tbest: 0.0814037 (467)\ttotal: 1m 25s\tremaining: 1m 36s\n","470:\tlearn: 0.0775247\ttest: 0.0813581\tbest: 0.0813581 (470)\ttotal: 1m 25s\tremaining: 1m 35s\n","472:\tlearn: 0.0774423\ttest: 0.0813363\tbest: 0.0813259 (471)\ttotal: 1m 25s\tremaining: 1m 35s\n","474:\tlearn: 0.0774217\ttest: 0.0813286\tbest: 0.0813259 (471)\ttotal: 1m 26s\tremaining: 1m 35s\n","476:\tlearn: 0.0773875\ttest: 0.0813358\tbest: 0.0813259 (471)\ttotal: 1m 26s\tremaining: 1m 34s\n","478:\tlearn: 0.0772607\ttest: 0.0812613\tbest: 0.0812613 (478)\ttotal: 1m 26s\tremaining: 1m 34s\n","480:\tlearn: 0.0772216\ttest: 0.0812386\tbest: 0.0812386 (480)\ttotal: 1m 27s\tremaining: 1m 33s\n","482:\tlearn: 0.0771537\ttest: 0.0812201\tbest: 0.0812201 (482)\ttotal: 1m 27s\tremaining: 1m 33s\n","484:\tlearn: 0.0770520\ttest: 0.0811552\tbest: 0.0811552 (484)\ttotal: 1m 27s\tremaining: 1m 33s\n","486:\tlearn: 0.0769170\ttest: 0.0810496\tbest: 0.0810496 (486)\ttotal: 1m 28s\tremaining: 1m 32s\n","488:\tlearn: 0.0769055\ttest: 0.0810505\tbest: 0.0810461 (487)\ttotal: 1m 28s\tremaining: 1m 32s\n","490:\tlearn: 0.0768524\ttest: 0.0810295\tbest: 0.0810295 (490)\ttotal: 1m 28s\tremaining: 1m 32s\n","492:\tlearn: 0.0768086\ttest: 0.0809865\tbest: 0.0809843 (491)\ttotal: 1m 29s\tremaining: 1m 31s\n","494:\tlearn: 0.0767751\ttest: 0.0809780\tbest: 0.0809780 (494)\ttotal: 1m 29s\tremaining: 1m 31s\n","496:\tlearn: 0.0767245\ttest: 0.0809423\tbest: 0.0809423 (496)\ttotal: 1m 29s\tremaining: 1m 31s\n","498:\tlearn: 0.0766779\ttest: 0.0809042\tbest: 0.0809042 (498)\ttotal: 1m 30s\tremaining: 1m 30s\n","500:\tlearn: 0.0766679\ttest: 0.0809032\tbest: 0.0809032 (500)\ttotal: 1m 30s\tremaining: 1m 30s\n","502:\tlearn: 0.0766479\ttest: 0.0808944\tbest: 0.0808928 (501)\ttotal: 1m 31s\tremaining: 1m 29s\n","504:\tlearn: 0.0766031\ttest: 0.0808312\tbest: 0.0808312 (504)\ttotal: 1m 31s\tremaining: 1m 29s\n","506:\tlearn: 0.0765449\ttest: 0.0808083\tbest: 0.0807981 (505)\ttotal: 1m 31s\tremaining: 1m 29s\n","508:\tlearn: 0.0764601\ttest: 0.0807525\tbest: 0.0807525 (508)\ttotal: 1m 32s\tremaining: 1m 28s\n","510:\tlearn: 0.0763903\ttest: 0.0807440\tbest: 0.0807440 (510)\ttotal: 1m 32s\tremaining: 1m 28s\n","512:\tlearn: 0.0763580\ttest: 0.0807457\tbest: 0.0807440 (510)\ttotal: 1m 32s\tremaining: 1m 28s\n","514:\tlearn: 0.0763166\ttest: 0.0807463\tbest: 0.0807440 (510)\ttotal: 1m 33s\tremaining: 1m 27s\n","516:\tlearn: 0.0762278\ttest: 0.0806899\tbest: 0.0806899 (516)\ttotal: 1m 33s\tremaining: 1m 27s\n","518:\tlearn: 0.0762094\ttest: 0.0806795\tbest: 0.0806795 (518)\ttotal: 1m 34s\tremaining: 1m 27s\n","520:\tlearn: 0.0761506\ttest: 0.0806732\tbest: 0.0806732 (520)\ttotal: 1m 34s\tremaining: 1m 26s\n","522:\tlearn: 0.0761241\ttest: 0.0806790\tbest: 0.0806722 (521)\ttotal: 1m 35s\tremaining: 1m 26s\n","524:\tlearn: 0.0760984\ttest: 0.0806812\tbest: 0.0806722 (521)\ttotal: 1m 35s\tremaining: 1m 26s\n","526:\tlearn: 0.0760271\ttest: 0.0805751\tbest: 0.0805751 (526)\ttotal: 1m 36s\tremaining: 1m 26s\n","528:\tlearn: 0.0759479\ttest: 0.0805704\tbest: 0.0805499 (527)\ttotal: 1m 36s\tremaining: 1m 25s\n","530:\tlearn: 0.0759152\ttest: 0.0805713\tbest: 0.0805499 (527)\ttotal: 1m 37s\tremaining: 1m 25s\n","532:\tlearn: 0.0758787\ttest: 0.0805613\tbest: 0.0805499 (527)\ttotal: 1m 37s\tremaining: 1m 25s\n","534:\tlearn: 0.0758678\ttest: 0.0805735\tbest: 0.0805499 (527)\ttotal: 1m 37s\tremaining: 1m 25s\n","536:\tlearn: 0.0757970\ttest: 0.0804977\tbest: 0.0804977 (536)\ttotal: 1m 38s\tremaining: 1m 24s\n","538:\tlearn: 0.0757763\ttest: 0.0804911\tbest: 0.0804911 (538)\ttotal: 1m 38s\tremaining: 1m 24s\n","540:\tlearn: 0.0757434\ttest: 0.0804640\tbest: 0.0804640 (540)\ttotal: 1m 38s\tremaining: 1m 23s\n","542:\tlearn: 0.0756595\ttest: 0.0803965\tbest: 0.0803965 (542)\ttotal: 1m 39s\tremaining: 1m 23s\n","544:\tlearn: 0.0756169\ttest: 0.0803618\tbest: 0.0803618 (544)\ttotal: 1m 39s\tremaining: 1m 23s\n","546:\tlearn: 0.0756016\ttest: 0.0803562\tbest: 0.0803562 (546)\ttotal: 1m 39s\tremaining: 1m 22s\n","548:\tlearn: 0.0755559\ttest: 0.0803572\tbest: 0.0803562 (546)\ttotal: 1m 40s\tremaining: 1m 22s\n","550:\tlearn: 0.0754758\ttest: 0.0803626\tbest: 0.0803498 (549)\ttotal: 1m 40s\tremaining: 1m 22s\n","552:\tlearn: 0.0754467\ttest: 0.0803615\tbest: 0.0803498 (549)\ttotal: 1m 41s\tremaining: 1m 21s\n","554:\tlearn: 0.0754022\ttest: 0.0803383\tbest: 0.0803371 (553)\ttotal: 1m 41s\tremaining: 1m 21s\n","556:\tlearn: 0.0752917\ttest: 0.0802910\tbest: 0.0802910 (556)\ttotal: 1m 41s\tremaining: 1m 20s\n","558:\tlearn: 0.0752811\ttest: 0.0802888\tbest: 0.0802888 (558)\ttotal: 1m 42s\tremaining: 1m 20s\n","560:\tlearn: 0.0751781\ttest: 0.0802131\tbest: 0.0802131 (560)\ttotal: 1m 42s\tremaining: 1m 20s\n","562:\tlearn: 0.0751376\ttest: 0.0801971\tbest: 0.0801956 (561)\ttotal: 1m 42s\tremaining: 1m 19s\n","564:\tlearn: 0.0750920\ttest: 0.0801570\tbest: 0.0801570 (564)\ttotal: 1m 43s\tremaining: 1m 19s\n","566:\tlearn: 0.0750373\ttest: 0.0801359\tbest: 0.0801359 (566)\ttotal: 1m 43s\tremaining: 1m 19s\n","568:\tlearn: 0.0750119\ttest: 0.0801139\tbest: 0.0801139 (568)\ttotal: 1m 43s\tremaining: 1m 18s\n","570:\tlearn: 0.0749568\ttest: 0.0800930\tbest: 0.0800930 (570)\ttotal: 1m 44s\tremaining: 1m 18s\n","572:\tlearn: 0.0749175\ttest: 0.0800731\tbest: 0.0800731 (572)\ttotal: 1m 44s\tremaining: 1m 17s\n","574:\tlearn: 0.0748316\ttest: 0.0799364\tbest: 0.0799364 (574)\ttotal: 1m 44s\tremaining: 1m 17s\n","576:\tlearn: 0.0747734\ttest: 0.0799209\tbest: 0.0799209 (576)\ttotal: 1m 45s\tremaining: 1m 17s\n","578:\tlearn: 0.0747533\ttest: 0.0799064\tbest: 0.0799064 (578)\ttotal: 1m 45s\tremaining: 1m 16s\n","580:\tlearn: 0.0746979\ttest: 0.0798638\tbest: 0.0798634 (579)\ttotal: 1m 46s\tremaining: 1m 16s\n","582:\tlearn: 0.0746024\ttest: 0.0798275\tbest: 0.0798233 (581)\ttotal: 1m 46s\tremaining: 1m 16s\n","584:\tlearn: 0.0745714\ttest: 0.0798250\tbest: 0.0798233 (581)\ttotal: 1m 46s\tremaining: 1m 15s\n","586:\tlearn: 0.0745431\ttest: 0.0798201\tbest: 0.0798201 (586)\ttotal: 1m 47s\tremaining: 1m 15s\n","588:\tlearn: 0.0744265\ttest: 0.0797573\tbest: 0.0797573 (588)\ttotal: 1m 47s\tremaining: 1m 15s\n","590:\tlearn: 0.0743960\ttest: 0.0797651\tbest: 0.0797573 (588)\ttotal: 1m 47s\tremaining: 1m 14s\n","592:\tlearn: 0.0743325\ttest: 0.0796766\tbest: 0.0796744 (591)\ttotal: 1m 48s\tremaining: 1m 14s\n","594:\tlearn: 0.0742914\ttest: 0.0795854\tbest: 0.0795854 (594)\ttotal: 1m 48s\tremaining: 1m 14s\n","596:\tlearn: 0.0742826\ttest: 0.0795832\tbest: 0.0795826 (595)\ttotal: 1m 49s\tremaining: 1m 13s\n","598:\tlearn: 0.0742583\ttest: 0.0795823\tbest: 0.0795807 (597)\ttotal: 1m 49s\tremaining: 1m 13s\n","600:\tlearn: 0.0742190\ttest: 0.0795595\tbest: 0.0795595 (600)\ttotal: 1m 49s\tremaining: 1m 12s\n","602:\tlearn: 0.0741568\ttest: 0.0794967\tbest: 0.0794967 (602)\ttotal: 1m 50s\tremaining: 1m 12s\n","604:\tlearn: 0.0740726\ttest: 0.0794579\tbest: 0.0794579 (604)\ttotal: 1m 50s\tremaining: 1m 12s\n","606:\tlearn: 0.0740164\ttest: 0.0794278\tbest: 0.0794278 (606)\ttotal: 1m 50s\tremaining: 1m 11s\n","608:\tlearn: 0.0739847\ttest: 0.0794081\tbest: 0.0794081 (608)\ttotal: 1m 51s\tremaining: 1m 11s\n","610:\tlearn: 0.0739632\ttest: 0.0794114\tbest: 0.0794081 (608)\ttotal: 1m 51s\tremaining: 1m 11s\n","612:\tlearn: 0.0738715\ttest: 0.0793656\tbest: 0.0793656 (612)\ttotal: 1m 52s\tremaining: 1m 10s\n","614:\tlearn: 0.0738504\ttest: 0.0793596\tbest: 0.0793596 (614)\ttotal: 1m 52s\tremaining: 1m 10s\n","616:\tlearn: 0.0738335\ttest: 0.0793538\tbest: 0.0793538 (616)\ttotal: 1m 52s\tremaining: 1m 9s\n","618:\tlearn: 0.0738132\ttest: 0.0793437\tbest: 0.0793411 (617)\ttotal: 1m 53s\tremaining: 1m 9s\n","620:\tlearn: 0.0736696\ttest: 0.0792747\tbest: 0.0792747 (620)\ttotal: 1m 53s\tremaining: 1m 9s\n","622:\tlearn: 0.0736261\ttest: 0.0792558\tbest: 0.0792549 (621)\ttotal: 1m 53s\tremaining: 1m 8s\n","624:\tlearn: 0.0736191\ttest: 0.0792533\tbest: 0.0792533 (624)\ttotal: 1m 54s\tremaining: 1m 8s\n","626:\tlearn: 0.0735356\ttest: 0.0791925\tbest: 0.0791925 (626)\ttotal: 1m 54s\tremaining: 1m 8s\n","628:\tlearn: 0.0735214\ttest: 0.0791917\tbest: 0.0791917 (628)\ttotal: 1m 54s\tremaining: 1m 7s\n","630:\tlearn: 0.0734455\ttest: 0.0791405\tbest: 0.0791405 (630)\ttotal: 1m 55s\tremaining: 1m 7s\n","632:\tlearn: 0.0734182\ttest: 0.0791376\tbest: 0.0791368 (631)\ttotal: 1m 55s\tremaining: 1m 7s\n","634:\tlearn: 0.0733272\ttest: 0.0790610\tbest: 0.0790610 (634)\ttotal: 1m 55s\tremaining: 1m 6s\n","636:\tlearn: 0.0732658\ttest: 0.0790383\tbest: 0.0790383 (636)\ttotal: 1m 56s\tremaining: 1m 6s\n","638:\tlearn: 0.0730675\ttest: 0.0788659\tbest: 0.0788659 (638)\ttotal: 1m 56s\tremaining: 1m 5s\n","640:\tlearn: 0.0729545\ttest: 0.0787753\tbest: 0.0787753 (640)\ttotal: 1m 56s\tremaining: 1m 5s\n","642:\tlearn: 0.0728497\ttest: 0.0786929\tbest: 0.0786929 (642)\ttotal: 1m 57s\tremaining: 1m 5s\n","644:\tlearn: 0.0727696\ttest: 0.0786393\tbest: 0.0786393 (644)\ttotal: 1m 57s\tremaining: 1m 4s\n","646:\tlearn: 0.0727135\ttest: 0.0786031\tbest: 0.0786031 (646)\ttotal: 1m 58s\tremaining: 1m 4s\n","648:\tlearn: 0.0726743\ttest: 0.0785754\tbest: 0.0785754 (648)\ttotal: 1m 58s\tremaining: 1m 4s\n","650:\tlearn: 0.0725845\ttest: 0.0785444\tbest: 0.0785444 (650)\ttotal: 1m 58s\tremaining: 1m 3s\n","652:\tlearn: 0.0725739\ttest: 0.0785460\tbest: 0.0785444 (650)\ttotal: 1m 59s\tremaining: 1m 3s\n","654:\tlearn: 0.0725080\ttest: 0.0785329\tbest: 0.0785329 (654)\ttotal: 1m 59s\tremaining: 1m 2s\n","656:\tlearn: 0.0725001\ttest: 0.0785339\tbest: 0.0785329 (654)\ttotal: 1m 59s\tremaining: 1m 2s\n","658:\tlearn: 0.0724645\ttest: 0.0785353\tbest: 0.0785329 (654)\ttotal: 2m\tremaining: 1m 2s\n","660:\tlearn: 0.0724558\ttest: 0.0785342\tbest: 0.0785329 (654)\ttotal: 2m\tremaining: 1m 1s\n","662:\tlearn: 0.0724257\ttest: 0.0785021\tbest: 0.0785012 (661)\ttotal: 2m\tremaining: 1m 1s\n","664:\tlearn: 0.0724066\ttest: 0.0785023\tbest: 0.0785012 (661)\ttotal: 2m 1s\tremaining: 1m 1s\n","666:\tlearn: 0.0723750\ttest: 0.0784774\tbest: 0.0784774 (666)\ttotal: 2m 1s\tremaining: 1m\n","668:\tlearn: 0.0723489\ttest: 0.0784669\tbest: 0.0784669 (668)\ttotal: 2m 1s\tremaining: 1m\n","670:\tlearn: 0.0722544\ttest: 0.0784231\tbest: 0.0784231 (670)\ttotal: 2m 2s\tremaining: 60s\n","672:\tlearn: 0.0722219\ttest: 0.0784081\tbest: 0.0784063 (671)\ttotal: 2m 2s\tremaining: 59.6s\n","674:\tlearn: 0.0721654\ttest: 0.0783944\tbest: 0.0783944 (674)\ttotal: 2m 3s\tremaining: 59.2s\n","676:\tlearn: 0.0721079\ttest: 0.0783917\tbest: 0.0783917 (676)\ttotal: 2m 3s\tremaining: 58.9s\n","678:\tlearn: 0.0720493\ttest: 0.0783664\tbest: 0.0783664 (678)\ttotal: 2m 3s\tremaining: 58.5s\n","680:\tlearn: 0.0720131\ttest: 0.0783434\tbest: 0.0783434 (680)\ttotal: 2m 4s\tremaining: 58.1s\n","682:\tlearn: 0.0719938\ttest: 0.0783503\tbest: 0.0783434 (680)\ttotal: 2m 4s\tremaining: 57.8s\n","684:\tlearn: 0.0718977\ttest: 0.0783262\tbest: 0.0783262 (684)\ttotal: 2m 4s\tremaining: 57.4s\n","686:\tlearn: 0.0718799\ttest: 0.0783022\tbest: 0.0783022 (686)\ttotal: 2m 5s\tremaining: 57s\n","688:\tlearn: 0.0718309\ttest: 0.0782746\tbest: 0.0782746 (688)\ttotal: 2m 5s\tremaining: 56.7s\n","690:\tlearn: 0.0718032\ttest: 0.0782664\tbest: 0.0782664 (690)\ttotal: 2m 5s\tremaining: 56.3s\n","692:\tlearn: 0.0717713\ttest: 0.0782703\tbest: 0.0782645 (691)\ttotal: 2m 6s\tremaining: 56s\n","694:\tlearn: 0.0717620\ttest: 0.0782717\tbest: 0.0782645 (691)\ttotal: 2m 6s\tremaining: 55.6s\n","696:\tlearn: 0.0716647\ttest: 0.0782406\tbest: 0.0782406 (696)\ttotal: 2m 7s\tremaining: 55.2s\n","698:\tlearn: 0.0716183\ttest: 0.0782264\tbest: 0.0782264 (698)\ttotal: 2m 7s\tremaining: 54.9s\n","700:\tlearn: 0.0716103\ttest: 0.0782288\tbest: 0.0782264 (698)\ttotal: 2m 7s\tremaining: 54.5s\n","702:\tlearn: 0.0715925\ttest: 0.0782232\tbest: 0.0782232 (702)\ttotal: 2m 8s\tremaining: 54.1s\n","704:\tlearn: 0.0715720\ttest: 0.0782213\tbest: 0.0782213 (704)\ttotal: 2m 8s\tremaining: 53.8s\n","706:\tlearn: 0.0715280\ttest: 0.0782019\tbest: 0.0782019 (706)\ttotal: 2m 8s\tremaining: 53.4s\n","708:\tlearn: 0.0715068\ttest: 0.0781901\tbest: 0.0781901 (708)\ttotal: 2m 9s\tremaining: 53s\n","710:\tlearn: 0.0714695\ttest: 0.0781925\tbest: 0.0781865 (709)\ttotal: 2m 9s\tremaining: 52.6s\n","712:\tlearn: 0.0714395\ttest: 0.0781499\tbest: 0.0781499 (712)\ttotal: 2m 9s\tremaining: 52.3s\n","714:\tlearn: 0.0714297\ttest: 0.0781521\tbest: 0.0781499 (712)\ttotal: 2m 10s\tremaining: 51.9s\n","716:\tlearn: 0.0714055\ttest: 0.0781598\tbest: 0.0781499 (712)\ttotal: 2m 10s\tremaining: 51.5s\n","718:\tlearn: 0.0713818\ttest: 0.0781569\tbest: 0.0781499 (712)\ttotal: 2m 10s\tremaining: 51.2s\n","720:\tlearn: 0.0713500\ttest: 0.0781540\tbest: 0.0781499 (712)\ttotal: 2m 11s\tremaining: 50.8s\n","722:\tlearn: 0.0713338\ttest: 0.0781532\tbest: 0.0781499 (712)\ttotal: 2m 11s\tremaining: 50.4s\n","724:\tlearn: 0.0712810\ttest: 0.0780980\tbest: 0.0780980 (724)\ttotal: 2m 12s\tremaining: 50.1s\n","726:\tlearn: 0.0712688\ttest: 0.0781013\tbest: 0.0780980 (724)\ttotal: 2m 12s\tremaining: 49.7s\n","728:\tlearn: 0.0712485\ttest: 0.0781004\tbest: 0.0780980 (724)\ttotal: 2m 12s\tremaining: 49.3s\n","730:\tlearn: 0.0711469\ttest: 0.0779762\tbest: 0.0779762 (730)\ttotal: 2m 13s\tremaining: 49s\n","732:\tlearn: 0.0711369\ttest: 0.0779687\tbest: 0.0779687 (732)\ttotal: 2m 13s\tremaining: 48.6s\n","734:\tlearn: 0.0711052\ttest: 0.0779694\tbest: 0.0779687 (732)\ttotal: 2m 13s\tremaining: 48.2s\n","736:\tlearn: 0.0710414\ttest: 0.0779479\tbest: 0.0779479 (736)\ttotal: 2m 14s\tremaining: 47.9s\n","738:\tlearn: 0.0710124\ttest: 0.0779434\tbest: 0.0779434 (738)\ttotal: 2m 14s\tremaining: 47.5s\n","740:\tlearn: 0.0709601\ttest: 0.0779283\tbest: 0.0779283 (740)\ttotal: 2m 14s\tremaining: 47.1s\n","742:\tlearn: 0.0709252\ttest: 0.0778746\tbest: 0.0778746 (742)\ttotal: 2m 15s\tremaining: 46.8s\n","744:\tlearn: 0.0708141\ttest: 0.0778090\tbest: 0.0778090 (744)\ttotal: 2m 15s\tremaining: 46.4s\n","746:\tlearn: 0.0707822\ttest: 0.0778054\tbest: 0.0778054 (746)\ttotal: 2m 15s\tremaining: 46.1s\n","748:\tlearn: 0.0707675\ttest: 0.0778095\tbest: 0.0778054 (746)\ttotal: 2m 16s\tremaining: 45.7s\n","750:\tlearn: 0.0707347\ttest: 0.0777721\tbest: 0.0777721 (750)\ttotal: 2m 16s\tremaining: 45.3s\n","752:\tlearn: 0.0707189\ttest: 0.0777726\tbest: 0.0777721 (750)\ttotal: 2m 17s\tremaining: 44.9s\n","754:\tlearn: 0.0706843\ttest: 0.0777623\tbest: 0.0777623 (754)\ttotal: 2m 17s\tremaining: 44.6s\n","756:\tlearn: 0.0706183\ttest: 0.0777181\tbest: 0.0777181 (756)\ttotal: 2m 17s\tremaining: 44.2s\n","758:\tlearn: 0.0706095\ttest: 0.0777088\tbest: 0.0777080 (757)\ttotal: 2m 18s\tremaining: 43.9s\n","760:\tlearn: 0.0705116\ttest: 0.0776418\tbest: 0.0776418 (760)\ttotal: 2m 18s\tremaining: 43.5s\n","762:\tlearn: 0.0704797\ttest: 0.0776162\tbest: 0.0776151 (761)\ttotal: 2m 18s\tremaining: 43.1s\n","764:\tlearn: 0.0704049\ttest: 0.0776148\tbest: 0.0776148 (764)\ttotal: 2m 19s\tremaining: 42.8s\n","766:\tlearn: 0.0703776\ttest: 0.0776140\tbest: 0.0776140 (766)\ttotal: 2m 19s\tremaining: 42.4s\n","768:\tlearn: 0.0703290\ttest: 0.0776004\tbest: 0.0776004 (768)\ttotal: 2m 19s\tremaining: 42s\n","770:\tlearn: 0.0702901\ttest: 0.0775865\tbest: 0.0775865 (770)\ttotal: 2m 20s\tremaining: 41.7s\n","772:\tlearn: 0.0702588\ttest: 0.0775701\tbest: 0.0775701 (772)\ttotal: 2m 20s\tremaining: 41.3s\n","774:\tlearn: 0.0702317\ttest: 0.0775671\tbest: 0.0775671 (774)\ttotal: 2m 20s\tremaining: 40.9s\n","776:\tlearn: 0.0702001\ttest: 0.0775836\tbest: 0.0775671 (774)\ttotal: 2m 21s\tremaining: 40.5s\n","778:\tlearn: 0.0701384\ttest: 0.0774962\tbest: 0.0774951 (777)\ttotal: 2m 21s\tremaining: 40.2s\n","780:\tlearn: 0.0700923\ttest: 0.0774891\tbest: 0.0774888 (779)\ttotal: 2m 22s\tremaining: 39.8s\n","782:\tlearn: 0.0700549\ttest: 0.0774919\tbest: 0.0774888 (779)\ttotal: 2m 22s\tremaining: 39.5s\n","784:\tlearn: 0.0700453\ttest: 0.0774848\tbest: 0.0774848 (784)\ttotal: 2m 22s\tremaining: 39.1s\n","786:\tlearn: 0.0700183\ttest: 0.0774783\tbest: 0.0774783 (786)\ttotal: 2m 23s\tremaining: 38.7s\n","788:\tlearn: 0.0699740\ttest: 0.0774733\tbest: 0.0774733 (788)\ttotal: 2m 23s\tremaining: 38.4s\n","790:\tlearn: 0.0699046\ttest: 0.0774423\tbest: 0.0774423 (790)\ttotal: 2m 23s\tremaining: 38s\n","792:\tlearn: 0.0698811\ttest: 0.0774242\tbest: 0.0774242 (792)\ttotal: 2m 24s\tremaining: 37.6s\n","794:\tlearn: 0.0698534\ttest: 0.0773908\tbest: 0.0773908 (794)\ttotal: 2m 24s\tremaining: 37.3s\n","796:\tlearn: 0.0698252\ttest: 0.0773711\tbest: 0.0773623 (795)\ttotal: 2m 24s\tremaining: 36.9s\n","798:\tlearn: 0.0697633\ttest: 0.0773145\tbest: 0.0773133 (797)\ttotal: 2m 25s\tremaining: 36.5s\n","800:\tlearn: 0.0697419\ttest: 0.0773134\tbest: 0.0773075 (799)\ttotal: 2m 25s\tremaining: 36.2s\n","802:\tlearn: 0.0697068\ttest: 0.0772914\tbest: 0.0772914 (802)\ttotal: 2m 26s\tremaining: 35.8s\n","804:\tlearn: 0.0696945\ttest: 0.0772846\tbest: 0.0772846 (804)\ttotal: 2m 26s\tremaining: 35.5s\n","806:\tlearn: 0.0696530\ttest: 0.0772713\tbest: 0.0772713 (806)\ttotal: 2m 26s\tremaining: 35.1s\n","808:\tlearn: 0.0696209\ttest: 0.0772579\tbest: 0.0772571 (807)\ttotal: 2m 27s\tremaining: 34.7s\n","810:\tlearn: 0.0696185\ttest: 0.0772620\tbest: 0.0772571 (807)\ttotal: 2m 27s\tremaining: 34.4s\n","812:\tlearn: 0.0695773\ttest: 0.0772278\tbest: 0.0772278 (812)\ttotal: 2m 27s\tremaining: 34s\n","814:\tlearn: 0.0695437\ttest: 0.0772269\tbest: 0.0772266 (813)\ttotal: 2m 28s\tremaining: 33.6s\n","816:\tlearn: 0.0694968\ttest: 0.0771876\tbest: 0.0771876 (816)\ttotal: 2m 28s\tremaining: 33.3s\n","818:\tlearn: 0.0694846\ttest: 0.0771819\tbest: 0.0771819 (818)\ttotal: 2m 28s\tremaining: 32.9s\n","820:\tlearn: 0.0694510\ttest: 0.0771564\tbest: 0.0771561 (819)\ttotal: 2m 29s\tremaining: 32.5s\n","822:\tlearn: 0.0694222\ttest: 0.0771527\tbest: 0.0771527 (822)\ttotal: 2m 29s\tremaining: 32.2s\n","824:\tlearn: 0.0693579\ttest: 0.0771038\tbest: 0.0771038 (824)\ttotal: 2m 29s\tremaining: 31.8s\n","826:\tlearn: 0.0692795\ttest: 0.0770519\tbest: 0.0770519 (826)\ttotal: 2m 30s\tremaining: 31.4s\n","828:\tlearn: 0.0692216\ttest: 0.0770496\tbest: 0.0770496 (828)\ttotal: 2m 30s\tremaining: 31.1s\n","830:\tlearn: 0.0691826\ttest: 0.0770274\tbest: 0.0770274 (830)\ttotal: 2m 30s\tremaining: 30.7s\n","832:\tlearn: 0.0691630\ttest: 0.0770227\tbest: 0.0770227 (832)\ttotal: 2m 31s\tremaining: 30.3s\n","834:\tlearn: 0.0691497\ttest: 0.0770158\tbest: 0.0770158 (834)\ttotal: 2m 31s\tremaining: 30s\n","836:\tlearn: 0.0691141\ttest: 0.0770136\tbest: 0.0770125 (835)\ttotal: 2m 32s\tremaining: 29.6s\n","838:\tlearn: 0.0690785\ttest: 0.0769937\tbest: 0.0769937 (838)\ttotal: 2m 32s\tremaining: 29.3s\n","840:\tlearn: 0.0690488\ttest: 0.0769826\tbest: 0.0769826 (840)\ttotal: 2m 32s\tremaining: 28.9s\n","842:\tlearn: 0.0690162\ttest: 0.0769545\tbest: 0.0769545 (842)\ttotal: 2m 33s\tremaining: 28.5s\n","844:\tlearn: 0.0689670\ttest: 0.0769471\tbest: 0.0769471 (844)\ttotal: 2m 33s\tremaining: 28.2s\n","846:\tlearn: 0.0689639\ttest: 0.0769418\tbest: 0.0769414 (845)\ttotal: 2m 33s\tremaining: 27.8s\n","848:\tlearn: 0.0689250\ttest: 0.0769229\tbest: 0.0769229 (848)\ttotal: 2m 34s\tremaining: 27.4s\n","850:\tlearn: 0.0689138\ttest: 0.0769241\tbest: 0.0769226 (849)\ttotal: 2m 34s\tremaining: 27.1s\n","852:\tlearn: 0.0688848\ttest: 0.0769099\tbest: 0.0769099 (852)\ttotal: 2m 34s\tremaining: 26.7s\n","854:\tlearn: 0.0688719\ttest: 0.0769019\tbest: 0.0769019 (854)\ttotal: 2m 35s\tremaining: 26.3s\n","856:\tlearn: 0.0688452\ttest: 0.0769051\tbest: 0.0769019 (854)\ttotal: 2m 35s\tremaining: 26s\n","858:\tlearn: 0.0688134\ttest: 0.0768890\tbest: 0.0768890 (857)\ttotal: 2m 35s\tremaining: 25.6s\n","860:\tlearn: 0.0687895\ttest: 0.0768826\tbest: 0.0768797 (859)\ttotal: 2m 36s\tremaining: 25.2s\n","862:\tlearn: 0.0687653\ttest: 0.0768588\tbest: 0.0768540 (861)\ttotal: 2m 36s\tremaining: 24.9s\n","864:\tlearn: 0.0687472\ttest: 0.0768568\tbest: 0.0768540 (861)\ttotal: 2m 37s\tremaining: 24.5s\n","866:\tlearn: 0.0687449\ttest: 0.0768567\tbest: 0.0768540 (861)\ttotal: 2m 37s\tremaining: 24.1s\n","868:\tlearn: 0.0686960\ttest: 0.0768403\tbest: 0.0768403 (868)\ttotal: 2m 37s\tremaining: 23.8s\n","870:\tlearn: 0.0686817\ttest: 0.0768165\tbest: 0.0768165 (870)\ttotal: 2m 38s\tremaining: 23.4s\n","872:\tlearn: 0.0686406\ttest: 0.0768003\tbest: 0.0768003 (872)\ttotal: 2m 38s\tremaining: 23s\n","874:\tlearn: 0.0685996\ttest: 0.0767615\tbest: 0.0767615 (874)\ttotal: 2m 38s\tremaining: 22.7s\n","876:\tlearn: 0.0685836\ttest: 0.0767444\tbest: 0.0767444 (876)\ttotal: 2m 39s\tremaining: 22.3s\n","878:\tlearn: 0.0685418\ttest: 0.0767246\tbest: 0.0767246 (878)\ttotal: 2m 39s\tremaining: 22s\n","880:\tlearn: 0.0684194\ttest: 0.0766973\tbest: 0.0766973 (880)\ttotal: 2m 39s\tremaining: 21.6s\n","882:\tlearn: 0.0684005\ttest: 0.0766860\tbest: 0.0766860 (882)\ttotal: 2m 40s\tremaining: 21.2s\n","884:\tlearn: 0.0683668\ttest: 0.0766774\tbest: 0.0766754 (883)\ttotal: 2m 40s\tremaining: 20.9s\n","886:\tlearn: 0.0683211\ttest: 0.0766624\tbest: 0.0766616 (885)\ttotal: 2m 40s\tremaining: 20.5s\n","888:\tlearn: 0.0683042\ttest: 0.0766650\tbest: 0.0766616 (887)\ttotal: 2m 41s\tremaining: 20.1s\n","890:\tlearn: 0.0682866\ttest: 0.0766668\tbest: 0.0766616 (887)\ttotal: 2m 41s\tremaining: 19.8s\n","892:\tlearn: 0.0682466\ttest: 0.0766628\tbest: 0.0766616 (887)\ttotal: 2m 42s\tremaining: 19.4s\n","894:\tlearn: 0.0682219\ttest: 0.0766596\tbest: 0.0766582 (893)\ttotal: 2m 42s\tremaining: 19.1s\n","896:\tlearn: 0.0682156\ttest: 0.0766580\tbest: 0.0766580 (896)\ttotal: 2m 42s\tremaining: 18.7s\n","898:\tlearn: 0.0681932\ttest: 0.0766662\tbest: 0.0766580 (896)\ttotal: 2m 43s\tremaining: 18.3s\n","900:\tlearn: 0.0681442\ttest: 0.0766470\tbest: 0.0766470 (900)\ttotal: 2m 43s\tremaining: 18s\n","902:\tlearn: 0.0681221\ttest: 0.0766457\tbest: 0.0766455 (901)\ttotal: 2m 43s\tremaining: 17.6s\n","904:\tlearn: 0.0680982\ttest: 0.0766408\tbest: 0.0766400 (903)\ttotal: 2m 44s\tremaining: 17.2s\n","906:\tlearn: 0.0680247\ttest: 0.0765802\tbest: 0.0765802 (906)\ttotal: 2m 44s\tremaining: 16.9s\n","908:\tlearn: 0.0679778\ttest: 0.0765656\tbest: 0.0765649 (907)\ttotal: 2m 44s\tremaining: 16.5s\n","910:\tlearn: 0.0679614\ttest: 0.0765714\tbest: 0.0765649 (907)\ttotal: 2m 45s\tremaining: 16.2s\n","912:\tlearn: 0.0679294\ttest: 0.0765702\tbest: 0.0765649 (907)\ttotal: 2m 45s\tremaining: 15.8s\n","914:\tlearn: 0.0679158\ttest: 0.0765689\tbest: 0.0765649 (907)\ttotal: 2m 46s\tremaining: 15.4s\n","916:\tlearn: 0.0678662\ttest: 0.0765445\tbest: 0.0765445 (916)\ttotal: 2m 46s\tremaining: 15.1s\n","918:\tlearn: 0.0678037\ttest: 0.0765017\tbest: 0.0765017 (918)\ttotal: 2m 46s\tremaining: 14.7s\n","920:\tlearn: 0.0677558\ttest: 0.0764833\tbest: 0.0764833 (920)\ttotal: 2m 47s\tremaining: 14.3s\n","922:\tlearn: 0.0677171\ttest: 0.0764819\tbest: 0.0764819 (922)\ttotal: 2m 47s\tremaining: 14s\n","924:\tlearn: 0.0676695\ttest: 0.0764690\tbest: 0.0764690 (924)\ttotal: 2m 47s\tremaining: 13.6s\n","926:\tlearn: 0.0676380\ttest: 0.0764601\tbest: 0.0764601 (926)\ttotal: 2m 48s\tremaining: 13.2s\n","928:\tlearn: 0.0676110\ttest: 0.0764440\tbest: 0.0764440 (928)\ttotal: 2m 48s\tremaining: 12.9s\n","930:\tlearn: 0.0675754\ttest: 0.0764378\tbest: 0.0764378 (930)\ttotal: 2m 48s\tremaining: 12.5s\n","932:\tlearn: 0.0675566\ttest: 0.0764406\tbest: 0.0764378 (930)\ttotal: 2m 49s\tremaining: 12.2s\n","934:\tlearn: 0.0675175\ttest: 0.0764258\tbest: 0.0764258 (934)\ttotal: 2m 49s\tremaining: 11.8s\n","936:\tlearn: 0.0674898\ttest: 0.0764138\tbest: 0.0764138 (936)\ttotal: 2m 49s\tremaining: 11.4s\n","938:\tlearn: 0.0674559\ttest: 0.0764062\tbest: 0.0764062 (938)\ttotal: 2m 50s\tremaining: 11.1s\n","940:\tlearn: 0.0674424\ttest: 0.0764069\tbest: 0.0764062 (938)\ttotal: 2m 50s\tremaining: 10.7s\n","942:\tlearn: 0.0674350\ttest: 0.0764098\tbest: 0.0764062 (938)\ttotal: 2m 51s\tremaining: 10.3s\n","944:\tlearn: 0.0673891\ttest: 0.0763925\tbest: 0.0763925 (944)\ttotal: 2m 51s\tremaining: 9.97s\n","946:\tlearn: 0.0673582\ttest: 0.0763681\tbest: 0.0763681 (946)\ttotal: 2m 51s\tremaining: 9.61s\n","948:\tlearn: 0.0673296\ttest: 0.0763573\tbest: 0.0763573 (948)\ttotal: 2m 52s\tremaining: 9.25s\n","950:\tlearn: 0.0673079\ttest: 0.0763432\tbest: 0.0763432 (950)\ttotal: 2m 52s\tremaining: 8.89s\n","952:\tlearn: 0.0672935\ttest: 0.0763292\tbest: 0.0763292 (952)\ttotal: 2m 52s\tremaining: 8.52s\n","954:\tlearn: 0.0672647\ttest: 0.0763250\tbest: 0.0763250 (954)\ttotal: 2m 53s\tremaining: 8.16s\n","956:\tlearn: 0.0672500\ttest: 0.0763258\tbest: 0.0763237 (955)\ttotal: 2m 53s\tremaining: 7.8s\n","958:\tlearn: 0.0672162\ttest: 0.0762985\tbest: 0.0762985 (958)\ttotal: 2m 53s\tremaining: 7.43s\n","960:\tlearn: 0.0671985\ttest: 0.0762988\tbest: 0.0762971 (959)\ttotal: 2m 54s\tremaining: 7.07s\n","962:\tlearn: 0.0671731\ttest: 0.0762891\tbest: 0.0762891 (962)\ttotal: 2m 54s\tremaining: 6.71s\n","964:\tlearn: 0.0671500\ttest: 0.0762669\tbest: 0.0762669 (964)\ttotal: 2m 55s\tremaining: 6.35s\n","966:\tlearn: 0.0670688\ttest: 0.0762324\tbest: 0.0762324 (966)\ttotal: 2m 55s\tremaining: 5.99s\n","968:\tlearn: 0.0670383\ttest: 0.0761927\tbest: 0.0761927 (968)\ttotal: 2m 55s\tremaining: 5.62s\n","970:\tlearn: 0.0670016\ttest: 0.0761878\tbest: 0.0761878 (970)\ttotal: 2m 56s\tremaining: 5.26s\n","972:\tlearn: 0.0669794\ttest: 0.0761701\tbest: 0.0761701 (972)\ttotal: 2m 56s\tremaining: 4.9s\n","974:\tlearn: 0.0669568\ttest: 0.0761605\tbest: 0.0761605 (974)\ttotal: 2m 56s\tremaining: 4.53s\n","976:\tlearn: 0.0669303\ttest: 0.0761564\tbest: 0.0761564 (976)\ttotal: 2m 57s\tremaining: 4.17s\n","978:\tlearn: 0.0668933\ttest: 0.0760934\tbest: 0.0760934 (978)\ttotal: 2m 57s\tremaining: 3.81s\n","980:\tlearn: 0.0668702\ttest: 0.0760964\tbest: 0.0760886 (979)\ttotal: 2m 57s\tremaining: 3.45s\n","982:\tlearn: 0.0668402\ttest: 0.0761047\tbest: 0.0760886 (979)\ttotal: 2m 58s\tremaining: 3.08s\n","984:\tlearn: 0.0668173\ttest: 0.0760993\tbest: 0.0760886 (979)\ttotal: 2m 58s\tremaining: 2.72s\n","986:\tlearn: 0.0668131\ttest: 0.0760989\tbest: 0.0760886 (979)\ttotal: 2m 59s\tremaining: 2.36s\n","988:\tlearn: 0.0667386\ttest: 0.0760492\tbest: 0.0760492 (988)\ttotal: 2m 59s\tremaining: 2s\n","990:\tlearn: 0.0667158\ttest: 0.0760294\tbest: 0.0760294 (990)\ttotal: 2m 59s\tremaining: 1.63s\n","992:\tlearn: 0.0666895\ttest: 0.0760236\tbest: 0.0760236 (992)\ttotal: 3m\tremaining: 1.27s\n","994:\tlearn: 0.0666721\ttest: 0.0760046\tbest: 0.0760046 (994)\ttotal: 3m\tremaining: 907ms\n","996:\tlearn: 0.0666338\ttest: 0.0760009\tbest: 0.0760009 (996)\ttotal: 3m\tremaining: 544ms\n","998:\tlearn: 0.0666166\ttest: 0.0759908\tbest: 0.0759908 (998)\ttotal: 3m 1s\tremaining: 181ms\n","999:\tlearn: 0.0665986\ttest: 0.0759931\tbest: 0.0759908 (998)\ttotal: 3m 1s\tremaining: 0us\n","\n","bestTest = 0.07599083394\n","bestIteration = 998\n","\n","Shrink model to first 999 iterations.\n"]},{"data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7fa2626ced50>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["cat_features = ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', \n","            'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', \n","            'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID']\n","\n","clf = CatBoostClassifier(random_state=RAND,\\\n","                         scale_pos_weight = percent_of_negative_class,\n","                         cat_features = cat_features)\n","\n","eval_set = [(X_val, y_val)]\n","\n","clf.fit(X_train_,\n","        y_train_,\n","        eval_set=eval_set,\n","        early_stopping_rounds=100,\n","        verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"7daf56a4","outputId":"72be5dc6-d7b8-4de4-9adf-79a94e6f4381"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-6f6ef21a-92ad-4023-8155-16f5db97bafc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost</td>\n","      <td>0.973192</td>\n","      <td>0.861562</td>\n","      <td>0.904762</td>\n","      <td>0.072704</td>\n","      <td>0.134593</td>\n","      <td>0.100149</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost_train</td>\n","      <td>0.971720</td>\n","      <td>0.861385</td>\n","      <td>0.879479</td>\n","      <td>0.074115</td>\n","      <td>0.136709</td>\n","      <td>0.103957</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM</td>\n","      <td>0.975496</td>\n","      <td>0.930576</td>\n","      <td>0.875000</td>\n","      <td>0.169643</td>\n","      <td>0.284188</td>\n","      <td>0.079913</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM_train</td>\n","      <td>0.975775</td>\n","      <td>0.954605</td>\n","      <td>0.909297</td>\n","      <td>0.220148</td>\n","      <td>0.354475</td>\n","      <td>0.074276</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost</td>\n","      <td>0.977874</td>\n","      <td>0.928530</td>\n","      <td>0.868313</td>\n","      <td>0.269133</td>\n","      <td>0.410906</td>\n","      <td>0.075150</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost_train</td>\n","      <td>0.979424</td>\n","      <td>0.952206</td>\n","      <td>0.946237</td>\n","      <td>0.338183</td>\n","      <td>0.498281</td>\n","      <td>0.068209</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f6ef21a-92ad-4023-8155-16f5db97bafc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f6ef21a-92ad-4023-8155-16f5db97bafc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f6ef21a-92ad-4023-8155-16f5db97bafc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","0                   XGBoost  0.973192  0.861562   0.904762  0.072704   \n","0             XGBoost_train  0.971720  0.861385   0.879479  0.074115   \n","0                  LightGBM  0.975496  0.930576   0.875000  0.169643   \n","0            LightGBM_train  0.975775  0.954605   0.909297  0.220148   \n","0                  Catboost  0.977874  0.928530   0.868313  0.269133   \n","0            Catboost_train  0.979424  0.952206   0.946237  0.338183   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  \n","0  0.134593  0.100149  \n","0  0.136709  0.103957  \n","0  0.284188  0.079913  \n","0  0.354475  0.074276  \n","0  0.410906  0.075150  \n","0  0.498281  0.068209  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf.predict(X_test)\n","y_pred_prob = clf.predict_proba(X_test)\n","metrics = metrics.append(\n","    get_metrics(y_test, y_pred, y_pred_prob, name='Catboost'))\n","\n","y_pred_train = clf.predict(X_train_)\n","y_pred_prob_train = clf.predict_proba(X_train_)\n","metrics = metrics.append(\n","    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='Catboost_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"a419ccb2"},"source":["# Gradient boosting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"045e013f","outputId":"50417507-26a2-4393-fb2b-939f24c86b4e"},"outputs":[{"data":{"text/plain":["GradientBoostingClassifier(random_state=10)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["clf = GradientBoostingClassifier(random_state=RAND)\n","clf.fit(X_train_bin, y_train_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"f0d83269","outputId":"f723a4a9-5fc2-4aa7-da70-85725e10e8f6"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e8ef8a02-a8b2-41bc-a31f-4fa5b8bab64b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost</td>\n","      <td>0.973192</td>\n","      <td>0.861562</td>\n","      <td>0.904762</td>\n","      <td>0.072704</td>\n","      <td>0.134593</td>\n","      <td>0.100149</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost_train</td>\n","      <td>0.971720</td>\n","      <td>0.861385</td>\n","      <td>0.879479</td>\n","      <td>0.074115</td>\n","      <td>0.136709</td>\n","      <td>0.103957</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM</td>\n","      <td>0.975496</td>\n","      <td>0.930576</td>\n","      <td>0.875000</td>\n","      <td>0.169643</td>\n","      <td>0.284188</td>\n","      <td>0.079913</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM_train</td>\n","      <td>0.975775</td>\n","      <td>0.954605</td>\n","      <td>0.909297</td>\n","      <td>0.220148</td>\n","      <td>0.354475</td>\n","      <td>0.074276</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost</td>\n","      <td>0.977874</td>\n","      <td>0.928530</td>\n","      <td>0.868313</td>\n","      <td>0.269133</td>\n","      <td>0.410906</td>\n","      <td>0.075150</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost_train</td>\n","      <td>0.979424</td>\n","      <td>0.952206</td>\n","      <td>0.946237</td>\n","      <td>0.338183</td>\n","      <td>0.498281</td>\n","      <td>0.068209</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Gradient_Boosting</td>\n","      <td>0.974399</td>\n","      <td>0.860162</td>\n","      <td>0.850000</td>\n","      <td>0.130102</td>\n","      <td>0.225664</td>\n","      <td>0.098675</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Gradient_Boosting_train</td>\n","      <td>0.973514</td>\n","      <td>0.856629</td>\n","      <td>0.874622</td>\n","      <td>0.134714</td>\n","      <td>0.233468</td>\n","      <td>0.100951</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ef8a02-a8b2-41bc-a31f-4fa5b8bab64b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e8ef8a02-a8b2-41bc-a31f-4fa5b8bab64b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e8ef8a02-a8b2-41bc-a31f-4fa5b8bab64b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","0                   XGBoost  0.973192  0.861562   0.904762  0.072704   \n","0             XGBoost_train  0.971720  0.861385   0.879479  0.074115   \n","0                  LightGBM  0.975496  0.930576   0.875000  0.169643   \n","0            LightGBM_train  0.975775  0.954605   0.909297  0.220148   \n","0                  Catboost  0.977874  0.928530   0.868313  0.269133   \n","0            Catboost_train  0.979424  0.952206   0.946237  0.338183   \n","0         Gradient_Boosting  0.974399  0.860162   0.850000  0.130102   \n","0   Gradient_Boosting_train  0.973514  0.856629   0.874622  0.134714   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  \n","0  0.134593  0.100149  \n","0  0.136709  0.103957  \n","0  0.284188  0.079913  \n","0  0.354475  0.074276  \n","0  0.410906  0.075150  \n","0  0.498281  0.068209  \n","0  0.225664  0.098675  \n","0  0.233468  0.100951  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf.predict(X_test_bin)\n","y_pred_prob = clf.predict_proba(X_test_bin)\n","metrics = metrics.append(\n","    get_metrics(y_test, y_pred, y_pred_prob, name='Gradient_Boosting'))\n","\n","y_pred_train = clf.predict(X_train_bin)\n","y_pred_prob_train = clf.predict_proba(X_train_bin)\n","metrics = metrics.append(\n","    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='Gradient_Boosting_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"7598a4ba"},"source":["# kNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4bdf202","outputId":"d6ad9a8e-1c02-4a3e-bf55-3893920317ed"},"outputs":[{"data":{"text/plain":["KNeighborsClassifier()"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["clf = KNeighborsClassifier()\n","clf.fit(X_train_bin_scaled, y_train_bin)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"1797660f","outputId":"2274f813-2187-423e-d5a8-0d8729629458"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f6ec3649-3b3a-4e26-a6c6-beda73720490\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>Accuracy</th>\n","      <th>ROC_AUC</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>f1</th>\n","      <th>Logloss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression</td>\n","      <td>0.768753</td>\n","      <td>0.876500</td>\n","      <td>0.093498</td>\n","      <td>0.812500</td>\n","      <td>0.167698</td>\n","      <td>0.438062</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LogisticRegression_train</td>\n","      <td>0.769455</td>\n","      <td>0.889472</td>\n","      <td>0.100677</td>\n","      <td>0.844579</td>\n","      <td>0.179908</td>\n","      <td>0.437340</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree</td>\n","      <td>0.969206</td>\n","      <td>0.747928</td>\n","      <td>0.466357</td>\n","      <td>0.512755</td>\n","      <td>0.488457</td>\n","      <td>1.036513</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Decision_tree_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest</td>\n","      <td>0.974290</td>\n","      <td>0.937556</td>\n","      <td>0.651685</td>\n","      <td>0.221939</td>\n","      <td>0.331113</td>\n","      <td>0.109669</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Random_forest_train</td>\n","      <td>0.998983</td>\n","      <td>0.999997</td>\n","      <td>0.967147</td>\n","      <td>1.000000</td>\n","      <td>0.983299</td>\n","      <td>0.002193</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier</td>\n","      <td>0.973558</td>\n","      <td>0.870698</td>\n","      <td>0.744000</td>\n","      <td>0.118622</td>\n","      <td>0.204620</td>\n","      <td>0.096452</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Bagging_classifier_train</td>\n","      <td>0.972204</td>\n","      <td>0.879720</td>\n","      <td>0.733333</td>\n","      <td>0.112611</td>\n","      <td>0.195240</td>\n","      <td>0.098379</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost</td>\n","      <td>0.973192</td>\n","      <td>0.861562</td>\n","      <td>0.904762</td>\n","      <td>0.072704</td>\n","      <td>0.134593</td>\n","      <td>0.100149</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>XGBoost_train</td>\n","      <td>0.971720</td>\n","      <td>0.861385</td>\n","      <td>0.879479</td>\n","      <td>0.074115</td>\n","      <td>0.136709</td>\n","      <td>0.103957</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM</td>\n","      <td>0.975496</td>\n","      <td>0.930576</td>\n","      <td>0.875000</td>\n","      <td>0.169643</td>\n","      <td>0.284188</td>\n","      <td>0.079913</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LightGBM_train</td>\n","      <td>0.975775</td>\n","      <td>0.954605</td>\n","      <td>0.909297</td>\n","      <td>0.220148</td>\n","      <td>0.354475</td>\n","      <td>0.074276</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost</td>\n","      <td>0.977874</td>\n","      <td>0.928530</td>\n","      <td>0.868313</td>\n","      <td>0.269133</td>\n","      <td>0.410906</td>\n","      <td>0.075150</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Catboost_train</td>\n","      <td>0.979424</td>\n","      <td>0.952206</td>\n","      <td>0.946237</td>\n","      <td>0.338183</td>\n","      <td>0.498281</td>\n","      <td>0.068209</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Gradient_Boosting</td>\n","      <td>0.974399</td>\n","      <td>0.860162</td>\n","      <td>0.850000</td>\n","      <td>0.130102</td>\n","      <td>0.225664</td>\n","      <td>0.098675</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Gradient_Boosting_train</td>\n","      <td>0.973514</td>\n","      <td>0.856629</td>\n","      <td>0.874622</td>\n","      <td>0.134714</td>\n","      <td>0.233468</td>\n","      <td>0.100951</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>kNN</td>\n","      <td>0.972717</td>\n","      <td>0.718276</td>\n","      <td>0.588785</td>\n","      <td>0.160714</td>\n","      <td>0.252505</td>\n","      <td>0.533837</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>kNN_train</td>\n","      <td>0.975444</td>\n","      <td>0.976953</td>\n","      <td>0.812955</td>\n","      <td>0.233597</td>\n","      <td>0.362913</td>\n","      <td>0.053914</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6ec3649-3b3a-4e26-a6c6-beda73720490')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6ec3649-3b3a-4e26-a6c6-beda73720490 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6ec3649-3b3a-4e26-a6c6-beda73720490');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n","0        LogisticRegression  0.768753  0.876500   0.093498  0.812500   \n","0  LogisticRegression_train  0.769455  0.889472   0.100677  0.844579   \n","0             Decision_tree  0.969206  0.747928   0.466357  0.512755   \n","0       Decision_tree_train  0.998983  0.999997   0.967147  1.000000   \n","0             Random_forest  0.974290  0.937556   0.651685  0.221939   \n","0       Random_forest_train  0.998983  0.999997   0.967147  1.000000   \n","0        Bagging_classifier  0.973558  0.870698   0.744000  0.118622   \n","0  Bagging_classifier_train  0.972204  0.879720   0.733333  0.112611   \n","0                   XGBoost  0.973192  0.861562   0.904762  0.072704   \n","0             XGBoost_train  0.971720  0.861385   0.879479  0.074115   \n","0                  LightGBM  0.975496  0.930576   0.875000  0.169643   \n","0            LightGBM_train  0.975775  0.954605   0.909297  0.220148   \n","0                  Catboost  0.977874  0.928530   0.868313  0.269133   \n","0            Catboost_train  0.979424  0.952206   0.946237  0.338183   \n","0         Gradient_Boosting  0.974399  0.860162   0.850000  0.130102   \n","0   Gradient_Boosting_train  0.973514  0.856629   0.874622  0.134714   \n","0                       kNN  0.972717  0.718276   0.588785  0.160714   \n","0                 kNN_train  0.975444  0.976953   0.812955  0.233597   \n","\n","         f1   Logloss  \n","0  0.167698  0.438062  \n","0  0.179908  0.437340  \n","0  0.488457  1.036513  \n","0  0.983299  0.002193  \n","0  0.331113  0.109669  \n","0  0.983299  0.002193  \n","0  0.204620  0.096452  \n","0  0.195240  0.098379  \n","0  0.134593  0.100149  \n","0  0.136709  0.103957  \n","0  0.284188  0.079913  \n","0  0.354475  0.074276  \n","0  0.410906  0.075150  \n","0  0.498281  0.068209  \n","0  0.225664  0.098675  \n","0  0.233468  0.100951  \n","0  0.252505  0.533837  \n","0  0.362913  0.053914  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = clf.predict(X_test_bin_scaled)\n","y_pred_prob = clf.predict_proba(X_test_bin_scaled)\n","metrics = metrics.append(\n","    get_metrics(y_test_bin, y_pred, y_pred_prob, name='kNN'))\n","\n","y_pred_train = clf.predict(X_train_bin_scaled)\n","y_pred_prob_train = clf.predict_proba(X_train_bin_scaled)\n","metrics = metrics.append(\n","    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='kNN_train'))\n","\n","metrics"]},{"cell_type":"markdown","metadata":{"id":"44b57bee"},"source":["# Выводы"]},{"cell_type":"markdown","metadata":{"id":"516ffc32"},"source":["Итак, качество базового алгоритма будем ориентироваться на:\n","\n","1) метрику f1, т.к. она является критерием оценивания в соревновании\n","\n","1) значение метрик roc_auc, logloss на тестовой выборке\n","\n","2) разрыв между метриками f1, roc_auc, log_loss на тренировочной и тестовой выборках \n","\n","На другие метрики особо смотреть не будем, но их полезно выводить, чтобы лучше контролироовать адекватность происходящего. Так, recall, precision и занулятся, если все объекты выборки будут отнесены к одному классу. Это довольно редкая ситуация, поэтому обратить на неё внимание было бы неплохо. Единственной полностью бесполезной метрикой, конечно, является accuracy в силу дисбаланса классов\n","\n","Исходя из этих соображений, по таблице можно понять, что лучшие результаты дали LightGBM и Catboost, для них мы и будем подбирать гиперпараметры"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}