{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8280dcc1",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3a8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
    "    precision_recall_curve, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RAND = 10\n",
    "percent_of_negative_class = 0.958"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d487ef",
   "metadata": {},
   "source": [
    "# Метод для подсчёта метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c68d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name):\n",
    "    df_metrics = pd.DataFrame()\n",
    "    \n",
    "    df_metrics['model'] = [name]\n",
    "    \n",
    "    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n",
    "    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:,1])]\n",
    "    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n",
    "    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n",
    "    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n",
    "    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a4a43",
   "metadata": {},
   "source": [
    "# Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15fb3e",
   "metadata": {},
   "source": [
    "Выгрузим данные, сохранённые на этапе EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db2dfaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEMESTER</th>\n",
       "      <th>DISC_ID</th>\n",
       "      <th>TYPE_NAME</th>\n",
       "      <th>DEBT</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CITIZENSHIP</th>\n",
       "      <th>EXAM_TYPE</th>\n",
       "      <th>EXAM_SUBJECT_1</th>\n",
       "      <th>EXAM_SUBJECT_2</th>\n",
       "      <th>EXAM_SUBJECT_3</th>\n",
       "      <th>ADMITTED_EXAM_1</th>\n",
       "      <th>ADMITTED_EXAM_2</th>\n",
       "      <th>ADMITTED_EXAM_3</th>\n",
       "      <th>ADMITTED_SUBJECT_PRIZE_LEVEL</th>\n",
       "      <th>REGION_ID</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10502311854018326223</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1601392918367593206</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9559803959325174929</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8955667882044263414</td>\n",
       "      <td>Зачет</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17741967398854095262</td>\n",
       "      <td>Экзамен</td>\n",
       "      <td>0</td>\n",
       "      <td>М</td>\n",
       "      <td>15601729049989747827</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>70786669040476600</td>\n",
       "      <td>5533732657842394915</td>\n",
       "      <td>8388269026169219461</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>ЕГЭ</td>\n",
       "      <td>7805492244297918082</td>\n",
       "      <td>82.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEMESTER               DISC_ID TYPE_NAME  DEBT GENDER  \\\n",
       "0         1  10502311854018326223     Зачет     0      М   \n",
       "1         1   1601392918367593206     Зачет     0      М   \n",
       "2         1   9559803959325174929     Зачет     0      М   \n",
       "3         1   8955667882044263414     Зачет     0      М   \n",
       "4         1  17741967398854095262   Экзамен     0      М   \n",
       "\n",
       "            CITIZENSHIP EXAM_TYPE     EXAM_SUBJECT_1       EXAM_SUBJECT_2  \\\n",
       "0  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "1  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "2  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "3  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "4  15601729049989747827       ЕГЭ  70786669040476600  5533732657842394915   \n",
       "\n",
       "        EXAM_SUBJECT_3  ADMITTED_EXAM_1  ADMITTED_EXAM_2  ADMITTED_EXAM_3  \\\n",
       "0  8388269026169219461             78.0             79.0             91.0   \n",
       "1  8388269026169219461             78.0             79.0             91.0   \n",
       "2  8388269026169219461             78.0             79.0             91.0   \n",
       "3  8388269026169219461             78.0             79.0             91.0   \n",
       "4  8388269026169219461             78.0             79.0             91.0   \n",
       "\n",
       "  ADMITTED_SUBJECT_PRIZE_LEVEL            REGION_ID  mean_score  \n",
       "0                          ЕГЭ  7805492244297918082   82.666667  \n",
       "1                          ЕГЭ  7805492244297918082   82.666667  \n",
       "2                          ЕГЭ  7805492244297918082   82.666667  \n",
       "3                          ЕГЭ  7805492244297918082   82.666667  \n",
       "4                          ЕГЭ  7805492244297918082   82.666667  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052630c4",
   "metadata": {},
   "source": [
    "## Бинаризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d3001",
   "metadata": {},
   "source": [
    "Проведём бинаризацию датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4a6f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEMESTER</th>\n",
       "      <th>DEBT</th>\n",
       "      <th>ADMITTED_EXAM_1</th>\n",
       "      <th>ADMITTED_EXAM_2</th>\n",
       "      <th>ADMITTED_EXAM_3</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>DISC_ID_57659945070201404</th>\n",
       "      <th>DISC_ID_81203412138540191</th>\n",
       "      <th>DISC_ID_119954623639665579</th>\n",
       "      <th>DISC_ID_150957394596913708</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_ID_15874707964024214396</th>\n",
       "      <th>REGION_ID_15990212999969728230</th>\n",
       "      <th>REGION_ID_16228771858762793341</th>\n",
       "      <th>REGION_ID_16416166836247151845</th>\n",
       "      <th>REGION_ID_16856079058758621152</th>\n",
       "      <th>REGION_ID_16925236604731044042</th>\n",
       "      <th>REGION_ID_17119224547502736839</th>\n",
       "      <th>REGION_ID_17341978997214072207</th>\n",
       "      <th>REGION_ID_17696900483302278054</th>\n",
       "      <th>REGION_ID_17759417206326758158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1076 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEMESTER  DEBT  ADMITTED_EXAM_1  ADMITTED_EXAM_2  ADMITTED_EXAM_3  \\\n",
       "0         1     0             78.0             79.0             91.0   \n",
       "1         1     0             78.0             79.0             91.0   \n",
       "2         1     0             78.0             79.0             91.0   \n",
       "3         1     0             78.0             79.0             91.0   \n",
       "4         1     0             78.0             79.0             91.0   \n",
       "\n",
       "   mean_score  DISC_ID_57659945070201404  DISC_ID_81203412138540191  \\\n",
       "0   82.666667                          0                          0   \n",
       "1   82.666667                          0                          0   \n",
       "2   82.666667                          0                          0   \n",
       "3   82.666667                          0                          0   \n",
       "4   82.666667                          0                          0   \n",
       "\n",
       "   DISC_ID_119954623639665579  DISC_ID_150957394596913708  ...  \\\n",
       "0                           0                           0  ...   \n",
       "1                           0                           0  ...   \n",
       "2                           0                           0  ...   \n",
       "3                           0                           0  ...   \n",
       "4                           0                           0  ...   \n",
       "\n",
       "   REGION_ID_15874707964024214396  REGION_ID_15990212999969728230  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   REGION_ID_16228771858762793341  REGION_ID_16416166836247151845  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   REGION_ID_16856079058758621152  REGION_ID_16925236604731044042  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   REGION_ID_17119224547502736839  REGION_ID_17341978997214072207  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "\n",
       "   REGION_ID_17696900483302278054  REGION_ID_17759417206326758158  \n",
       "0                               0                               0  \n",
       "1                               0                               0  \n",
       "2                               0                               0  \n",
       "3                               0                               0  \n",
       "4                               0                               0  \n",
       "\n",
       "[5 rows x 1076 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin = pd.get_dummies(df, drop_first=True)\n",
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945dd771",
   "metadata": {},
   "source": [
    "## Разбиение на train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b96cc",
   "metadata": {},
   "source": [
    "Разобьём датафрейм на обучающую и тестовую выборки для обоих датафреймов (бинаризованного и небинаризованного, чтобы в зависимости от модели подавать на вход тот или иной вариант)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22adee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.drop(columns = ['DEBT'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_cols,\n",
    "                                                    df['DEBT'],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d4733a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_bin = df_bin.drop(columns = ['DEBT'])\n",
    "\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(feature_cols_bin,\n",
    "                                                    df_bin['DEBT'],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ea60f",
   "metadata": {},
   "source": [
    "## Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ee81e",
   "metadata": {},
   "source": [
    "Приведём все признаки к одной шкале с помощью MinMaxScaler для бинаризованных данных - это будет третья и последняя вариация формата наших выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ec26d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = MinMaxScaler()\n",
    "X_train_bin_scaled = st.fit_transform(X_train_bin)\n",
    "X_test_bin_scaled = st.transform(X_test_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c8e2aa",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bdf908",
   "metadata": {},
   "source": [
    "Приступим к обучению наших бейзлайн моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "275199e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=RAND)\n",
    "lr.fit(X_train_bin_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56175b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0  LogisticRegression  0.697817  0.742184   0.095195  0.637509  0.165653   \n",
       "\n",
       "    Logloss  \n",
       "0  0.566596  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_bin_scaled)\n",
    "y_pred_prob = lr.predict_proba(X_test_bin_scaled)\n",
    "metrics = get_metrics(y_test, y_pred, y_pred_prob, name='LogisticRegression')\n",
    "\n",
    "y_pred_train = lr.predict(X_train_bin_scaled)\n",
    "y_pred_prob_train = lr.predict_proba(X_train_bin_scaled)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='LogisticRegression_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371f86f",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3654ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', random_state=10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=RAND)\n",
    "dt.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef91894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0   LogisticRegression  0.697817  0.742184   0.095195  0.637509  0.165653   \n",
       "0        Decision_tree  0.946593  0.788852   0.450146  0.609431  0.517816   \n",
       "0  Decision_tree_train  0.991081  0.999807   0.842620  0.998770  0.914074   \n",
       "\n",
       "    Logloss  \n",
       "0  0.566596  \n",
       "0  1.536115  \n",
       "0  0.017985  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dt.predict(X_test_bin)\n",
    "y_pred_prob = dt.predict_proba(X_test_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test_bin, y_pred, y_pred_prob, name='Decision_tree'))\n",
    "\n",
    "y_pred_train = dt.predict(X_train_bin)\n",
    "y_pred_prob_train = dt.predict_proba(X_train_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='Decision_tree_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c01c97",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f0f2051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "                       random_state=10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', bootstrap=False, random_state=RAND)\n",
    "rf.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa112a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy   ROC_AUC  Precision    Recall        f1  \\\n",
       "0   LogisticRegression  0.697817  0.742184   0.095195  0.637509  0.165653   \n",
       "0        Decision_tree  0.946593  0.788852   0.450146  0.609431  0.517816   \n",
       "0  Decision_tree_train  0.991081  0.999807   0.842620  0.998770  0.914074   \n",
       "0        Random_forest  0.951912  0.884939   0.481091  0.279338  0.353450   \n",
       "0  Random_forest_train  0.991081  0.999807   0.842620  0.998770  0.914074   \n",
       "\n",
       "    Logloss  \n",
       "0  0.566596  \n",
       "0  1.536115  \n",
       "0  0.017985  \n",
       "0  0.351344  \n",
       "0  0.017991  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_bin)\n",
    "y_pred_prob = rf.predict_proba(X_test_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test_bin, y_pred, y_pred_prob, name='Random_forest'))\n",
    "\n",
    "y_pred_train = rf.predict(X_train_bin)\n",
    "y_pred_prob_train = rf.predict_proba(X_train_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='Random_forest_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2134b9",
   "metadata": {},
   "source": [
    "# Bagging classifier (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89350aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), random_state=10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = BaggingClassifier(base_estimator=LogisticRegression(),\n",
    "                      random_state=RAND)\n",
    "bg.fit(pd.DataFrame(X_train_bin_scaled), y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "152c6ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bg.predict(X_test_bin_scaled)\n",
    "y_pred_prob = bg.predict_proba(X_test_bin_scaled)\n",
    "metrics = metrics.append(get_metrics(y_test, y_pred, y_pred_prob, name='Bagging_classifier'))\n",
    "\n",
    "y_pred_train = bg.predict(X_train_bin_scaled)\n",
    "y_pred_prob_train = bg.predict_proba(X_train_bin_scaled)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train, y_pred_train, y_pred_prob_train, name='Bagging_classifier_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725bfd7",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93bdfa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.69734\n",
      "[2]\tvalidation_0-auc:0.72105\n",
      "[4]\tvalidation_0-auc:0.74048\n",
      "[6]\tvalidation_0-auc:0.74580\n",
      "[8]\tvalidation_0-auc:0.75601\n",
      "[10]\tvalidation_0-auc:0.75828\n",
      "[12]\tvalidation_0-auc:0.76750\n",
      "[14]\tvalidation_0-auc:0.76876\n",
      "[16]\tvalidation_0-auc:0.77103\n",
      "[18]\tvalidation_0-auc:0.77443\n",
      "[20]\tvalidation_0-auc:0.77507\n",
      "[22]\tvalidation_0-auc:0.77632\n",
      "[24]\tvalidation_0-auc:0.77696\n",
      "[26]\tvalidation_0-auc:0.78338\n",
      "[28]\tvalidation_0-auc:0.78232\n",
      "[30]\tvalidation_0-auc:0.78480\n",
      "[32]\tvalidation_0-auc:0.78465\n",
      "[34]\tvalidation_0-auc:0.78492\n",
      "[36]\tvalidation_0-auc:0.78507\n",
      "[38]\tvalidation_0-auc:0.78566\n",
      "[40]\tvalidation_0-auc:0.78953\n",
      "[42]\tvalidation_0-auc:0.79314\n",
      "[44]\tvalidation_0-auc:0.79386\n",
      "[46]\tvalidation_0-auc:0.79243\n",
      "[48]\tvalidation_0-auc:0.79742\n",
      "[50]\tvalidation_0-auc:0.79807\n",
      "[52]\tvalidation_0-auc:0.79788\n",
      "[54]\tvalidation_0-auc:0.79828\n",
      "[56]\tvalidation_0-auc:0.79781\n",
      "[58]\tvalidation_0-auc:0.79959\n",
      "[60]\tvalidation_0-auc:0.79861\n",
      "[62]\tvalidation_0-auc:0.79902\n",
      "[64]\tvalidation_0-auc:0.80379\n",
      "[66]\tvalidation_0-auc:0.80688\n",
      "[68]\tvalidation_0-auc:0.80794\n",
      "[70]\tvalidation_0-auc:0.80931\n",
      "[72]\tvalidation_0-auc:0.80954\n",
      "[74]\tvalidation_0-auc:0.81006\n",
      "[76]\tvalidation_0-auc:0.81037\n",
      "[78]\tvalidation_0-auc:0.80993\n",
      "[80]\tvalidation_0-auc:0.80992\n",
      "[82]\tvalidation_0-auc:0.80984\n",
      "[84]\tvalidation_0-auc:0.80932\n",
      "[86]\tvalidation_0-auc:0.80964\n",
      "[88]\tvalidation_0-auc:0.80912\n",
      "[90]\tvalidation_0-auc:0.80961\n",
      "[92]\tvalidation_0-auc:0.81014\n",
      "[94]\tvalidation_0-auc:0.80992\n",
      "[96]\tvalidation_0-auc:0.80950\n",
      "[98]\tvalidation_0-auc:0.80953\n",
      "[99]\tvalidation_0-auc:0.81139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=10,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=20.27659574468085,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выборки для проверки после каждой итерации обучения\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train_bin,\n",
    "                                                    y_train_bin,\n",
    "                                                    test_size=0.16,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RAND)\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clf = XGBClassifier(random_state=RAND, scale_pos_weight = percent_of_negative_class)\n",
    "\n",
    "clf.fit(X_train_,\n",
    "        y_train_,\n",
    "        eval_metric=\"auc\",\n",
    "        eval_set=eval_set,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b76eb3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.213353</td>\n",
       "      <td>0.481870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_train</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.886426</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "0                   XGBoost  0.768298  0.806016   0.126959  0.667747   \n",
       "0             XGBoost_train  0.784206  0.886426   0.155538  0.808008   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  \n",
       "0  0.213353  0.481870  \n",
       "0  0.260861  0.466063  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_bin)\n",
    "y_pred_prob = clf.predict_proba(X_test_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test_bin, y_pred, y_pred_prob, name='XGBoost'))\n",
    "\n",
    "y_pred_train = clf.predict(X_train_)\n",
    "y_pred_prob_train = clf.predict_proba(X_train_)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='XGBoost_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7e050",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e14ad56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.724668\tvalid_0's binary_logloss: 0.226594\n",
      "[4]\tvalid_0's auc: 0.742846\tvalid_0's binary_logloss: 0.264321\n",
      "[6]\tvalid_0's auc: 0.750452\tvalid_0's binary_logloss: 0.29881\n",
      "[8]\tvalid_0's auc: 0.754218\tvalid_0's binary_logloss: 0.328605\n",
      "[10]\tvalid_0's auc: 0.757157\tvalid_0's binary_logloss: 0.355085\n",
      "[12]\tvalid_0's auc: 0.761666\tvalid_0's binary_logloss: 0.37593\n",
      "[14]\tvalid_0's auc: 0.762603\tvalid_0's binary_logloss: 0.394402\n",
      "[16]\tvalid_0's auc: 0.76587\tvalid_0's binary_logloss: 0.40863\n",
      "[18]\tvalid_0's auc: 0.768676\tvalid_0's binary_logloss: 0.420258\n",
      "[20]\tvalid_0's auc: 0.771517\tvalid_0's binary_logloss: 0.428942\n",
      "[22]\tvalid_0's auc: 0.77362\tvalid_0's binary_logloss: 0.43493\n",
      "[24]\tvalid_0's auc: 0.775752\tvalid_0's binary_logloss: 0.439685\n",
      "[26]\tvalid_0's auc: 0.776909\tvalid_0's binary_logloss: 0.443347\n",
      "[28]\tvalid_0's auc: 0.777914\tvalid_0's binary_logloss: 0.445802\n",
      "[30]\tvalid_0's auc: 0.779189\tvalid_0's binary_logloss: 0.446851\n",
      "[32]\tvalid_0's auc: 0.780594\tvalid_0's binary_logloss: 0.447105\n",
      "[34]\tvalid_0's auc: 0.781557\tvalid_0's binary_logloss: 0.446942\n",
      "[36]\tvalid_0's auc: 0.783168\tvalid_0's binary_logloss: 0.444212\n",
      "[38]\tvalid_0's auc: 0.785618\tvalid_0's binary_logloss: 0.441613\n",
      "[40]\tvalid_0's auc: 0.786\tvalid_0's binary_logloss: 0.440731\n",
      "[42]\tvalid_0's auc: 0.787414\tvalid_0's binary_logloss: 0.438265\n",
      "[44]\tvalid_0's auc: 0.78814\tvalid_0's binary_logloss: 0.435363\n",
      "[46]\tvalid_0's auc: 0.788594\tvalid_0's binary_logloss: 0.433579\n",
      "[48]\tvalid_0's auc: 0.789506\tvalid_0's binary_logloss: 0.430233\n",
      "[50]\tvalid_0's auc: 0.789677\tvalid_0's binary_logloss: 0.427586\n",
      "[52]\tvalid_0's auc: 0.790122\tvalid_0's binary_logloss: 0.426354\n",
      "[54]\tvalid_0's auc: 0.792341\tvalid_0's binary_logloss: 0.422969\n",
      "[56]\tvalid_0's auc: 0.793559\tvalid_0's binary_logloss: 0.420127\n",
      "[58]\tvalid_0's auc: 0.794456\tvalid_0's binary_logloss: 0.416592\n",
      "[60]\tvalid_0's auc: 0.795014\tvalid_0's binary_logloss: 0.414265\n",
      "[62]\tvalid_0's auc: 0.79608\tvalid_0's binary_logloss: 0.410667\n",
      "[64]\tvalid_0's auc: 0.796565\tvalid_0's binary_logloss: 0.407935\n",
      "[66]\tvalid_0's auc: 0.796763\tvalid_0's binary_logloss: 0.406434\n",
      "[68]\tvalid_0's auc: 0.796989\tvalid_0's binary_logloss: 0.403604\n",
      "[70]\tvalid_0's auc: 0.797425\tvalid_0's binary_logloss: 0.401496\n",
      "[72]\tvalid_0's auc: 0.798256\tvalid_0's binary_logloss: 0.398873\n",
      "[74]\tvalid_0's auc: 0.799303\tvalid_0's binary_logloss: 0.396687\n",
      "[76]\tvalid_0's auc: 0.801006\tvalid_0's binary_logloss: 0.392818\n",
      "[78]\tvalid_0's auc: 0.801682\tvalid_0's binary_logloss: 0.39028\n",
      "[80]\tvalid_0's auc: 0.802468\tvalid_0's binary_logloss: 0.388121\n",
      "[82]\tvalid_0's auc: 0.80337\tvalid_0's binary_logloss: 0.385661\n",
      "[84]\tvalid_0's auc: 0.803806\tvalid_0's binary_logloss: 0.384377\n",
      "[86]\tvalid_0's auc: 0.804985\tvalid_0's binary_logloss: 0.382552\n",
      "[88]\tvalid_0's auc: 0.806562\tvalid_0's binary_logloss: 0.379122\n",
      "[90]\tvalid_0's auc: 0.808276\tvalid_0's binary_logloss: 0.376172\n",
      "[92]\tvalid_0's auc: 0.808402\tvalid_0's binary_logloss: 0.374515\n",
      "[94]\tvalid_0's auc: 0.808387\tvalid_0's binary_logloss: 0.372679\n",
      "[96]\tvalid_0's auc: 0.809318\tvalid_0's binary_logloss: 0.370256\n",
      "[98]\tvalid_0's auc: 0.809881\tvalid_0's binary_logloss: 0.36904\n",
      "[100]\tvalid_0's auc: 0.810156\tvalid_0's binary_logloss: 0.367704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.810156\tvalid_0's binary_logloss: 0.367704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=10, scale_pos_weight=20.27659574468085)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train,\n",
    "                                                    y_train,\n",
    "                                                    test_size=0.16,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=RAND)\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clf = LGBMClassifier(random_state=RAND, scale_pos_weight=percent_of_negative_class)\n",
    "\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clf.fit(X_train_,\n",
    "        y_train_,\n",
    "        eval_metric=\"auc\",\n",
    "        eval_set=eval_set,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4add01dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.213353</td>\n",
       "      <td>0.481870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_train</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.886426</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.829310</td>\n",
       "      <td>0.803692</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>0.368354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_train</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.959865</td>\n",
       "      <td>0.236119</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.377731</td>\n",
       "      <td>0.331044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "0                   XGBoost  0.768298  0.806016   0.126959  0.667747   \n",
       "0             XGBoost_train  0.784206  0.886426   0.155538  0.808008   \n",
       "0                  LightGBM  0.829310  0.803692   0.155154  0.591073   \n",
       "0            LightGBM_train  0.853462  0.959865   0.236119  0.943730   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  \n",
       "0  0.213353  0.481870  \n",
       "0  0.260861  0.466063  \n",
       "0  0.245790  0.368354  \n",
       "0  0.377731  0.331044  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_prob = clf.predict_proba(X_test)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test, y_pred, y_pred_prob, name='LightGBM'))\n",
    "\n",
    "y_pred_train = clf.predict(X_train_)\n",
    "y_pred_prob_train = clf.predict_proba(X_train_)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='LightGBM_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631c53b",
   "metadata": {},
   "source": [
    "# Catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "507846b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.099001\n",
      "0:\ttest: 0.7194341\tbest: 0.7194341 (0)\ttotal: 303ms\tremaining: 5m 2s\n",
      "2:\ttest: 0.7327368\tbest: 0.7327368 (2)\ttotal: 498ms\tremaining: 2m 45s\n",
      "4:\ttest: 0.7375244\tbest: 0.7375244 (4)\ttotal: 715ms\tremaining: 2m 22s\n",
      "6:\ttest: 0.7402752\tbest: 0.7402752 (6)\ttotal: 896ms\tremaining: 2m 7s\n",
      "8:\ttest: 0.7433100\tbest: 0.7433100 (8)\ttotal: 1.14s\tremaining: 2m 5s\n",
      "10:\ttest: 0.7483543\tbest: 0.7483543 (10)\ttotal: 1.35s\tremaining: 2m 1s\n",
      "12:\ttest: 0.7515538\tbest: 0.7515538 (12)\ttotal: 1.57s\tremaining: 1m 58s\n",
      "14:\ttest: 0.7536830\tbest: 0.7536830 (14)\ttotal: 1.76s\tremaining: 1m 55s\n",
      "16:\ttest: 0.7600306\tbest: 0.7603297 (15)\ttotal: 1.99s\tremaining: 1m 54s\n",
      "18:\ttest: 0.7611093\tbest: 0.7611129 (17)\ttotal: 2.23s\tremaining: 1m 55s\n",
      "20:\ttest: 0.7692986\tbest: 0.7692986 (20)\ttotal: 2.46s\tremaining: 1m 54s\n",
      "22:\ttest: 0.7733354\tbest: 0.7733354 (22)\ttotal: 2.67s\tremaining: 1m 53s\n",
      "24:\ttest: 0.7837858\tbest: 0.7837858 (24)\ttotal: 2.89s\tremaining: 1m 52s\n",
      "26:\ttest: 0.7846967\tbest: 0.7846967 (26)\ttotal: 3.1s\tremaining: 1m 51s\n",
      "28:\ttest: 0.7848095\tbest: 0.7848095 (28)\ttotal: 3.33s\tremaining: 1m 51s\n",
      "30:\ttest: 0.7862519\tbest: 0.7862519 (30)\ttotal: 3.57s\tremaining: 1m 51s\n",
      "32:\ttest: 0.7865964\tbest: 0.7866526 (31)\ttotal: 3.84s\tremaining: 1m 52s\n",
      "34:\ttest: 0.7894119\tbest: 0.7894119 (34)\ttotal: 4.11s\tremaining: 1m 53s\n",
      "36:\ttest: 0.7905700\tbest: 0.7905700 (36)\ttotal: 4.33s\tremaining: 1m 52s\n",
      "38:\ttest: 0.7906149\tbest: 0.7906149 (38)\ttotal: 4.53s\tremaining: 1m 51s\n",
      "40:\ttest: 0.7919387\tbest: 0.7919387 (40)\ttotal: 4.78s\tremaining: 1m 51s\n",
      "42:\ttest: 0.7925682\tbest: 0.7925682 (42)\ttotal: 4.96s\tremaining: 1m 50s\n",
      "44:\ttest: 0.7938612\tbest: 0.7938612 (44)\ttotal: 5.29s\tremaining: 1m 52s\n",
      "46:\ttest: 0.7945014\tbest: 0.7945014 (46)\ttotal: 5.57s\tremaining: 1m 52s\n",
      "48:\ttest: 0.7953037\tbest: 0.7953037 (48)\ttotal: 5.89s\tremaining: 1m 54s\n",
      "50:\ttest: 0.7993867\tbest: 0.7993867 (50)\ttotal: 6.21s\tremaining: 1m 55s\n",
      "52:\ttest: 0.8010997\tbest: 0.8010997 (52)\ttotal: 6.56s\tremaining: 1m 57s\n",
      "54:\ttest: 0.8019059\tbest: 0.8019059 (54)\ttotal: 6.97s\tremaining: 1m 59s\n",
      "56:\ttest: 0.8017709\tbest: 0.8019941 (55)\ttotal: 7.22s\tremaining: 1m 59s\n",
      "58:\ttest: 0.8027167\tbest: 0.8027167 (58)\ttotal: 7.49s\tremaining: 1m 59s\n",
      "60:\ttest: 0.8036237\tbest: 0.8036237 (60)\ttotal: 7.88s\tremaining: 2m 1s\n",
      "62:\ttest: 0.8043793\tbest: 0.8043793 (62)\ttotal: 8.13s\tremaining: 2m\n",
      "64:\ttest: 0.8043769\tbest: 0.8043793 (62)\ttotal: 8.36s\tremaining: 2m\n",
      "66:\ttest: 0.8051209\tbest: 0.8051209 (66)\ttotal: 8.82s\tremaining: 2m 2s\n",
      "68:\ttest: 0.8059015\tbest: 0.8059015 (68)\ttotal: 9.2s\tremaining: 2m 4s\n",
      "70:\ttest: 0.8060609\tbest: 0.8061266 (69)\ttotal: 9.66s\tremaining: 2m 6s\n",
      "72:\ttest: 0.8060829\tbest: 0.8061266 (69)\ttotal: 10.1s\tremaining: 2m 7s\n",
      "74:\ttest: 0.8067589\tbest: 0.8067589 (73)\ttotal: 10.4s\tremaining: 2m 8s\n",
      "76:\ttest: 0.8069993\tbest: 0.8069993 (76)\ttotal: 11s\tremaining: 2m 11s\n",
      "78:\ttest: 0.8076431\tbest: 0.8076431 (78)\ttotal: 11.5s\tremaining: 2m 13s\n",
      "80:\ttest: 0.8079428\tbest: 0.8079428 (80)\ttotal: 12s\tremaining: 2m 16s\n",
      "82:\ttest: 0.8100004\tbest: 0.8100004 (82)\ttotal: 12.4s\tremaining: 2m 16s\n",
      "84:\ttest: 0.8101817\tbest: 0.8101817 (84)\ttotal: 12.6s\tremaining: 2m 15s\n",
      "86:\ttest: 0.8102291\tbest: 0.8102291 (86)\ttotal: 12.7s\tremaining: 2m 13s\n",
      "88:\ttest: 0.8103584\tbest: 0.8103584 (88)\ttotal: 13.2s\tremaining: 2m 14s\n",
      "90:\ttest: 0.8119364\tbest: 0.8119364 (90)\ttotal: 13.7s\tremaining: 2m 16s\n",
      "92:\ttest: 0.8144362\tbest: 0.8144362 (92)\ttotal: 14.1s\tremaining: 2m 17s\n",
      "94:\ttest: 0.8145650\tbest: 0.8147076 (93)\ttotal: 14.3s\tremaining: 2m 16s\n",
      "96:\ttest: 0.8147195\tbest: 0.8147195 (96)\ttotal: 14.7s\tremaining: 2m 16s\n",
      "98:\ttest: 0.8159299\tbest: 0.8159299 (98)\ttotal: 15.2s\tremaining: 2m 18s\n",
      "100:\ttest: 0.8161536\tbest: 0.8161536 (100)\ttotal: 15.4s\tremaining: 2m 16s\n",
      "102:\ttest: 0.8162726\tbest: 0.8162726 (102)\ttotal: 15.8s\tremaining: 2m 17s\n",
      "104:\ttest: 0.8189930\tbest: 0.8189930 (104)\ttotal: 16s\tremaining: 2m 16s\n",
      "106:\ttest: 0.8198771\tbest: 0.8198771 (106)\ttotal: 16.2s\tremaining: 2m 15s\n",
      "108:\ttest: 0.8208384\tbest: 0.8208384 (108)\ttotal: 16.5s\tremaining: 2m 15s\n",
      "110:\ttest: 0.8211409\tbest: 0.8211409 (110)\ttotal: 16.8s\tremaining: 2m 14s\n",
      "112:\ttest: 0.8221606\tbest: 0.8221606 (112)\ttotal: 17.1s\tremaining: 2m 14s\n",
      "114:\ttest: 0.8227049\tbest: 0.8227049 (114)\ttotal: 17.4s\tremaining: 2m 14s\n",
      "116:\ttest: 0.8239845\tbest: 0.8239845 (116)\ttotal: 17.8s\tremaining: 2m 14s\n",
      "118:\ttest: 0.8245391\tbest: 0.8245391 (118)\ttotal: 18.1s\tremaining: 2m 13s\n",
      "120:\ttest: 0.8255992\tbest: 0.8255992 (120)\ttotal: 18.5s\tremaining: 2m 14s\n",
      "122:\ttest: 0.8270486\tbest: 0.8270486 (122)\ttotal: 18.9s\tremaining: 2m 14s\n",
      "124:\ttest: 0.8288375\tbest: 0.8288375 (124)\ttotal: 19.2s\tremaining: 2m 14s\n",
      "126:\ttest: 0.8311562\tbest: 0.8311562 (126)\ttotal: 19.4s\tremaining: 2m 13s\n",
      "128:\ttest: 0.8317780\tbest: 0.8319679 (127)\ttotal: 19.6s\tremaining: 2m 12s\n",
      "130:\ttest: 0.8333456\tbest: 0.8333456 (130)\ttotal: 20s\tremaining: 2m 12s\n",
      "132:\ttest: 0.8336276\tbest: 0.8336276 (132)\ttotal: 20.2s\tremaining: 2m 12s\n",
      "134:\ttest: 0.8348491\tbest: 0.8348491 (134)\ttotal: 20.5s\tremaining: 2m 11s\n",
      "136:\ttest: 0.8374324\tbest: 0.8374324 (136)\ttotal: 20.8s\tremaining: 2m 10s\n",
      "138:\ttest: 0.8388469\tbest: 0.8388469 (138)\ttotal: 21s\tremaining: 2m 9s\n",
      "140:\ttest: 0.8400414\tbest: 0.8400414 (140)\ttotal: 21.4s\tremaining: 2m 10s\n",
      "142:\ttest: 0.8408773\tbest: 0.8408773 (142)\ttotal: 21.6s\tremaining: 2m 9s\n",
      "144:\ttest: 0.8418699\tbest: 0.8418699 (144)\ttotal: 21.9s\tremaining: 2m 9s\n",
      "146:\ttest: 0.8425211\tbest: 0.8425211 (146)\ttotal: 22.1s\tremaining: 2m 8s\n",
      "148:\ttest: 0.8433202\tbest: 0.8433202 (148)\ttotal: 22.4s\tremaining: 2m 7s\n",
      "150:\ttest: 0.8455640\tbest: 0.8455640 (150)\ttotal: 22.6s\tremaining: 2m 7s\n",
      "152:\ttest: 0.8474720\tbest: 0.8474720 (152)\ttotal: 22.9s\tremaining: 2m 6s\n",
      "154:\ttest: 0.8495200\tbest: 0.8495200 (154)\ttotal: 23.1s\tremaining: 2m 6s\n",
      "156:\ttest: 0.8499492\tbest: 0.8499492 (156)\ttotal: 23.4s\tremaining: 2m 5s\n",
      "158:\ttest: 0.8507387\tbest: 0.8507387 (158)\ttotal: 23.7s\tremaining: 2m 5s\n",
      "160:\ttest: 0.8512599\tbest: 0.8512599 (160)\ttotal: 23.9s\tremaining: 2m 4s\n",
      "162:\ttest: 0.8528538\tbest: 0.8528538 (162)\ttotal: 24.2s\tremaining: 2m 4s\n",
      "164:\ttest: 0.8545278\tbest: 0.8545278 (164)\ttotal: 24.5s\tremaining: 2m 3s\n",
      "166:\ttest: 0.8547365\tbest: 0.8548395 (165)\ttotal: 24.7s\tremaining: 2m 3s\n",
      "168:\ttest: 0.8569911\tbest: 0.8569911 (168)\ttotal: 24.9s\tremaining: 2m 2s\n",
      "170:\ttest: 0.8577081\tbest: 0.8577081 (170)\ttotal: 25.3s\tremaining: 2m 2s\n",
      "172:\ttest: 0.8585863\tbest: 0.8585863 (172)\ttotal: 25.6s\tremaining: 2m 2s\n",
      "174:\ttest: 0.8597792\tbest: 0.8597792 (174)\ttotal: 25.8s\tremaining: 2m 1s\n",
      "176:\ttest: 0.8604786\tbest: 0.8604786 (176)\ttotal: 26.1s\tremaining: 2m 1s\n",
      "178:\ttest: 0.8607234\tbest: 0.8607234 (178)\ttotal: 26.3s\tremaining: 2m\n",
      "180:\ttest: 0.8615079\tbest: 0.8615079 (180)\ttotal: 26.5s\tremaining: 2m\n",
      "182:\ttest: 0.8617898\tbest: 0.8617898 (182)\ttotal: 26.8s\tremaining: 1m 59s\n",
      "184:\ttest: 0.8621770\tbest: 0.8621770 (184)\ttotal: 27s\tremaining: 1m 58s\n",
      "186:\ttest: 0.8628429\tbest: 0.8628429 (186)\ttotal: 27.2s\tremaining: 1m 58s\n",
      "188:\ttest: 0.8631828\tbest: 0.8631828 (188)\ttotal: 27.4s\tremaining: 1m 57s\n",
      "190:\ttest: 0.8633605\tbest: 0.8633962 (189)\ttotal: 27.7s\tremaining: 1m 57s\n",
      "192:\ttest: 0.8646468\tbest: 0.8646468 (192)\ttotal: 27.9s\tremaining: 1m 56s\n",
      "194:\ttest: 0.8648903\tbest: 0.8648903 (194)\ttotal: 28.3s\tremaining: 1m 56s\n",
      "196:\ttest: 0.8654624\tbest: 0.8654624 (196)\ttotal: 28.7s\tremaining: 1m 57s\n",
      "198:\ttest: 0.8663199\tbest: 0.8663199 (198)\ttotal: 28.9s\tremaining: 1m 56s\n",
      "200:\ttest: 0.8663911\tbest: 0.8663911 (200)\ttotal: 29.2s\tremaining: 1m 56s\n",
      "202:\ttest: 0.8674158\tbest: 0.8674158 (202)\ttotal: 29.5s\tremaining: 1m 55s\n",
      "204:\ttest: 0.8675211\tbest: 0.8675211 (204)\ttotal: 29.7s\tremaining: 1m 55s\n",
      "206:\ttest: 0.8681469\tbest: 0.8681469 (206)\ttotal: 30s\tremaining: 1m 54s\n",
      "208:\ttest: 0.8684776\tbest: 0.8684776 (208)\ttotal: 30.2s\tremaining: 1m 54s\n",
      "210:\ttest: 0.8693918\tbest: 0.8693918 (210)\ttotal: 30.5s\tremaining: 1m 54s\n",
      "212:\ttest: 0.8696648\tbest: 0.8696648 (212)\ttotal: 30.8s\tremaining: 1m 53s\n",
      "214:\ttest: 0.8702856\tbest: 0.8702856 (214)\ttotal: 31s\tremaining: 1m 53s\n",
      "216:\ttest: 0.8709442\tbest: 0.8709442 (216)\ttotal: 31.2s\tremaining: 1m 52s\n",
      "218:\ttest: 0.8714099\tbest: 0.8714119 (217)\ttotal: 31.4s\tremaining: 1m 52s\n",
      "220:\ttest: 0.8717595\tbest: 0.8717595 (220)\ttotal: 31.6s\tremaining: 1m 51s\n",
      "222:\ttest: 0.8719543\tbest: 0.8719543 (222)\ttotal: 31.9s\tremaining: 1m 51s\n",
      "224:\ttest: 0.8723931\tbest: 0.8723931 (224)\ttotal: 32.2s\tremaining: 1m 50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226:\ttest: 0.8725733\tbest: 0.8725733 (226)\ttotal: 32.4s\tremaining: 1m 50s\n",
      "228:\ttest: 0.8735607\tbest: 0.8735607 (228)\ttotal: 32.7s\tremaining: 1m 49s\n",
      "230:\ttest: 0.8742116\tbest: 0.8742116 (230)\ttotal: 33.2s\tremaining: 1m 50s\n",
      "232:\ttest: 0.8743765\tbest: 0.8743765 (232)\ttotal: 33.4s\tremaining: 1m 49s\n",
      "234:\ttest: 0.8746411\tbest: 0.8746411 (234)\ttotal: 33.6s\tremaining: 1m 49s\n",
      "236:\ttest: 0.8748546\tbest: 0.8748546 (236)\ttotal: 33.9s\tremaining: 1m 48s\n",
      "238:\ttest: 0.8756059\tbest: 0.8756059 (238)\ttotal: 34.1s\tremaining: 1m 48s\n",
      "240:\ttest: 0.8759964\tbest: 0.8759964 (240)\ttotal: 34.3s\tremaining: 1m 48s\n",
      "242:\ttest: 0.8764322\tbest: 0.8764322 (242)\ttotal: 34.6s\tremaining: 1m 47s\n",
      "244:\ttest: 0.8772824\tbest: 0.8772824 (244)\ttotal: 34.7s\tremaining: 1m 47s\n",
      "246:\ttest: 0.8778447\tbest: 0.8778447 (246)\ttotal: 35s\tremaining: 1m 46s\n",
      "248:\ttest: 0.8780222\tbest: 0.8780441 (247)\ttotal: 35.2s\tremaining: 1m 46s\n",
      "250:\ttest: 0.8784609\tbest: 0.8784609 (250)\ttotal: 35.4s\tremaining: 1m 45s\n",
      "252:\ttest: 0.8786872\tbest: 0.8786872 (252)\ttotal: 35.7s\tremaining: 1m 45s\n",
      "254:\ttest: 0.8791137\tbest: 0.8791137 (254)\ttotal: 35.9s\tremaining: 1m 44s\n",
      "256:\ttest: 0.8792331\tbest: 0.8792331 (256)\ttotal: 36.2s\tremaining: 1m 44s\n",
      "258:\ttest: 0.8797956\tbest: 0.8797956 (258)\ttotal: 36.4s\tremaining: 1m 44s\n",
      "260:\ttest: 0.8798458\tbest: 0.8798471 (259)\ttotal: 36.6s\tremaining: 1m 43s\n",
      "262:\ttest: 0.8801019\tbest: 0.8801019 (262)\ttotal: 36.9s\tremaining: 1m 43s\n",
      "264:\ttest: 0.8802942\tbest: 0.8802942 (264)\ttotal: 37.1s\tremaining: 1m 42s\n",
      "266:\ttest: 0.8804551\tbest: 0.8804551 (266)\ttotal: 37.3s\tremaining: 1m 42s\n",
      "268:\ttest: 0.8803701\tbest: 0.8804551 (266)\ttotal: 37.6s\tremaining: 1m 42s\n",
      "270:\ttest: 0.8804355\tbest: 0.8804714 (269)\ttotal: 37.9s\tremaining: 1m 41s\n",
      "272:\ttest: 0.8804322\tbest: 0.8804714 (269)\ttotal: 38.2s\tremaining: 1m 41s\n",
      "274:\ttest: 0.8809523\tbest: 0.8809523 (274)\ttotal: 38.4s\tremaining: 1m 41s\n",
      "276:\ttest: 0.8812015\tbest: 0.8812015 (276)\ttotal: 38.6s\tremaining: 1m 40s\n",
      "278:\ttest: 0.8813102\tbest: 0.8813350 (277)\ttotal: 38.8s\tremaining: 1m 40s\n",
      "280:\ttest: 0.8819049\tbest: 0.8819049 (280)\ttotal: 39.1s\tremaining: 1m 39s\n",
      "282:\ttest: 0.8819738\tbest: 0.8820419 (281)\ttotal: 39.3s\tremaining: 1m 39s\n",
      "284:\ttest: 0.8820936\tbest: 0.8820936 (284)\ttotal: 39.6s\tremaining: 1m 39s\n",
      "286:\ttest: 0.8821054\tbest: 0.8821054 (286)\ttotal: 39.8s\tremaining: 1m 38s\n",
      "288:\ttest: 0.8827595\tbest: 0.8827595 (288)\ttotal: 40.1s\tremaining: 1m 38s\n",
      "290:\ttest: 0.8831361\tbest: 0.8831361 (290)\ttotal: 40.4s\tremaining: 1m 38s\n",
      "292:\ttest: 0.8831268\tbest: 0.8831710 (291)\ttotal: 40.7s\tremaining: 1m 38s\n",
      "294:\ttest: 0.8835077\tbest: 0.8835077 (294)\ttotal: 40.9s\tremaining: 1m 37s\n",
      "296:\ttest: 0.8837023\tbest: 0.8837023 (296)\ttotal: 41.1s\tremaining: 1m 37s\n",
      "298:\ttest: 0.8841988\tbest: 0.8841988 (298)\ttotal: 41.4s\tremaining: 1m 37s\n",
      "300:\ttest: 0.8843215\tbest: 0.8843215 (300)\ttotal: 41.7s\tremaining: 1m 36s\n",
      "302:\ttest: 0.8852383\tbest: 0.8852383 (302)\ttotal: 41.9s\tremaining: 1m 36s\n",
      "304:\ttest: 0.8854416\tbest: 0.8854416 (304)\ttotal: 42.2s\tremaining: 1m 36s\n",
      "306:\ttest: 0.8860905\tbest: 0.8860905 (306)\ttotal: 42.5s\tremaining: 1m 35s\n",
      "308:\ttest: 0.8866055\tbest: 0.8866055 (308)\ttotal: 42.8s\tremaining: 1m 35s\n",
      "310:\ttest: 0.8872357\tbest: 0.8872357 (310)\ttotal: 43s\tremaining: 1m 35s\n",
      "312:\ttest: 0.8876392\tbest: 0.8876392 (312)\ttotal: 43.3s\tremaining: 1m 35s\n",
      "314:\ttest: 0.8876330\tbest: 0.8876392 (312)\ttotal: 43.6s\tremaining: 1m 34s\n",
      "316:\ttest: 0.8879467\tbest: 0.8879467 (316)\ttotal: 43.8s\tremaining: 1m 34s\n",
      "318:\ttest: 0.8879684\tbest: 0.8879684 (318)\ttotal: 44.1s\tremaining: 1m 34s\n",
      "320:\ttest: 0.8884319\tbest: 0.8884319 (320)\ttotal: 44.3s\tremaining: 1m 33s\n",
      "322:\ttest: 0.8888903\tbest: 0.8889537 (321)\ttotal: 44.5s\tremaining: 1m 33s\n",
      "324:\ttest: 0.8889074\tbest: 0.8889537 (321)\ttotal: 44.8s\tremaining: 1m 32s\n",
      "326:\ttest: 0.8894021\tbest: 0.8894021 (326)\ttotal: 45s\tremaining: 1m 32s\n",
      "328:\ttest: 0.8897180\tbest: 0.8897523 (327)\ttotal: 45.2s\tremaining: 1m 32s\n",
      "330:\ttest: 0.8898912\tbest: 0.8898948 (329)\ttotal: 45.4s\tremaining: 1m 31s\n",
      "332:\ttest: 0.8899371\tbest: 0.8899371 (332)\ttotal: 45.7s\tremaining: 1m 31s\n",
      "334:\ttest: 0.8900351\tbest: 0.8900351 (334)\ttotal: 45.9s\tremaining: 1m 31s\n",
      "336:\ttest: 0.8903110\tbest: 0.8903110 (336)\ttotal: 46.2s\tremaining: 1m 30s\n",
      "338:\ttest: 0.8906823\tbest: 0.8906823 (338)\ttotal: 46.4s\tremaining: 1m 30s\n",
      "340:\ttest: 0.8907433\tbest: 0.8907433 (340)\ttotal: 46.6s\tremaining: 1m 30s\n",
      "342:\ttest: 0.8908925\tbest: 0.8908925 (342)\ttotal: 47s\tremaining: 1m 29s\n",
      "344:\ttest: 0.8910642\tbest: 0.8910642 (344)\ttotal: 47.3s\tremaining: 1m 29s\n",
      "346:\ttest: 0.8910648\tbest: 0.8912183 (345)\ttotal: 47.5s\tremaining: 1m 29s\n",
      "348:\ttest: 0.8913596\tbest: 0.8913596 (348)\ttotal: 47.9s\tremaining: 1m 29s\n",
      "350:\ttest: 0.8914449\tbest: 0.8914664 (349)\ttotal: 48.2s\tremaining: 1m 29s\n",
      "352:\ttest: 0.8914187\tbest: 0.8914664 (349)\ttotal: 48.4s\tremaining: 1m 28s\n",
      "354:\ttest: 0.8918734\tbest: 0.8918734 (354)\ttotal: 48.7s\tremaining: 1m 28s\n",
      "356:\ttest: 0.8919148\tbest: 0.8919148 (356)\ttotal: 49.2s\tremaining: 1m 28s\n",
      "358:\ttest: 0.8922225\tbest: 0.8922225 (358)\ttotal: 49.4s\tremaining: 1m 28s\n",
      "360:\ttest: 0.8924286\tbest: 0.8924286 (360)\ttotal: 49.8s\tremaining: 1m 28s\n",
      "362:\ttest: 0.8925425\tbest: 0.8925425 (362)\ttotal: 50.1s\tremaining: 1m 27s\n",
      "364:\ttest: 0.8924629\tbest: 0.8925425 (362)\ttotal: 50.5s\tremaining: 1m 27s\n",
      "366:\ttest: 0.8925013\tbest: 0.8925425 (362)\ttotal: 50.9s\tremaining: 1m 27s\n",
      "368:\ttest: 0.8926661\tbest: 0.8926661 (368)\ttotal: 51.3s\tremaining: 1m 27s\n",
      "370:\ttest: 0.8928178\tbest: 0.8928178 (370)\ttotal: 51.7s\tremaining: 1m 27s\n",
      "372:\ttest: 0.8927546\tbest: 0.8928421 (371)\ttotal: 52.1s\tremaining: 1m 27s\n",
      "374:\ttest: 0.8929536\tbest: 0.8929536 (374)\ttotal: 52.5s\tremaining: 1m 27s\n",
      "376:\ttest: 0.8933388\tbest: 0.8933388 (376)\ttotal: 52.7s\tremaining: 1m 27s\n",
      "378:\ttest: 0.8935721\tbest: 0.8935721 (378)\ttotal: 53.2s\tremaining: 1m 27s\n",
      "380:\ttest: 0.8940272\tbest: 0.8940272 (380)\ttotal: 53.6s\tremaining: 1m 27s\n",
      "382:\ttest: 0.8942521\tbest: 0.8942521 (382)\ttotal: 54s\tremaining: 1m 26s\n",
      "384:\ttest: 0.8943881\tbest: 0.8943924 (383)\ttotal: 54.2s\tremaining: 1m 26s\n",
      "386:\ttest: 0.8949287\tbest: 0.8949287 (386)\ttotal: 54.4s\tremaining: 1m 26s\n",
      "388:\ttest: 0.8950110\tbest: 0.8950110 (388)\ttotal: 54.7s\tremaining: 1m 25s\n",
      "390:\ttest: 0.8951069\tbest: 0.8951069 (390)\ttotal: 54.9s\tremaining: 1m 25s\n",
      "392:\ttest: 0.8951908\tbest: 0.8951908 (391)\ttotal: 55.1s\tremaining: 1m 25s\n",
      "394:\ttest: 0.8951543\tbest: 0.8952217 (393)\ttotal: 55.3s\tremaining: 1m 24s\n",
      "396:\ttest: 0.8951819\tbest: 0.8952217 (393)\ttotal: 55.6s\tremaining: 1m 24s\n",
      "398:\ttest: 0.8951326\tbest: 0.8952217 (393)\ttotal: 55.8s\tremaining: 1m 24s\n",
      "400:\ttest: 0.8953583\tbest: 0.8953583 (400)\ttotal: 56.1s\tremaining: 1m 23s\n",
      "402:\ttest: 0.8956134\tbest: 0.8956134 (402)\ttotal: 56.4s\tremaining: 1m 23s\n",
      "404:\ttest: 0.8960201\tbest: 0.8960201 (404)\ttotal: 56.7s\tremaining: 1m 23s\n",
      "406:\ttest: 0.8967695\tbest: 0.8967695 (406)\ttotal: 56.9s\tremaining: 1m 22s\n",
      "408:\ttest: 0.8973940\tbest: 0.8973940 (408)\ttotal: 57.1s\tremaining: 1m 22s\n",
      "410:\ttest: 0.8974609\tbest: 0.8974609 (409)\ttotal: 57.3s\tremaining: 1m 22s\n",
      "412:\ttest: 0.8975831\tbest: 0.8975831 (412)\ttotal: 57.6s\tremaining: 1m 21s\n",
      "414:\ttest: 0.8976937\tbest: 0.8976937 (414)\ttotal: 57.8s\tremaining: 1m 21s\n",
      "416:\ttest: 0.8976854\tbest: 0.8976937 (414)\ttotal: 58.2s\tremaining: 1m 21s\n",
      "418:\ttest: 0.8981962\tbest: 0.8981962 (418)\ttotal: 58.4s\tremaining: 1m 20s\n",
      "420:\ttest: 0.8982531\tbest: 0.8982531 (419)\ttotal: 58.6s\tremaining: 1m 20s\n",
      "422:\ttest: 0.8983346\tbest: 0.8983346 (422)\ttotal: 58.9s\tremaining: 1m 20s\n",
      "424:\ttest: 0.8983846\tbest: 0.8983846 (424)\ttotal: 59.1s\tremaining: 1m 20s\n",
      "426:\ttest: 0.8982300\tbest: 0.8983880 (425)\ttotal: 59.4s\tremaining: 1m 19s\n",
      "428:\ttest: 0.8982925\tbest: 0.8983880 (425)\ttotal: 59.6s\tremaining: 1m 19s\n",
      "430:\ttest: 0.8984210\tbest: 0.8984465 (429)\ttotal: 59.8s\tremaining: 1m 18s\n",
      "432:\ttest: 0.8985569\tbest: 0.8985569 (432)\ttotal: 1m\tremaining: 1m 18s\n",
      "434:\ttest: 0.8986476\tbest: 0.8986476 (434)\ttotal: 1m\tremaining: 1m 18s\n",
      "436:\ttest: 0.8989819\tbest: 0.8989819 (435)\ttotal: 1m\tremaining: 1m 17s\n",
      "438:\ttest: 0.8990940\tbest: 0.8990940 (438)\ttotal: 1m\tremaining: 1m 17s\n",
      "440:\ttest: 0.8991189\tbest: 0.8991189 (439)\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "442:\ttest: 0.8996785\tbest: 0.8996785 (442)\ttotal: 1m 1s\tremaining: 1m 17s\n",
      "444:\ttest: 0.8999088\tbest: 0.8999088 (443)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "446:\ttest: 0.9003719\tbest: 0.9003719 (446)\ttotal: 1m 1s\tremaining: 1m 16s\n",
      "448:\ttest: 0.9004333\tbest: 0.9004743 (447)\ttotal: 1m 2s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450:\ttest: 0.9005820\tbest: 0.9005820 (450)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "452:\ttest: 0.9005295\tbest: 0.9005861 (451)\ttotal: 1m 2s\tremaining: 1m 15s\n",
      "454:\ttest: 0.9008411\tbest: 0.9008411 (454)\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "456:\ttest: 0.9010247\tbest: 0.9010564 (455)\ttotal: 1m 3s\tremaining: 1m 15s\n",
      "458:\ttest: 0.9010857\tbest: 0.9011155 (457)\ttotal: 1m 4s\tremaining: 1m 15s\n",
      "460:\ttest: 0.9012557\tbest: 0.9012557 (460)\ttotal: 1m 4s\tremaining: 1m 15s\n",
      "462:\ttest: 0.9017694\tbest: 0.9018277 (461)\ttotal: 1m 4s\tremaining: 1m 15s\n",
      "464:\ttest: 0.9018493\tbest: 0.9018493 (464)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "466:\ttest: 0.9018427\tbest: 0.9018493 (464)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "468:\ttest: 0.9020458\tbest: 0.9020458 (468)\ttotal: 1m 5s\tremaining: 1m 14s\n",
      "470:\ttest: 0.9020608\tbest: 0.9020608 (470)\ttotal: 1m 5s\tremaining: 1m 13s\n",
      "472:\ttest: 0.9022814\tbest: 0.9022814 (472)\ttotal: 1m 6s\tremaining: 1m 13s\n",
      "474:\ttest: 0.9024866\tbest: 0.9024866 (474)\ttotal: 1m 6s\tremaining: 1m 13s\n",
      "476:\ttest: 0.9023313\tbest: 0.9024866 (474)\ttotal: 1m 6s\tremaining: 1m 13s\n",
      "478:\ttest: 0.9023673\tbest: 0.9024866 (474)\ttotal: 1m 7s\tremaining: 1m 13s\n",
      "480:\ttest: 0.9025321\tbest: 0.9025321 (480)\ttotal: 1m 7s\tremaining: 1m 13s\n",
      "482:\ttest: 0.9026797\tbest: 0.9026797 (482)\ttotal: 1m 8s\tremaining: 1m 12s\n",
      "484:\ttest: 0.9028012\tbest: 0.9028012 (484)\ttotal: 1m 8s\tremaining: 1m 12s\n",
      "486:\ttest: 0.9028433\tbest: 0.9028587 (485)\ttotal: 1m 8s\tremaining: 1m 12s\n",
      "488:\ttest: 0.9030059\tbest: 0.9030059 (488)\ttotal: 1m 8s\tremaining: 1m 11s\n",
      "490:\ttest: 0.9031275\tbest: 0.9031275 (490)\ttotal: 1m 9s\tremaining: 1m 11s\n",
      "492:\ttest: 0.9030946\tbest: 0.9031275 (490)\ttotal: 1m 9s\tremaining: 1m 11s\n",
      "494:\ttest: 0.9031920\tbest: 0.9031920 (494)\ttotal: 1m 9s\tremaining: 1m 10s\n",
      "496:\ttest: 0.9033714\tbest: 0.9033714 (496)\ttotal: 1m 9s\tremaining: 1m 10s\n",
      "498:\ttest: 0.9034225\tbest: 0.9034254 (497)\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "500:\ttest: 0.9034973\tbest: 0.9035413 (499)\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "502:\ttest: 0.9035988\tbest: 0.9035988 (502)\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "504:\ttest: 0.9036587\tbest: 0.9036587 (504)\ttotal: 1m 11s\tremaining: 1m 9s\n",
      "506:\ttest: 0.9036195\tbest: 0.9036607 (505)\ttotal: 1m 11s\tremaining: 1m 9s\n",
      "508:\ttest: 0.9039212\tbest: 0.9039212 (508)\ttotal: 1m 11s\tremaining: 1m 9s\n",
      "510:\ttest: 0.9037884\tbest: 0.9039212 (508)\ttotal: 1m 12s\tremaining: 1m 8s\n",
      "512:\ttest: 0.9039089\tbest: 0.9039212 (508)\ttotal: 1m 12s\tremaining: 1m 8s\n",
      "514:\ttest: 0.9043573\tbest: 0.9043573 (514)\ttotal: 1m 12s\tremaining: 1m 8s\n",
      "516:\ttest: 0.9044560\tbest: 0.9044560 (516)\ttotal: 1m 12s\tremaining: 1m 8s\n",
      "518:\ttest: 0.9045238\tbest: 0.9045959 (517)\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "520:\ttest: 0.9047161\tbest: 0.9047161 (520)\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "522:\ttest: 0.9050519\tbest: 0.9050877 (521)\ttotal: 1m 13s\tremaining: 1m 7s\n",
      "524:\ttest: 0.9052021\tbest: 0.9052021 (524)\ttotal: 1m 13s\tremaining: 1m 6s\n",
      "526:\ttest: 0.9051570\tbest: 0.9052021 (524)\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "528:\ttest: 0.9054617\tbest: 0.9054617 (528)\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "530:\ttest: 0.9054599\tbest: 0.9054617 (528)\ttotal: 1m 14s\tremaining: 1m 6s\n",
      "532:\ttest: 0.9056507\tbest: 0.9056546 (531)\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "534:\ttest: 0.9060325\tbest: 0.9060325 (534)\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "536:\ttest: 0.9060848\tbest: 0.9060883 (535)\ttotal: 1m 15s\tremaining: 1m 5s\n",
      "538:\ttest: 0.9062939\tbest: 0.9062939 (538)\ttotal: 1m 15s\tremaining: 1m 4s\n",
      "540:\ttest: 0.9064313\tbest: 0.9064313 (540)\ttotal: 1m 16s\tremaining: 1m 4s\n",
      "542:\ttest: 0.9063125\tbest: 0.9064313 (540)\ttotal: 1m 16s\tremaining: 1m 4s\n",
      "544:\ttest: 0.9064746\tbest: 0.9064746 (544)\ttotal: 1m 16s\tremaining: 1m 3s\n",
      "546:\ttest: 0.9064505\tbest: 0.9064746 (544)\ttotal: 1m 16s\tremaining: 1m 3s\n",
      "548:\ttest: 0.9064993\tbest: 0.9064993 (548)\ttotal: 1m 16s\tremaining: 1m 3s\n",
      "550:\ttest: 0.9066183\tbest: 0.9066183 (550)\ttotal: 1m 17s\tremaining: 1m 2s\n",
      "552:\ttest: 0.9067929\tbest: 0.9067929 (552)\ttotal: 1m 17s\tremaining: 1m 2s\n",
      "554:\ttest: 0.9069095\tbest: 0.9069205 (553)\ttotal: 1m 17s\tremaining: 1m 2s\n",
      "556:\ttest: 0.9070401\tbest: 0.9070401 (556)\ttotal: 1m 17s\tremaining: 1m 1s\n",
      "558:\ttest: 0.9071216\tbest: 0.9071216 (558)\ttotal: 1m 18s\tremaining: 1m 1s\n",
      "560:\ttest: 0.9072475\tbest: 0.9072475 (560)\ttotal: 1m 18s\tremaining: 1m 1s\n",
      "562:\ttest: 0.9072250\tbest: 0.9072829 (561)\ttotal: 1m 18s\tremaining: 1m 1s\n",
      "564:\ttest: 0.9072259\tbest: 0.9072829 (561)\ttotal: 1m 18s\tremaining: 1m\n",
      "566:\ttest: 0.9071703\tbest: 0.9072829 (561)\ttotal: 1m 19s\tremaining: 1m\n",
      "568:\ttest: 0.9074476\tbest: 0.9074476 (568)\ttotal: 1m 19s\tremaining: 1m\n",
      "570:\ttest: 0.9075238\tbest: 0.9075238 (570)\ttotal: 1m 19s\tremaining: 59.7s\n",
      "572:\ttest: 0.9074952\tbest: 0.9075238 (570)\ttotal: 1m 19s\tremaining: 59.5s\n",
      "574:\ttest: 0.9078765\tbest: 0.9078765 (574)\ttotal: 1m 20s\tremaining: 59.3s\n",
      "576:\ttest: 0.9077224\tbest: 0.9078765 (574)\ttotal: 1m 20s\tremaining: 59.1s\n",
      "578:\ttest: 0.9078139\tbest: 0.9078765 (574)\ttotal: 1m 20s\tremaining: 58.8s\n",
      "580:\ttest: 0.9080981\tbest: 0.9081139 (579)\ttotal: 1m 21s\tremaining: 58.5s\n",
      "582:\ttest: 0.9084030\tbest: 0.9084030 (582)\ttotal: 1m 21s\tremaining: 58.3s\n",
      "584:\ttest: 0.9083442\tbest: 0.9084030 (582)\ttotal: 1m 21s\tremaining: 58s\n",
      "586:\ttest: 0.9082241\tbest: 0.9084030 (582)\ttotal: 1m 22s\tremaining: 57.8s\n",
      "588:\ttest: 0.9082343\tbest: 0.9084030 (582)\ttotal: 1m 22s\tremaining: 57.6s\n",
      "590:\ttest: 0.9080488\tbest: 0.9084030 (582)\ttotal: 1m 22s\tremaining: 57.3s\n",
      "592:\ttest: 0.9081882\tbest: 0.9084030 (582)\ttotal: 1m 23s\tremaining: 57.1s\n",
      "594:\ttest: 0.9082808\tbest: 0.9084030 (582)\ttotal: 1m 23s\tremaining: 56.8s\n",
      "596:\ttest: 0.9081674\tbest: 0.9084030 (582)\ttotal: 1m 23s\tremaining: 56.5s\n",
      "598:\ttest: 0.9080679\tbest: 0.9084030 (582)\ttotal: 1m 24s\tremaining: 56.3s\n",
      "600:\ttest: 0.9082072\tbest: 0.9084030 (582)\ttotal: 1m 24s\tremaining: 56s\n",
      "602:\ttest: 0.9082954\tbest: 0.9084030 (582)\ttotal: 1m 24s\tremaining: 55.7s\n",
      "604:\ttest: 0.9083146\tbest: 0.9084030 (582)\ttotal: 1m 24s\tremaining: 55.4s\n",
      "606:\ttest: 0.9083832\tbest: 0.9084030 (582)\ttotal: 1m 25s\tremaining: 55.1s\n",
      "608:\ttest: 0.9084707\tbest: 0.9084707 (608)\ttotal: 1m 25s\tremaining: 54.8s\n",
      "610:\ttest: 0.9085483\tbest: 0.9085483 (610)\ttotal: 1m 25s\tremaining: 54.6s\n",
      "612:\ttest: 0.9086395\tbest: 0.9086395 (612)\ttotal: 1m 26s\tremaining: 54.3s\n",
      "614:\ttest: 0.9089122\tbest: 0.9089122 (614)\ttotal: 1m 26s\tremaining: 54.1s\n",
      "616:\ttest: 0.9089435\tbest: 0.9089435 (616)\ttotal: 1m 26s\tremaining: 53.8s\n",
      "618:\ttest: 0.9089235\tbest: 0.9089435 (616)\ttotal: 1m 27s\tremaining: 53.6s\n",
      "620:\ttest: 0.9089479\tbest: 0.9089498 (619)\ttotal: 1m 27s\tremaining: 53.4s\n",
      "622:\ttest: 0.9092780\tbest: 0.9092780 (622)\ttotal: 1m 27s\tremaining: 53.1s\n",
      "624:\ttest: 0.9092470\tbest: 0.9093356 (623)\ttotal: 1m 28s\tremaining: 52.8s\n",
      "626:\ttest: 0.9095416\tbest: 0.9095416 (625)\ttotal: 1m 28s\tremaining: 52.6s\n",
      "628:\ttest: 0.9095416\tbest: 0.9095416 (625)\ttotal: 1m 28s\tremaining: 52.2s\n",
      "630:\ttest: 0.9096724\tbest: 0.9096724 (630)\ttotal: 1m 28s\tremaining: 52s\n",
      "632:\ttest: 0.9099161\tbest: 0.9099161 (632)\ttotal: 1m 29s\tremaining: 51.8s\n",
      "634:\ttest: 0.9097841\tbest: 0.9099161 (632)\ttotal: 1m 29s\tremaining: 51.6s\n",
      "636:\ttest: 0.9098284\tbest: 0.9099161 (632)\ttotal: 1m 30s\tremaining: 51.4s\n",
      "638:\ttest: 0.9098497\tbest: 0.9099161 (632)\ttotal: 1m 30s\tremaining: 51.2s\n",
      "640:\ttest: 0.9099917\tbest: 0.9099917 (640)\ttotal: 1m 30s\tremaining: 50.9s\n",
      "642:\ttest: 0.9099872\tbest: 0.9099917 (640)\ttotal: 1m 31s\tremaining: 50.8s\n",
      "644:\ttest: 0.9100148\tbest: 0.9100148 (644)\ttotal: 1m 31s\tremaining: 50.5s\n",
      "646:\ttest: 0.9099244\tbest: 0.9100148 (644)\ttotal: 1m 32s\tremaining: 50.3s\n",
      "648:\ttest: 0.9100728\tbest: 0.9100728 (648)\ttotal: 1m 32s\tremaining: 50s\n",
      "650:\ttest: 0.9102030\tbest: 0.9102030 (650)\ttotal: 1m 32s\tremaining: 49.7s\n",
      "652:\ttest: 0.9102924\tbest: 0.9102924 (652)\ttotal: 1m 32s\tremaining: 49.4s\n",
      "654:\ttest: 0.9104796\tbest: 0.9104796 (654)\ttotal: 1m 33s\tremaining: 49.1s\n",
      "656:\ttest: 0.9104966\tbest: 0.9104966 (656)\ttotal: 1m 33s\tremaining: 48.7s\n",
      "658:\ttest: 0.9105510\tbest: 0.9105510 (658)\ttotal: 1m 33s\tremaining: 48.4s\n",
      "660:\ttest: 0.9105165\tbest: 0.9105510 (658)\ttotal: 1m 33s\tremaining: 48.1s\n",
      "662:\ttest: 0.9104682\tbest: 0.9105510 (658)\ttotal: 1m 34s\tremaining: 47.8s\n",
      "664:\ttest: 0.9107039\tbest: 0.9107078 (663)\ttotal: 1m 34s\tremaining: 47.5s\n",
      "666:\ttest: 0.9106531\tbest: 0.9107078 (663)\ttotal: 1m 34s\tremaining: 47.2s\n",
      "668:\ttest: 0.9108562\tbest: 0.9108562 (668)\ttotal: 1m 35s\tremaining: 47s\n",
      "670:\ttest: 0.9107252\tbest: 0.9108562 (668)\ttotal: 1m 35s\tremaining: 46.7s\n",
      "672:\ttest: 0.9107653\tbest: 0.9108562 (668)\ttotal: 1m 35s\tremaining: 46.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674:\ttest: 0.9108927\tbest: 0.9108927 (674)\ttotal: 1m 35s\tremaining: 46.1s\n",
      "676:\ttest: 0.9110576\tbest: 0.9110576 (676)\ttotal: 1m 36s\tremaining: 45.8s\n",
      "678:\ttest: 0.9111361\tbest: 0.9111363 (677)\ttotal: 1m 36s\tremaining: 45.5s\n",
      "680:\ttest: 0.9111003\tbest: 0.9111492 (679)\ttotal: 1m 36s\tremaining: 45.3s\n",
      "682:\ttest: 0.9112466\tbest: 0.9112466 (682)\ttotal: 1m 37s\tremaining: 45.1s\n",
      "684:\ttest: 0.9112769\tbest: 0.9112940 (683)\ttotal: 1m 37s\tremaining: 44.9s\n",
      "686:\ttest: 0.9112731\tbest: 0.9112940 (683)\ttotal: 1m 37s\tremaining: 44.6s\n",
      "688:\ttest: 0.9111816\tbest: 0.9112940 (683)\ttotal: 1m 38s\tremaining: 44.4s\n",
      "690:\ttest: 0.9111109\tbest: 0.9112940 (683)\ttotal: 1m 38s\tremaining: 44.2s\n",
      "692:\ttest: 0.9111445\tbest: 0.9112940 (683)\ttotal: 1m 39s\tremaining: 43.9s\n",
      "694:\ttest: 0.9111579\tbest: 0.9112940 (683)\ttotal: 1m 39s\tremaining: 43.8s\n",
      "696:\ttest: 0.9112235\tbest: 0.9112940 (683)\ttotal: 1m 40s\tremaining: 43.5s\n",
      "698:\ttest: 0.9112607\tbest: 0.9112940 (683)\ttotal: 1m 40s\tremaining: 43.3s\n",
      "700:\ttest: 0.9113479\tbest: 0.9113514 (699)\ttotal: 1m 40s\tremaining: 43s\n",
      "702:\ttest: 0.9113592\tbest: 0.9113592 (702)\ttotal: 1m 41s\tremaining: 42.8s\n",
      "704:\ttest: 0.9112617\tbest: 0.9113592 (702)\ttotal: 1m 41s\tremaining: 42.6s\n",
      "706:\ttest: 0.9112987\tbest: 0.9113592 (702)\ttotal: 1m 42s\tremaining: 42.4s\n",
      "708:\ttest: 0.9114845\tbest: 0.9114845 (708)\ttotal: 1m 42s\tremaining: 42.1s\n",
      "710:\ttest: 0.9116250\tbest: 0.9116250 (710)\ttotal: 1m 42s\tremaining: 41.8s\n",
      "712:\ttest: 0.9116175\tbest: 0.9116250 (710)\ttotal: 1m 43s\tremaining: 41.5s\n",
      "714:\ttest: 0.9117060\tbest: 0.9117060 (714)\ttotal: 1m 43s\tremaining: 41.2s\n",
      "716:\ttest: 0.9120261\tbest: 0.9120261 (716)\ttotal: 1m 43s\tremaining: 40.9s\n",
      "718:\ttest: 0.9121252\tbest: 0.9121252 (718)\ttotal: 1m 43s\tremaining: 40.6s\n",
      "720:\ttest: 0.9121772\tbest: 0.9121772 (720)\ttotal: 1m 44s\tremaining: 40.3s\n",
      "722:\ttest: 0.9122311\tbest: 0.9122311 (722)\ttotal: 1m 44s\tremaining: 40s\n",
      "724:\ttest: 0.9122470\tbest: 0.9122801 (723)\ttotal: 1m 44s\tremaining: 39.7s\n",
      "726:\ttest: 0.9121151\tbest: 0.9122801 (723)\ttotal: 1m 45s\tremaining: 39.4s\n",
      "728:\ttest: 0.9121147\tbest: 0.9122801 (723)\ttotal: 1m 45s\tremaining: 39.1s\n",
      "730:\ttest: 0.9121594\tbest: 0.9122801 (723)\ttotal: 1m 45s\tremaining: 38.8s\n",
      "732:\ttest: 0.9120824\tbest: 0.9122801 (723)\ttotal: 1m 45s\tremaining: 38.5s\n",
      "734:\ttest: 0.9121555\tbest: 0.9122801 (723)\ttotal: 1m 46s\tremaining: 38.3s\n",
      "736:\ttest: 0.9123327\tbest: 0.9123327 (736)\ttotal: 1m 46s\tremaining: 38s\n",
      "738:\ttest: 0.9123909\tbest: 0.9123909 (738)\ttotal: 1m 46s\tremaining: 37.7s\n",
      "740:\ttest: 0.9124658\tbest: 0.9124658 (740)\ttotal: 1m 47s\tremaining: 37.4s\n",
      "742:\ttest: 0.9124716\tbest: 0.9124734 (741)\ttotal: 1m 47s\tremaining: 37.1s\n",
      "744:\ttest: 0.9124152\tbest: 0.9124734 (741)\ttotal: 1m 47s\tremaining: 36.8s\n",
      "746:\ttest: 0.9124370\tbest: 0.9124734 (741)\ttotal: 1m 47s\tremaining: 36.5s\n",
      "748:\ttest: 0.9125090\tbest: 0.9125090 (748)\ttotal: 1m 47s\tremaining: 36.2s\n",
      "750:\ttest: 0.9124803\tbest: 0.9125090 (748)\ttotal: 1m 48s\tremaining: 35.9s\n",
      "752:\ttest: 0.9126738\tbest: 0.9126738 (751)\ttotal: 1m 48s\tremaining: 35.6s\n",
      "754:\ttest: 0.9126822\tbest: 0.9126822 (754)\ttotal: 1m 48s\tremaining: 35.4s\n",
      "756:\ttest: 0.9126699\tbest: 0.9126822 (754)\ttotal: 1m 49s\tremaining: 35.1s\n",
      "758:\ttest: 0.9125658\tbest: 0.9126822 (754)\ttotal: 1m 49s\tremaining: 34.8s\n",
      "760:\ttest: 0.9127945\tbest: 0.9127945 (760)\ttotal: 1m 49s\tremaining: 34.4s\n",
      "762:\ttest: 0.9129612\tbest: 0.9129612 (762)\ttotal: 1m 49s\tremaining: 34.2s\n",
      "764:\ttest: 0.9128774\tbest: 0.9129791 (763)\ttotal: 1m 50s\tremaining: 33.9s\n",
      "766:\ttest: 0.9129267\tbest: 0.9129791 (763)\ttotal: 1m 50s\tremaining: 33.5s\n",
      "768:\ttest: 0.9130305\tbest: 0.9130308 (767)\ttotal: 1m 50s\tremaining: 33.2s\n",
      "770:\ttest: 0.9130820\tbest: 0.9130820 (770)\ttotal: 1m 50s\tremaining: 32.9s\n",
      "772:\ttest: 0.9127135\tbest: 0.9130958 (771)\ttotal: 1m 51s\tremaining: 32.7s\n",
      "774:\ttest: 0.9127494\tbest: 0.9130958 (771)\ttotal: 1m 51s\tremaining: 32.4s\n",
      "776:\ttest: 0.9127253\tbest: 0.9130958 (771)\ttotal: 1m 51s\tremaining: 32.1s\n",
      "778:\ttest: 0.9127456\tbest: 0.9130958 (771)\ttotal: 1m 51s\tremaining: 31.8s\n",
      "780:\ttest: 0.9127342\tbest: 0.9130958 (771)\ttotal: 1m 52s\tremaining: 31.5s\n",
      "782:\ttest: 0.9127959\tbest: 0.9130958 (771)\ttotal: 1m 52s\tremaining: 31.2s\n",
      "784:\ttest: 0.9128005\tbest: 0.9130958 (771)\ttotal: 1m 52s\tremaining: 30.9s\n",
      "786:\ttest: 0.9129401\tbest: 0.9130958 (771)\ttotal: 1m 52s\tremaining: 30.6s\n",
      "788:\ttest: 0.9129380\tbest: 0.9130958 (771)\ttotal: 1m 53s\tremaining: 30.3s\n",
      "790:\ttest: 0.9130308\tbest: 0.9130958 (771)\ttotal: 1m 53s\tremaining: 30s\n",
      "792:\ttest: 0.9128995\tbest: 0.9130958 (771)\ttotal: 1m 53s\tremaining: 29.7s\n",
      "794:\ttest: 0.9129143\tbest: 0.9130958 (771)\ttotal: 1m 54s\tremaining: 29.4s\n",
      "796:\ttest: 0.9129239\tbest: 0.9130958 (771)\ttotal: 1m 54s\tremaining: 29.2s\n",
      "798:\ttest: 0.9127442\tbest: 0.9130958 (771)\ttotal: 1m 54s\tremaining: 28.9s\n",
      "800:\ttest: 0.9127681\tbest: 0.9130958 (771)\ttotal: 1m 55s\tremaining: 28.6s\n",
      "802:\ttest: 0.9128646\tbest: 0.9130958 (771)\ttotal: 1m 55s\tremaining: 28.3s\n",
      "804:\ttest: 0.9132926\tbest: 0.9132926 (804)\ttotal: 1m 56s\tremaining: 28.1s\n",
      "806:\ttest: 0.9133437\tbest: 0.9133437 (806)\ttotal: 1m 56s\tremaining: 27.8s\n",
      "808:\ttest: 0.9132453\tbest: 0.9133437 (806)\ttotal: 1m 56s\tremaining: 27.6s\n",
      "810:\ttest: 0.9132507\tbest: 0.9133437 (806)\ttotal: 1m 57s\tremaining: 27.3s\n",
      "812:\ttest: 0.9132595\tbest: 0.9133437 (806)\ttotal: 1m 57s\tremaining: 27.1s\n",
      "814:\ttest: 0.9133434\tbest: 0.9133437 (806)\ttotal: 1m 58s\tremaining: 26.8s\n",
      "816:\ttest: 0.9137805\tbest: 0.9137805 (816)\ttotal: 1m 58s\tremaining: 26.5s\n",
      "818:\ttest: 0.9138101\tbest: 0.9138101 (818)\ttotal: 1m 58s\tremaining: 26.2s\n",
      "820:\ttest: 0.9138150\tbest: 0.9138150 (820)\ttotal: 1m 58s\tremaining: 25.9s\n",
      "822:\ttest: 0.9138189\tbest: 0.9138261 (821)\ttotal: 1m 59s\tremaining: 25.6s\n",
      "824:\ttest: 0.9139890\tbest: 0.9139890 (824)\ttotal: 1m 59s\tremaining: 25.4s\n",
      "826:\ttest: 0.9139569\tbest: 0.9139890 (824)\ttotal: 2m\tremaining: 25.1s\n",
      "828:\ttest: 0.9140291\tbest: 0.9140291 (828)\ttotal: 2m\tremaining: 24.8s\n",
      "830:\ttest: 0.9141501\tbest: 0.9141501 (830)\ttotal: 2m\tremaining: 24.6s\n",
      "832:\ttest: 0.9142422\tbest: 0.9142422 (832)\ttotal: 2m 1s\tremaining: 24.3s\n",
      "834:\ttest: 0.9142705\tbest: 0.9142705 (834)\ttotal: 2m 1s\tremaining: 24s\n",
      "836:\ttest: 0.9143239\tbest: 0.9143239 (836)\ttotal: 2m 1s\tremaining: 23.7s\n",
      "838:\ttest: 0.9143617\tbest: 0.9143617 (838)\ttotal: 2m 2s\tremaining: 23.4s\n",
      "840:\ttest: 0.9144262\tbest: 0.9144262 (840)\ttotal: 2m 2s\tremaining: 23.1s\n",
      "842:\ttest: 0.9145033\tbest: 0.9145033 (842)\ttotal: 2m 2s\tremaining: 22.8s\n",
      "844:\ttest: 0.9145596\tbest: 0.9145596 (844)\ttotal: 2m 2s\tremaining: 22.6s\n",
      "846:\ttest: 0.9146585\tbest: 0.9146585 (846)\ttotal: 2m 3s\tremaining: 22.3s\n",
      "848:\ttest: 0.9148206\tbest: 0.9148206 (848)\ttotal: 2m 3s\tremaining: 22s\n",
      "850:\ttest: 0.9151302\tbest: 0.9151302 (850)\ttotal: 2m 3s\tremaining: 21.7s\n",
      "852:\ttest: 0.9154824\tbest: 0.9154824 (852)\ttotal: 2m 3s\tremaining: 21.4s\n",
      "854:\ttest: 0.9155004\tbest: 0.9155108 (853)\ttotal: 2m 4s\tremaining: 21.1s\n",
      "856:\ttest: 0.9154963\tbest: 0.9155108 (853)\ttotal: 2m 4s\tremaining: 20.8s\n",
      "858:\ttest: 0.9154757\tbest: 0.9155108 (853)\ttotal: 2m 4s\tremaining: 20.5s\n",
      "860:\ttest: 0.9156455\tbest: 0.9156455 (860)\ttotal: 2m 5s\tremaining: 20.2s\n",
      "862:\ttest: 0.9158015\tbest: 0.9158015 (862)\ttotal: 2m 5s\tremaining: 19.9s\n",
      "864:\ttest: 0.9157722\tbest: 0.9158015 (862)\ttotal: 2m 5s\tremaining: 19.6s\n",
      "866:\ttest: 0.9157447\tbest: 0.9158015 (862)\ttotal: 2m 5s\tremaining: 19.3s\n",
      "868:\ttest: 0.9158169\tbest: 0.9158169 (868)\ttotal: 2m 6s\tremaining: 19s\n",
      "870:\ttest: 0.9161037\tbest: 0.9161037 (870)\ttotal: 2m 6s\tremaining: 18.7s\n",
      "872:\ttest: 0.9161329\tbest: 0.9161348 (871)\ttotal: 2m 6s\tremaining: 18.4s\n",
      "874:\ttest: 0.9162918\tbest: 0.9163396 (873)\ttotal: 2m 6s\tremaining: 18.1s\n",
      "876:\ttest: 0.9163960\tbest: 0.9163960 (876)\ttotal: 2m 7s\tremaining: 17.8s\n",
      "878:\ttest: 0.9161837\tbest: 0.9163960 (876)\ttotal: 2m 7s\tremaining: 17.5s\n",
      "880:\ttest: 0.9162243\tbest: 0.9163960 (876)\ttotal: 2m 7s\tremaining: 17.3s\n",
      "882:\ttest: 0.9161737\tbest: 0.9163960 (876)\ttotal: 2m 8s\tremaining: 17s\n",
      "884:\ttest: 0.9161581\tbest: 0.9163960 (876)\ttotal: 2m 8s\tremaining: 16.7s\n",
      "886:\ttest: 0.9160292\tbest: 0.9163960 (876)\ttotal: 2m 8s\tremaining: 16.4s\n",
      "888:\ttest: 0.9158366\tbest: 0.9163960 (876)\ttotal: 2m 9s\tremaining: 16.1s\n",
      "890:\ttest: 0.9158335\tbest: 0.9163960 (876)\ttotal: 2m 9s\tremaining: 15.8s\n",
      "892:\ttest: 0.9157733\tbest: 0.9163960 (876)\ttotal: 2m 9s\tremaining: 15.5s\n",
      "894:\ttest: 0.9157360\tbest: 0.9163960 (876)\ttotal: 2m 9s\tremaining: 15.2s\n",
      "896:\ttest: 0.9157314\tbest: 0.9163960 (876)\ttotal: 2m 10s\tremaining: 14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898:\ttest: 0.9157759\tbest: 0.9163960 (876)\ttotal: 2m 10s\tremaining: 14.7s\n",
      "900:\ttest: 0.9158757\tbest: 0.9163960 (876)\ttotal: 2m 10s\tremaining: 14.4s\n",
      "902:\ttest: 0.9158886\tbest: 0.9163960 (876)\ttotal: 2m 10s\tremaining: 14.1s\n",
      "904:\ttest: 0.9159275\tbest: 0.9163960 (876)\ttotal: 2m 11s\tremaining: 13.8s\n",
      "906:\ttest: 0.9160515\tbest: 0.9163960 (876)\ttotal: 2m 11s\tremaining: 13.5s\n",
      "908:\ttest: 0.9160275\tbest: 0.9163960 (876)\ttotal: 2m 11s\tremaining: 13.2s\n",
      "910:\ttest: 0.9162328\tbest: 0.9163960 (876)\ttotal: 2m 11s\tremaining: 12.9s\n",
      "912:\ttest: 0.9162643\tbest: 0.9163960 (876)\ttotal: 2m 11s\tremaining: 12.6s\n",
      "914:\ttest: 0.9162898\tbest: 0.9163960 (876)\ttotal: 2m 12s\tremaining: 12.3s\n",
      "916:\ttest: 0.9164878\tbest: 0.9164878 (916)\ttotal: 2m 12s\tremaining: 12s\n",
      "918:\ttest: 0.9165342\tbest: 0.9165342 (918)\ttotal: 2m 12s\tremaining: 11.7s\n",
      "920:\ttest: 0.9166540\tbest: 0.9166540 (920)\ttotal: 2m 12s\tremaining: 11.4s\n",
      "922:\ttest: 0.9167465\tbest: 0.9167551 (921)\ttotal: 2m 13s\tremaining: 11.1s\n",
      "924:\ttest: 0.9168673\tbest: 0.9168673 (924)\ttotal: 2m 13s\tremaining: 10.8s\n",
      "926:\ttest: 0.9168699\tbest: 0.9169148 (925)\ttotal: 2m 13s\tremaining: 10.5s\n",
      "928:\ttest: 0.9168750\tbest: 0.9169148 (925)\ttotal: 2m 13s\tremaining: 10.2s\n",
      "930:\ttest: 0.9170542\tbest: 0.9170542 (930)\ttotal: 2m 14s\tremaining: 9.94s\n",
      "932:\ttest: 0.9171403\tbest: 0.9171405 (931)\ttotal: 2m 14s\tremaining: 9.65s\n",
      "934:\ttest: 0.9173101\tbest: 0.9173101 (934)\ttotal: 2m 14s\tremaining: 9.35s\n",
      "936:\ttest: 0.9173546\tbest: 0.9173703 (935)\ttotal: 2m 14s\tremaining: 9.06s\n",
      "938:\ttest: 0.9173824\tbest: 0.9173824 (938)\ttotal: 2m 14s\tremaining: 8.77s\n",
      "940:\ttest: 0.9173540\tbest: 0.9173841 (939)\ttotal: 2m 15s\tremaining: 8.48s\n",
      "942:\ttest: 0.9174707\tbest: 0.9175148 (941)\ttotal: 2m 15s\tremaining: 8.19s\n",
      "944:\ttest: 0.9174894\tbest: 0.9175148 (941)\ttotal: 2m 15s\tremaining: 7.9s\n",
      "946:\ttest: 0.9174481\tbest: 0.9175148 (941)\ttotal: 2m 15s\tremaining: 7.61s\n",
      "948:\ttest: 0.9175053\tbest: 0.9175148 (941)\ttotal: 2m 16s\tremaining: 7.32s\n",
      "950:\ttest: 0.9177447\tbest: 0.9177447 (950)\ttotal: 2m 16s\tremaining: 7.04s\n",
      "952:\ttest: 0.9179243\tbest: 0.9179243 (952)\ttotal: 2m 16s\tremaining: 6.75s\n",
      "954:\ttest: 0.9179781\tbest: 0.9179781 (954)\ttotal: 2m 16s\tremaining: 6.45s\n",
      "956:\ttest: 0.9180340\tbest: 0.9180340 (956)\ttotal: 2m 17s\tremaining: 6.17s\n",
      "958:\ttest: 0.9180605\tbest: 0.9180892 (957)\ttotal: 2m 17s\tremaining: 5.88s\n",
      "960:\ttest: 0.9180938\tbest: 0.9181045 (959)\ttotal: 2m 17s\tremaining: 5.59s\n",
      "962:\ttest: 0.9181097\tbest: 0.9181097 (962)\ttotal: 2m 17s\tremaining: 5.3s\n",
      "964:\ttest: 0.9181507\tbest: 0.9181591 (963)\ttotal: 2m 18s\tremaining: 5.01s\n",
      "966:\ttest: 0.9181573\tbest: 0.9181591 (963)\ttotal: 2m 18s\tremaining: 4.72s\n",
      "968:\ttest: 0.9182373\tbest: 0.9182373 (968)\ttotal: 2m 18s\tremaining: 4.43s\n",
      "970:\ttest: 0.9184047\tbest: 0.9184047 (970)\ttotal: 2m 18s\tremaining: 4.15s\n",
      "972:\ttest: 0.9185258\tbest: 0.9185283 (971)\ttotal: 2m 19s\tremaining: 3.86s\n",
      "974:\ttest: 0.9185369\tbest: 0.9185436 (973)\ttotal: 2m 19s\tremaining: 3.57s\n",
      "976:\ttest: 0.9185594\tbest: 0.9185594 (976)\ttotal: 2m 19s\tremaining: 3.28s\n",
      "978:\ttest: 0.9185665\tbest: 0.9185836 (977)\ttotal: 2m 19s\tremaining: 3s\n",
      "980:\ttest: 0.9185596\tbest: 0.9185836 (977)\ttotal: 2m 19s\tremaining: 2.71s\n",
      "982:\ttest: 0.9185534\tbest: 0.9185836 (977)\ttotal: 2m 20s\tremaining: 2.42s\n",
      "984:\ttest: 0.9185931\tbest: 0.9185931 (984)\ttotal: 2m 20s\tremaining: 2.14s\n",
      "986:\ttest: 0.9184324\tbest: 0.9185931 (984)\ttotal: 2m 20s\tremaining: 1.85s\n",
      "988:\ttest: 0.9184246\tbest: 0.9185931 (984)\ttotal: 2m 20s\tremaining: 1.56s\n",
      "990:\ttest: 0.9185089\tbest: 0.9185931 (984)\ttotal: 2m 20s\tremaining: 1.28s\n",
      "992:\ttest: 0.9185098\tbest: 0.9185931 (984)\ttotal: 2m 21s\tremaining: 995ms\n",
      "994:\ttest: 0.9184908\tbest: 0.9185931 (984)\ttotal: 2m 21s\tremaining: 710ms\n",
      "996:\ttest: 0.9186403\tbest: 0.9186403 (996)\ttotal: 2m 21s\tremaining: 426ms\n",
      "998:\ttest: 0.9186608\tbest: 0.9186608 (998)\ttotal: 2m 21s\tremaining: 142ms\n",
      "999:\ttest: 0.9185928\tbest: 0.9186608 (998)\ttotal: 2m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9186608178\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x23f099b2fa0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = ['DISC_ID', 'TYPE_NAME', 'GENDER', 'CITIZENSHIP', \n",
    "            'EXAM_TYPE', 'EXAM_SUBJECT_1', 'EXAM_SUBJECT_2', \n",
    "            'EXAM_SUBJECT_3', 'ADMITTED_SUBJECT_PRIZE_LEVEL', 'REGION_ID']\n",
    "\n",
    "clf = CatBoostClassifier(random_state=RAND,\\\n",
    "                         eval_metric=\"AUC\", \n",
    "                         scale_pos_weight = percent_of_negative_class,\n",
    "                         cat_features = cat_features)\n",
    "\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "clf.fit(X_train_,\n",
    "        y_train_,\n",
    "        eval_set=eval_set,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7daf56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.213353</td>\n",
       "      <td>0.481870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_train</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.886426</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.829310</td>\n",
       "      <td>0.803692</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>0.368354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_train</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.959865</td>\n",
       "      <td>0.236119</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.377731</td>\n",
       "      <td>0.331044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.890645</td>\n",
       "      <td>0.920715</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.785457</td>\n",
       "      <td>0.403327</td>\n",
       "      <td>0.303524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_train</td>\n",
       "      <td>0.898862</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.454959</td>\n",
       "      <td>0.289007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "0                   XGBoost  0.768298  0.806016   0.126959  0.667747   \n",
       "0             XGBoost_train  0.784206  0.886426   0.155538  0.808008   \n",
       "0                  LightGBM  0.829310  0.803692   0.155154  0.591073   \n",
       "0            LightGBM_train  0.853462  0.959865   0.236119  0.943730   \n",
       "0                  Catboost  0.890645  0.920715   0.271326  0.785457   \n",
       "0            Catboost_train  0.898862  0.963000   0.304922  0.895680   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  \n",
       "0  0.213353  0.481870  \n",
       "0  0.260861  0.466063  \n",
       "0  0.245790  0.368354  \n",
       "0  0.377731  0.331044  \n",
       "0  0.403327  0.303524  \n",
       "0  0.454959  0.289007  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_prob = clf.predict_proba(X_test)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test, y_pred, y_pred_prob, name='Catboost'))\n",
    "\n",
    "y_pred_train = clf.predict(X_train_)\n",
    "y_pred_prob_train = clf.predict_proba(X_train_)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='Catboost_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a419ccb2",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "045e013f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(random_state=RAND)\n",
    "clf.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0d83269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.213353</td>\n",
       "      <td>0.481870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_train</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.886426</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.829310</td>\n",
       "      <td>0.803692</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>0.368354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_train</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.959865</td>\n",
       "      <td>0.236119</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.377731</td>\n",
       "      <td>0.331044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.890645</td>\n",
       "      <td>0.920715</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.785457</td>\n",
       "      <td>0.403327</td>\n",
       "      <td>0.303524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_train</td>\n",
       "      <td>0.898862</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.454959</td>\n",
       "      <td>0.289007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosting</td>\n",
       "      <td>0.954605</td>\n",
       "      <td>0.734157</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.092756</td>\n",
       "      <td>0.168539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosting_train</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>0.748371</td>\n",
       "      <td>0.888298</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.110068</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "0                   XGBoost  0.768298  0.806016   0.126959  0.667747   \n",
       "0             XGBoost_train  0.784206  0.886426   0.155538  0.808008   \n",
       "0                  LightGBM  0.829310  0.803692   0.155154  0.591073   \n",
       "0            LightGBM_train  0.853462  0.959865   0.236119  0.943730   \n",
       "0                  Catboost  0.890645  0.920715   0.271326  0.785457   \n",
       "0            Catboost_train  0.898862  0.963000   0.304922  0.895680   \n",
       "0         Gradient_Boosting  0.954605  0.734157   0.778409  0.049316   \n",
       "0   Gradient_Boosting_train  0.954940  0.748371   0.888298  0.058669   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  \n",
       "0  0.213353  0.481870  \n",
       "0  0.260861  0.466063  \n",
       "0  0.245790  0.368354  \n",
       "0  0.377731  0.331044  \n",
       "0  0.403327  0.303524  \n",
       "0  0.454959  0.289007  \n",
       "0  0.092756  0.168539  \n",
       "0  0.110068  0.165294  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_bin)\n",
    "y_pred_prob = clf.predict_proba(X_test_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test, y_pred, y_pred_prob, name='Gradient_Boosting'))\n",
    "\n",
    "y_pred_train = clf.predict(X_train_bin)\n",
    "y_pred_prob_train = clf.predict_proba(X_train_bin)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='Gradient_Boosting_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598a4ba",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e4bdf202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train_bin_scaled, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1797660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.742184</td>\n",
       "      <td>0.095195</td>\n",
       "      <td>0.637509</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>0.566596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree</td>\n",
       "      <td>0.946593</td>\n",
       "      <td>0.788852</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.609431</td>\n",
       "      <td>0.517816</td>\n",
       "      <td>1.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_tree_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest</td>\n",
       "      <td>0.951912</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>0.279338</td>\n",
       "      <td>0.353450</td>\n",
       "      <td>0.351344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random_forest_train</td>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.842620</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.914074</td>\n",
       "      <td>0.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier</td>\n",
       "      <td>0.953013</td>\n",
       "      <td>0.741952</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.030598</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.168947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagging_classifier_train</td>\n",
       "      <td>0.952821</td>\n",
       "      <td>0.772599</td>\n",
       "      <td>0.555233</td>\n",
       "      <td>0.033550</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>0.164812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768298</td>\n",
       "      <td>0.806016</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.667747</td>\n",
       "      <td>0.213353</td>\n",
       "      <td>0.481870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_train</td>\n",
       "      <td>0.784206</td>\n",
       "      <td>0.886426</td>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.808008</td>\n",
       "      <td>0.260861</td>\n",
       "      <td>0.466063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.829310</td>\n",
       "      <td>0.803692</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>0.591073</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>0.368354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_train</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.959865</td>\n",
       "      <td>0.236119</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.377731</td>\n",
       "      <td>0.331044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.890645</td>\n",
       "      <td>0.920715</td>\n",
       "      <td>0.271326</td>\n",
       "      <td>0.785457</td>\n",
       "      <td>0.403327</td>\n",
       "      <td>0.303524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost_train</td>\n",
       "      <td>0.898862</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.454959</td>\n",
       "      <td>0.289007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosting</td>\n",
       "      <td>0.954605</td>\n",
       "      <td>0.734157</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.092756</td>\n",
       "      <td>0.168539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient_Boosting_train</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>0.748371</td>\n",
       "      <td>0.888298</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.110068</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.956248</td>\n",
       "      <td>0.727440</td>\n",
       "      <td>0.641921</td>\n",
       "      <td>0.158747</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_train</td>\n",
       "      <td>0.962023</td>\n",
       "      <td>0.962151</td>\n",
       "      <td>0.833821</td>\n",
       "      <td>0.250307</td>\n",
       "      <td>0.385031</td>\n",
       "      <td>0.090380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0        LogisticRegression  0.697817  0.742184   0.095195  0.637509   \n",
       "0             Decision_tree  0.946593  0.788852   0.450146  0.609431   \n",
       "0       Decision_tree_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0             Random_forest  0.951912  0.884939   0.481091  0.279338   \n",
       "0       Random_forest_train  0.991081  0.999807   0.842620  0.998770   \n",
       "0        Bagging_classifier  0.953013  0.741952   0.512048  0.030598   \n",
       "0  Bagging_classifier_train  0.952821  0.772599   0.555233  0.033550   \n",
       "0                   XGBoost  0.768298  0.806016   0.126959  0.667747   \n",
       "0             XGBoost_train  0.784206  0.886426   0.155538  0.808008   \n",
       "0                  LightGBM  0.829310  0.803692   0.155154  0.591073   \n",
       "0            LightGBM_train  0.853462  0.959865   0.236119  0.943730   \n",
       "0                  Catboost  0.890645  0.920715   0.271326  0.785457   \n",
       "0            Catboost_train  0.898862  0.963000   0.304922  0.895680   \n",
       "0         Gradient_Boosting  0.954605  0.734157   0.778409  0.049316   \n",
       "0   Gradient_Boosting_train  0.954940  0.748371   0.888298  0.058669   \n",
       "0                       kNN  0.956248  0.727440   0.641921  0.158747   \n",
       "0                 kNN_train  0.962023  0.962151   0.833821  0.250307   \n",
       "\n",
       "         f1   Logloss  \n",
       "0  0.165653  0.566596  \n",
       "0  0.517816  1.536115  \n",
       "0  0.914074  0.017985  \n",
       "0  0.353450  0.351344  \n",
       "0  0.914074  0.017991  \n",
       "0  0.057745  0.168947  \n",
       "0  0.063276  0.164812  \n",
       "0  0.213353  0.481870  \n",
       "0  0.260861  0.466063  \n",
       "0  0.245790  0.368354  \n",
       "0  0.377731  0.331044  \n",
       "0  0.403327  0.303524  \n",
       "0  0.454959  0.289007  \n",
       "0  0.092756  0.168539  \n",
       "0  0.110068  0.165294  \n",
       "0  0.254545  0.777528  \n",
       "0  0.385031  0.090380  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_bin_scaled)\n",
    "y_pred_prob = clf.predict_proba(X_test_bin_scaled)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_test_bin, y_pred, y_pred_prob, name='kNN'))\n",
    "\n",
    "y_pred_train = clf.predict(X_train_bin_scaled)\n",
    "y_pred_prob_train = clf.predict_proba(X_train_bin_scaled)\n",
    "metrics = metrics.append(\n",
    "    get_metrics(y_train_bin, y_pred_train, y_pred_prob_train, name='kNN_train'))\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b57bee",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ffc32",
   "metadata": {},
   "source": [
    "Итак, качество базового алгоритма будем определять по двум критериям:\n",
    "\n",
    "1) значение метрики roc_auc на тестовой выборке\n",
    "\n",
    "2) разрыв между метриками roc_auc и log_loss на тренировочной и тестовой выборках \n",
    "\n",
    "На другие метрики особо смотреть не будем, но их полезно выводить, чтобы лучше контролироовать адекватность происходящего. Так, recall, precision и f1 занулятся, если все объекты выборки будут отнесены к одному классу. Это довольно редкая ситуация, поэтому обратить на неё внимание было бы неплохо. Единственной полностью бесполезной метрикой, конечно, является accuracy в силу дисбаланса классов\n",
    "\n",
    "Исходя из этих соображений, по таблице можно понять, что лучшей бейзлайн моделью является CatBoost. Она дала лучший roc_auc=0.92 на тестовой выборке, при этом различия в метриках на train и на test минимальны\n",
    "\n",
    "XGBoost и LightGBM также дали хорошие результаты. Для LightGBM подберём гиперпараметры, и вполне возможно, что он побьёт Catboost в силу его известной хорошей начальной настройки. XGBoost, пожалуй, не будем брать в финал в силу того, что он не может работать с категориальными признаками, которых у нас подавляющее большинство. Нам приходится их бинаризовывать, а это часто не очень хорошо влияет на работу бустингов\n",
    "\n",
    "Итак, мы остановились на двух моделях - Catboost и LightGBM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
