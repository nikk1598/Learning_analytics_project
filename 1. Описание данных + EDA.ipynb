{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFRhfVMG0u4M"
      },
      "source": [
        "# Подключение гугл диска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdMLucE_uNi9",
        "outputId": "5fb3e6e7-b682-41e9-82aa-cf03a8038400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90634fee"
      },
      "source": [
        "# Описание задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cd456c2"
      },
      "source": [
        "Данные были взяты с соревнования ods, которое закончилось пару месяцев назад (https://ods.ai/competitions/learning-analytics)\n",
        "\n",
        "Я соедининил датафреймы train, comp_portrait, comp_marks и comp_disc и поставил задачу предсказания наличия у студента задолженности (по конкретной дисциплине в конкретный семестр) на основе имеющейся информации непосредственно в момент поступления в вуз. \n",
        "\n",
        "Таким образом, target (DEBT) является бинарным признаком (1 - есть задолженность, 0 - нет задолженностей), и мы будем решать задачу бинарной классификации \n",
        "\n",
        "Совокупность всех других признаков представляет собой описание попытки:\n",
        "\n",
        "- SEMESTER - семестр получения оценки\n",
        "- DISC_ID - UID дисциплины\n",
        "- TYPE_NAME - форма отчётности\n",
        "- GENDER - пол студента\n",
        "- CITIZENSHIP - гражданство студента\n",
        "- EXAM_TYPE - форма зачисления студента (ЕГЭ, олимпиада, ВИ - вступительные испытания)\n",
        "- EXAM_SUBJECT_1 - первый экзамен ЕГЭ\n",
        "- EXAM_SUBJECT_2 - второй экзамен ЕГЭ\n",
        "- EXAM_SUBJECT_3 - третий экзамен ЕГЭ\n",
        "- ADMITTED_EXAM_1 - баллы за 1 экзамен ЕГЭ\n",
        "- ADMITTED_EXAM_2 - баллы за 2 экзамен ЕГЭ\n",
        "- ADMITTED_EXAM_3 - баллы за 3 экзамен \n",
        "- ADMITTED_SUBJECT_PRIZE_LEVEL - уровень олимпиады (если есть)\n",
        "- REGION_ID - номер региона студента\n",
        "\n",
        "Также присутствуют бинаризованные признаки (каждый столбец представляет собой одно значение признака; 1 - значение соответствует объекту, 0 - не соответствует):\n",
        "- MAIN_PLAN - учебный план\n",
        "- PRED_ID - UID преподавателя\n",
        "- DISC_DEP - факультет-организатор дисциплины\n",
        "- CHOICE - выборность дисциплины"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "067080e7"
      },
      "source": [
        "# Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e7aafb0",
        "outputId": "f9dc21a9-2b8e-4680-859d-ed4fa79dbf14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Catboost\n",
            "  Downloading catboost-1.1-cp37-none-manylinux1_x86_64.whl (76.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from Catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from Catboost) (1.7.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from Catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from Catboost) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->Catboost) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->Catboost) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->Catboost) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->Catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->Catboost) (8.1.0)\n",
            "Installing collected packages: Catboost\n",
            "Successfully installed Catboost-1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.42)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=17f01736740392743d78d4341a65fdacbf75d59552ef831f6091111e19347f57\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.3 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Catboost\n",
        "!pip install optuna\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
        "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
        "    precision_recall_curve, roc_curve\n",
        "\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "import optuna\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfzLwTBCx00r"
      },
      "source": [
        "# Загрузка конфигурационного файла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8l2wfg04JJ"
      },
      "source": [
        "Загрузим файл, в котором лежат все необходимые константы, пути и т.д. Это нужно для того, чтобы в случае каких-либо изменений можно было поменять одну строку в файле, а не искать по всему проекту места, в которых используется старое значение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xngIzn8Cu8BD"
      },
      "outputs": [],
      "source": [
        "config_path = '/content/drive/MyDrive/params_.yml'\n",
        "config = yaml.load(open(config_path), Loader=yaml.FullLoader)\n",
        "preproc = config['preprocessing']\n",
        "training = config['training']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5175ed6f"
      },
      "source": [
        "# Считывание данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYKDD6I5hgM"
      },
      "source": [
        "Считаем обучающий датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP8lHW0_1_iy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(preproc['df_path'])\n",
        "df.drop(columns=['mean_score'], inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "XS-vRNk0nT8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_parquet('/content/drive/MyDrive/df.parquet.gzip')"
      ],
      "metadata": {
        "id": "d-vOWq-mRhGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWmJG20p1_ti"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2ioY3A2De9"
      },
      "source": [
        "# Преобразование типов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLNubgYY5Aju"
      },
      "source": [
        "Преобразуем категориальные столбцы в соответствующий тип данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P596Xl62Vud"
      },
      "outputs": [],
      "source": [
        "def transform_types(data: pd.DataFrame, change_type_columns: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Преобразование признаков в заданный тип данных\n",
        "    :param data: датасет\n",
        "    :param change_type_columns: словарь с признаками и типами данных\n",
        "    : return: преобразованный датасет\n",
        "    \"\"\"\n",
        "    return data.astype(change_type_columns, errors=\"raise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMPa6EaF33ER"
      },
      "outputs": [],
      "source": [
        "df = transform_types(data=df, change_type_columns=preproc['change_type_columns'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYhwufphE7Bo"
      },
      "source": [
        "# Сохранение уникальных значений признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmfv7o79FLD-"
      },
      "source": [
        "Сохраним списки уникальных значений для каждого признака, которые затем будем использовать для подачи через UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjFtQZz3FKDL"
      },
      "outputs": [],
      "source": [
        "def save_unique_train_data(data: pd.DataFrame,\n",
        "                           drop_columns: list,\n",
        "                           target_column:str,\n",
        "                           unique_values_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Сохранение словаря с признаками и уникальными значениями\n",
        "    :param drop_columns: список с признаками для удаления\n",
        "    :param data: датасет\n",
        "    :param target_column: целевая переменная\n",
        "    :param unique_values_path: путь до файла со словарём\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    unique_df = data.drop(\n",
        "        columns=drop_columns + [target_column], axis=1, errors=\"ignore\"\n",
        "    )\n",
        "\n",
        "    dict_unique = {key: list(unique_df[key].unique()) for key in unique_df.columns}  \n",
        "    print(dict_unique)\n",
        "    with open(unique_values_path, \"w\") as file:\n",
        "      json.dump(dict_unique, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEHAE45i-kOI"
      },
      "outputs": [],
      "source": [
        "save_unique_train_data(\n",
        "    data=df[preproc['not_binary_columns']],\n",
        "    drop_columns=[],\n",
        "    target_column=preproc['target_column'],\n",
        "    unique_values_path=preproc['unique_values_path']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLjj48yWTwMd"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bce41931"
      },
      "source": [
        "# Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfV7LCNb7Rse"
      },
      "source": [
        "## Основные статистики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a8b9c55"
      },
      "source": [
        "Посмотрим описательные статистики по float столбцам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "009d32f3"
      },
      "outputs": [],
      "source": [
        "df.describe(include=[\"float64\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dcd9cc4"
      },
      "source": [
        "Посмотрим описательные статистики по category столбцам"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08e398d2"
      },
      "outputs": [],
      "source": [
        "df.describe(include=\"category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "209fb27e"
      },
      "source": [
        "## Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e51QpZ6S7uAf"
      },
      "source": [
        "Посмотрим распределение целевой переменной"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBrJbnhT__x4"
      },
      "outputs": [],
      "source": [
        "def plot_text(ax):\n",
        "    \"\"\"\n",
        "    Добавление подписи процентов на график barplot\n",
        "    :param ax: ось\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    for p in ax.patches:\n",
        "        percentage = '{:.1f}%'.format(p.get_height())\n",
        "        ax.annotate(\n",
        "            percentage,  # текст\n",
        "            # координата xy\n",
        "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "            # центрирование\n",
        "            ha='center',\n",
        "            va='center',\n",
        "            xytext=(0, 10),\n",
        "            # точка смещения относительно координаты\n",
        "            textcoords='offset points',\n",
        "            fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMdikpMi1_3S"
      },
      "outputs": [],
      "source": [
        "def barplot(data: pd.DataFrame,\n",
        "            col: str,\n",
        "            title: str) -> None:\n",
        "    \"\"\"\n",
        "    Построение графика распределения признака в виде столбчатой диаграммы\n",
        "    :param data: датасет\n",
        "    :param col: столбец, для которого которого хотим смотреть распределение\n",
        "    :param title: заголовок\n",
        "    :return: None \n",
        "    \"\"\"\n",
        "    rcParams['figure.figsize'] = 10, 8\n",
        "    sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "\n",
        "    # Датафрейм частот значений  \n",
        "    norm_target = pd.DataFrame(df[col].value_counts(normalize=True).mul(100)\\\n",
        "                           .rename('percent')).reset_index()\n",
        "\n",
        "    ax = sns.barplot(x='index', y='percent', data=norm_target, palette=\"flare\")\n",
        "    plt.title(title)\n",
        "    plot_text(ax) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MDOnz0o9RIU"
      },
      "outputs": [],
      "source": [
        "barplot(data=df,\n",
        "        col=preproc['target_column'], \n",
        "        title='Распределение классов в разрезе target')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qYnqpmNEWuR"
      },
      "source": [
        "Видим сильный дисбаланс классов, это нужно будет учесть при обучении алгоритма"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcc99c4b"
      },
      "source": [
        "Придумаем ряд гипотез, которые помогут нам лучше понять данные, и сразу же их проверим"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c21c71b"
      },
      "source": [
        "## 1 гипотеза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a023f035"
      },
      "source": [
        "Доля задолженностей у мужчин больше, чем у женщин (иными словами, вероятность того, что случайно выбранный объект с gender='М' будет принадлежать целевому классу больше вероятности того, что случайно выбранный объект с gender='Ж' будет принадлежать целевому классу)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5kqPj-R1_8Q"
      },
      "outputs": [],
      "source": [
        "def barplot_group(data: pd.DataFrame,\n",
        "                  col: str,\n",
        "                  col_group: str,\n",
        "                  values_in_col_group: list,\n",
        "                  title: str) -> None:\n",
        "    \"\"\"\n",
        "    Построение графика распределения признака в виде ступенчатой диаграммы\n",
        "    в разрезе другого бинарного признака\n",
        "    :param data: датасет\n",
        "    :param col: столбец, для которого хотим смотреть распределение\n",
        "    :param col_group: столбец, в разрезе которого хотим смотреть распределение\n",
        "    :values_in_col_group: список значений col_group\n",
        "    :param title: заголовок\n",
        "    :return: None \n",
        "    \"\"\"\n",
        "    rcParams['figure.figsize'] = 10, 8\n",
        "    sns.color_palette(\"YlOrBr\", as_cmap=True)\n",
        "    \n",
        "    # Датафрейм частот для каждого значения col_group\n",
        "    dataframes_of_frequency = []\n",
        "\n",
        "    for x in values_in_col_group:\n",
        "        freq = df[df[col_group]==x][col]\\\n",
        "                .value_counts(normalize=True).rename('percent').reset_index()\n",
        "        freq[col_group] = x\n",
        "        dataframes_of_frequency.append(freq)\n",
        "\n",
        "    # Общий датафрейм частот\n",
        "    target_values = pd.concat(dataframes_of_frequency)\n",
        "    target_values.rename(columns={\"index\": \"target\"}, inplace=True)\n",
        "    target_values['percent']=target_values['percent']*100\n",
        "\n",
        "    g = sns.catplot(x=col_group,\n",
        "                    y='percent',\n",
        "                    hue='target',\n",
        "                    data=target_values,\n",
        "                    kind='bar',\n",
        "                    height=8,\n",
        "                    palette=sns.color_palette([\"indianred\", \"purple\"]))\n",
        "    plt.title(title)\n",
        "\n",
        "    plot_text(g.ax);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPNNRJ631__P"
      },
      "outputs": [],
      "source": [
        "barplot_group(data=df,\n",
        "              col=preproc['target_column'],\n",
        "              col_group=preproc['gender_column'],\n",
        "              values_in_col_group=preproc['values_in_gender_column'],\n",
        "              title='Распределение target в разрезе пола')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103d56ff"
      },
      "source": [
        "Видим, что доля попыток, закончившихся задолженностью у мужчин почти в 2 раза больше, чем у женщин. Гипотеза подтвердилась, и можно сделать вывод, что пол является важным признаком в нашей задаче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123c076b"
      },
      "source": [
        "## 2 гипотеза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2772069f"
      },
      "source": [
        "Доля задолженностей у олимпиадников меньше, чем у тех, кто сдавал ЕГЭ или вступительные испытания.\n",
        "\n",
        "Это выглядит здравым предположением, так как задачи олимпиад обычно сложнее, и победители должны потратить на них много времени, параллельно готовясь к ЕГЭ/ ВИ. Даже людей, просто участвующих в олимпиадах обычно не очень много, и сложно представить, что те, кто в них побеждают, могут иметь плохие оценки в вузе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faQxevxW2ADD"
      },
      "outputs": [],
      "source": [
        "barplot_group(data=df,\n",
        "              col=preproc['target_column'],\n",
        "              col_group=preproc['exam_type_column'],\n",
        "              values_in_col_group=preproc['values_in_exam_type_column'],\n",
        "              title='Распределение target в разрезе типа экзамена')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28015f72"
      },
      "source": [
        "Вторая гипотеза тоже подтвердилась - видим, что олимпиадники более успешны относительно других каст, хоть они и обогнали сдающих ЕГЭ всего на 0.4%. При этом, у людей, поступающих по вступительным испытаниям, доля неудач значительно выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdd97eb0"
      },
      "source": [
        "## 3 гипотеза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ea8aea3"
      },
      "source": [
        "На экзаменах неудачи случаются чаще, чем на зачётах/диф. зачётах/при сдаче курсовых проектов\n",
        "\n",
        "Экзамены в вузе, как правило, сложнее зачётов, и их нельзя сдавать много раз. Причём, в некоторых местах, если студент не сдал определённое кол-во зачётов, то к экзаменам его тоже не допустят. Аналогично, с курсовыми проектами - человек, не закрывший курсовую, автоматически получает 2 за экзамен. Поэтому логично предположить, что доля задолженностей выше для экзаменов, чем для других форм отчётности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzpDkzKovDbp"
      },
      "outputs": [],
      "source": [
        "barplot_group(data=df,\n",
        "              col=preproc['target_column'],\n",
        "              col_group=preproc['type_name_column'],\n",
        "              values_in_col_group=preproc['values_in_type_name_column'],\n",
        "              title='Распределение target в разрезе типа отчётности')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xgbo8rgmORP"
      },
      "source": [
        "Вторая гипотеза тоже подтвердилась - видим, что олимпиадники более успешны относительно других каст, хоть они и обогнали сдающих ЕГЭ всего на 0.4%. При этом, у людей, поступающих по вступительным испытаниям, доля неудач значительно выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2857e62"
      },
      "source": [
        "## 4 гипотеза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd9737e4"
      },
      "source": [
        "Вероятность наличия задолженности обратно пропорциональна среднему баллу поступления. Иными словами, в разрезе target распределения среднего балла отличаются, при этом распределение для строк, соответствующих успешной попытке, должно быть смещено вправо (т.е. в сторону максимального балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX3KF0Qrewdy"
      },
      "outputs": [],
      "source": [
        "def create_mean_column(data: pd.DataFrame,\n",
        "                       cols: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Добавление столбца средних по некоторому подмножеству признаков (столбцов)\n",
        "    :param data: датасет\n",
        "    :param cols: список столбцов, значения которых участвуют в вычислении среднего\n",
        "    \"\"\"\n",
        "    # Столбец суммы по подмножеству признаков\n",
        "    sum = 0\n",
        "    for x in cols:\n",
        "        sum += data[x]\n",
        "   \n",
        "    # Столбец средних\n",
        "    data['mean'] = sum/len(cols)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZHw5C1bglsJ"
      },
      "outputs": [],
      "source": [
        "data = create_mean_column(data=df,\n",
        "                   cols=preproc['addmited_exam_columns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sawJIutlUal"
      },
      "outputs": [],
      "source": [
        "def displots_of_statistic(data: pd.DataFrame,\n",
        "                         col: list,\n",
        "                         col_group: str,\n",
        "                         values_in_col_group: list,\n",
        "                         title: str) -> None:\n",
        "    \"\"\"\n",
        "    Построение графиков распределений значений одного столбца в разрезе значений\n",
        "     другого столбца\n",
        "    :param data: датасет\n",
        "    :param col: столбец, по которому хотим смотреть распределение\n",
        "    :param col_group: столбец, в разрезе которого хотим смотреть распределение\n",
        "    :values_in_col_group: список значений col_group\n",
        "    :param title: заголовок\n",
        "    :return: None \n",
        "    \"\"\"\n",
        "    \n",
        "    ''' Словарь, в котором значения являются подстолбцами столбца средних, соответствующие\n",
        "    той или иной градации признака col_group. Ключи, по сути, являются идентификатором\n",
        "    этой градации\n",
        "    '''\n",
        "    data_for_displot = {}\n",
        "    for x in values_in_col_group:\n",
        "        data_for_displot[col_group + ' ' + str(x)] = data[data[col_group] == x][col]\n",
        "\n",
        "    sns.displot(\n",
        "    data=data_for_displot,\n",
        "    kind=\"kde\",\n",
        "    common_norm=False)\n",
        "\n",
        "    plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq3exQEVlUdg"
      },
      "outputs": [],
      "source": [
        "displots_of_statistic(data=df,\n",
        "                     col='mean',\n",
        "                     col_group=preproc['target_column'],\n",
        "                     values_in_col_group=preproc['values_in_target_column'],\n",
        "                     title='Распределение значений mean_score\\n') \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA2psH9ylUgd"
      },
      "outputs": [],
      "source": [
        "def boxplot(data: pd.DataFrame,\n",
        "            x: str,\n",
        "            y: str,\n",
        "            title: str) -> None:\n",
        "    \"\"\"\n",
        "    Построение графиков boxplot по столбцу в разрезе значений другого столбца\n",
        "    :param data: датасет,\n",
        "    :param x: столбец, в разрезе которого хотим строить график\n",
        "    :param y: столбец, по которому хотим строить график\n",
        "    :param title: заголовок\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    sns.boxplot(x=x, y=y, data=data)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.ylabel(y, fontsize=14)\n",
        "    plt.xlabel(x, fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ5oZPxPlUkX"
      },
      "outputs": [],
      "source": [
        "boxplot(data=df,\n",
        "        x=preproc['target_column'],\n",
        "        y='mean',\n",
        "        title='Распределение значений mean_score\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knEh3Ar3i3U6"
      },
      "outputs": [],
      "source": [
        "del df['mean']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49220d4b"
      },
      "source": [
        "Гипотеза в принципе подтвердилась - по первому графику видно, что синее распределение смещено вправо. Это значит, что попытки, заканчивающиеся задолженностью, чаще приходятся на людей, имеющих меньшие баллы при поступлении. Боксплот также демонстрирует смещение статистик, хоть и не очень сильное"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDr41rbWS5lj"
      },
      "source": [
        "# Обучение бейзлайна Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWTSfmXwS5LI"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_test: list,\n",
        "                y_pred: list,\n",
        "                y_score: list,\n",
        "                name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Подсчёт метрик бинарной классификации\n",
        "    :param y_test: реальные метки классов\n",
        "    :parsm y_pred: предсказание алгоритма\n",
        "    :param y_score: вероятность того, что объект относится к целевому классу\n",
        "    \"\"\"\n",
        "    df_metrics = pd.DataFrame()\n",
        "    \n",
        "    df_metrics['model'] = [name]\n",
        "\n",
        "    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n",
        "    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:,1])]\n",
        "    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n",
        "    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n",
        "    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n",
        "    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n",
        "    \n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZv1yvyEXAhA"
      },
      "source": [
        "Разобьём данные на train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvTcr2IlW3EI"
      },
      "outputs": [],
      "source": [
        "X = df.drop(training['target_column'], axis=1)\n",
        "y = df[training['target_column']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    stratify=y,\n",
        "                                                    shuffle=True,\n",
        "                                                    test_size=training['test_size'],\n",
        "                                                    random_state=training['random_state'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1lWV_SncY-H"
      },
      "source": [
        "Разобьём train на train_ и val_, чтобы использовать валидационное множество для проверки после построения каждого нового дерева"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x6Jbnx0cXvM"
      },
      "outputs": [],
      "source": [
        "X_train_, X_val, y_train_, y_val = train_test_split(X_train,\n",
        "                                                    y_train,\n",
        "                                                    stratify=y_train,\n",
        "                                                    shuffle=True,\n",
        "                                                    test_size=training['test_size'],\n",
        "                                                    random_state=training['random_state'])\n",
        "eval_set = [(X_val, y_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJE48hawXEaO"
      },
      "outputs": [],
      "source": [
        "scale_pos_weight =  df[df[training['target_column']] == 0\n",
        "                       ].shape[0] / df[df[training['target_column']] == 1].shape[0]\n",
        "\n",
        "catboost = CatBoostClassifier(random_state=training['random_state'],\n",
        "                              cat_features=training['category_features'],\n",
        "                              scale_pos_weight=scale_pos_weight)\n",
        "catboost.fit(X_train_,\n",
        "        y_train_,\n",
        "        eval_set=eval_set,\n",
        "        early_stopping_rounds=training['early_stopping_round'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1GRGy_keqB8"
      },
      "source": [
        "Взглянем на метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdFBHhL2WwHQ"
      },
      "outputs": [],
      "source": [
        "y_pred = catboost.predict(X_test)\n",
        "y_pred_prob = catboost.predict_proba(X_test)\n",
        "metrics = get_metrics(y_test, y_pred, y_pred_prob, name='Catboost')\n",
        "\n",
        "y_pred_train = catboost.predict(X_train_)\n",
        "y_pred_prob_train = catboost.predict_proba(X_train_)\n",
        "metrics = metrics.append(\n",
        "    get_metrics(y_train_, y_pred_train, y_pred_prob_train, name='Catboost_train'))\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7qlO7bcYDIC"
      },
      "source": [
        "# Подбор гиперпараметров Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_gGGgXdYFMO"
      },
      "outputs": [],
      "source": [
        "def f1_metric(labels, scores):\n",
        "    \"\"\"\n",
        "    Реализация f1-метрики для подачи в Catboost\n",
        "    :param labels: истинные метки классов\n",
        "    :param scores: вероятности того, что объект принадлежит целевому классу\n",
        "    \"\"\"\n",
        "    pred = np.round(scores)\n",
        "    return 'f1', f1_score(labels, pred), True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUdBBPQXYFPK"
      },
      "outputs": [],
      "source": [
        "def objective_lgb(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
        "    params = {\n",
        "        \"n_estimators\":\n",
        "        trial.suggest_categorical(\"n_estimators\", [training['n_estimators']]),\n",
        "        \"learning_rate\":\n",
        "        trial.suggest_categorical(\"learning_rate\", [training['learning_rate']]),\n",
        "        \"max_depth\":\n",
        "        trial.suggest_int(\"max_depth\", 3, 12),\n",
        "        \"l2_leaf_reg\":\n",
        "        trial.suggest_uniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
        "        \"bootstrap_type\":\n",
        "        trial.suggest_categorical(\"bootstrap_type\",\n",
        "                                  [\"Bayesian\", \"Bernoulli\", \"MVS\", \"No\"]),\n",
        "        \"border_count\":\n",
        "        trial.suggest_categorical('border_count', [128, 254]),\n",
        "        \"grow_policy\":\n",
        "        trial.suggest_categorical('grow_policy',\n",
        "                                  [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
        "        \"auto_class_weights\":\n",
        "        trial.suggest_categorical(\"auto_class_weights\",\n",
        "                                  [\"None\", \"Balanced\", \"SqrtBalanced\"]),\n",
        "        \n",
        "        \"cat_features\":\n",
        "        trial.suggest_categorical(\"cat_features\", [training['category_features']]),\n",
        "        \"loss_function\":\n",
        "        trial.suggest_categorical(\"loss_function\", [\"Logloss\"]),\n",
        "        \"use_best_model\":\n",
        "        trial.suggest_categorical(\"use_best_model\", [True]),\n",
        "        \"random_state\":\n",
        "        training['random_state']\n",
        "    }\n",
        "\n",
        "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
        "        params[\"bagging_temperature\"] = trial.suggest_float(\n",
        "            \"bagging_temperature\", 0, 10)\n",
        "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
        "        params[\"subsample\"] = trial.suggest_float(\"subsample\",\n",
        "                                                  0.1,\n",
        "                                                  1,\n",
        "                                                  log=True)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=training['random_state'])\n",
        "\n",
        "    cv_predicts = np.empty(N_FOLDS)\n",
        "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
        "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
        "\n",
        "        model = CatBoostClassifier(**params)\n",
        "        model.fit(train_data,\n",
        "                  eval_set=eval_data,\n",
        "                  early_stopping_rounds=training['early_stopping_round'],\n",
        "                  verbose=0)\n",
        "        \n",
        "        preds = model.predict(X_test)\n",
        "        cv_predicts[idx] = f1_score(y_test, preds)\n",
        "\n",
        "    return np.mean(cv_predicts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFN2XR-MYFRu"
      },
      "outputs": [],
      "source": [
        "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"Catboost\")\n",
        "func = lambda trial: objective_lgb(trial,\n",
        "                                   X_train,\n",
        "                                   y_train,\n",
        "                                   N_FOLDS=training['n_folds'],\n",
        "                                   random_state=training['random_state'],\n",
        "                                   cat_feat=training['category_features'])\n",
        "\n",
        "study_cat.optimize(func, n_trials=20, show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u82HjyLScfQl"
      },
      "outputs": [],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogEviKRzcfT1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xhljiM2YFUP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQagikLhYFWB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}